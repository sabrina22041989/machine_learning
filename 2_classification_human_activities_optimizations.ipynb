{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARHIBdo58IHS"
   },
   "source": [
    "# Data Understanding, Data Preprocessing & Optimierungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "lnhhDCho8IHV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import mean\n",
    "from pandas import Series\n",
    "from numpy.random import randn\n",
    "from numpy import loadtxt\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import tree\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "import math\n",
    "\n",
    "import statistics as stat\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNgt3Hx4DcoO"
   },
   "source": [
    "### Einlesen des Datensatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9A8x_ooFDcoO"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/sabrinagreifzu/Documents/Masterstudium Data Science/Machine Learning und Deep Learning/Thomas/activity_recognition_with_index 3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "ZyLtWssUDcoP",
    "outputId": "8f75f9d2-c6f9-4ee2-d80e-c7b9eda35ac1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person</th>\n",
       "      <th>E1</th>\n",
       "      <th>E2</th>\n",
       "      <th>E3</th>\n",
       "      <th>E4</th>\n",
       "      <th>E5</th>\n",
       "      <th>E6</th>\n",
       "      <th>E7</th>\n",
       "      <th>E8</th>\n",
       "      <th>E9</th>\n",
       "      <th>...</th>\n",
       "      <th>DH96</th>\n",
       "      <th>DH97</th>\n",
       "      <th>DH98</th>\n",
       "      <th>DH99</th>\n",
       "      <th>DH100</th>\n",
       "      <th>DH101</th>\n",
       "      <th>DH102</th>\n",
       "      <th>DH103</th>\n",
       "      <th>DH104</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.004125</td>\n",
       "      <td>0.254095</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>-0.01037</td>\n",
       "      <td>-0.538509</td>\n",
       "      <td>5.95534</td>\n",
       "      <td>1.04063</td>\n",
       "      <td>-1.37437</td>\n",
       "      <td>-0.10937</td>\n",
       "      <td>...</td>\n",
       "      <td>1015.36</td>\n",
       "      <td>717032000.0</td>\n",
       "      <td>0.027384</td>\n",
       "      <td>2.53425</td>\n",
       "      <td>17.3882</td>\n",
       "      <td>8.05589</td>\n",
       "      <td>1.80247</td>\n",
       "      <td>1413310.0</td>\n",
       "      <td>3028080.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.031029</td>\n",
       "      <td>0.193761</td>\n",
       "      <td>0.012918</td>\n",
       "      <td>-0.00237</td>\n",
       "      <td>0.781415</td>\n",
       "      <td>5.18794</td>\n",
       "      <td>0.98963</td>\n",
       "      <td>-0.71937</td>\n",
       "      <td>-0.08737</td>\n",
       "      <td>...</td>\n",
       "      <td>1015.78</td>\n",
       "      <td>705854000.0</td>\n",
       "      <td>0.016947</td>\n",
       "      <td>2.51513</td>\n",
       "      <td>16.5914</td>\n",
       "      <td>7.81769</td>\n",
       "      <td>1.52349</td>\n",
       "      <td>1390180.0</td>\n",
       "      <td>3016420.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015678</td>\n",
       "      <td>0.182336</td>\n",
       "      <td>-0.003028</td>\n",
       "      <td>-0.02337</td>\n",
       "      <td>0.881194</td>\n",
       "      <td>5.66530</td>\n",
       "      <td>0.87563</td>\n",
       "      <td>-0.71937</td>\n",
       "      <td>-0.08037</td>\n",
       "      <td>...</td>\n",
       "      <td>1016.16</td>\n",
       "      <td>627018000.0</td>\n",
       "      <td>0.008129</td>\n",
       "      <td>2.25959</td>\n",
       "      <td>15.2312</td>\n",
       "      <td>7.11684</td>\n",
       "      <td>1.25860</td>\n",
       "      <td>1234110.0</td>\n",
       "      <td>3004430.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.014525</td>\n",
       "      <td>0.176636</td>\n",
       "      <td>-0.006161</td>\n",
       "      <td>-0.02737</td>\n",
       "      <td>1.024900</td>\n",
       "      <td>6.10968</td>\n",
       "      <td>0.91063</td>\n",
       "      <td>-0.71937</td>\n",
       "      <td>-0.08037</td>\n",
       "      <td>...</td>\n",
       "      <td>1015.61</td>\n",
       "      <td>559748000.0</td>\n",
       "      <td>0.007377</td>\n",
       "      <td>2.13924</td>\n",
       "      <td>14.4663</td>\n",
       "      <td>6.70236</td>\n",
       "      <td>1.26643</td>\n",
       "      <td>1102720.0</td>\n",
       "      <td>2992170.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010349</td>\n",
       "      <td>0.179248</td>\n",
       "      <td>-0.008526</td>\n",
       "      <td>-0.02737</td>\n",
       "      <td>0.935697</td>\n",
       "      <td>5.83902</td>\n",
       "      <td>0.91063</td>\n",
       "      <td>-0.75637</td>\n",
       "      <td>-0.08337</td>\n",
       "      <td>...</td>\n",
       "      <td>1015.67</td>\n",
       "      <td>484473000.0</td>\n",
       "      <td>0.011448</td>\n",
       "      <td>1.93595</td>\n",
       "      <td>12.5493</td>\n",
       "      <td>6.08647</td>\n",
       "      <td>1.22387</td>\n",
       "      <td>954322.0</td>\n",
       "      <td>2979610.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 535 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Person        E1        E2        E3       E4        E5       E6       E7  \\\n",
       "0       1 -0.004125  0.254095  0.001426 -0.01037 -0.538509  5.95534  1.04063   \n",
       "1       1  0.031029  0.193761  0.012918 -0.00237  0.781415  5.18794  0.98963   \n",
       "2       1  0.015678  0.182336 -0.003028 -0.02337  0.881194  5.66530  0.87563   \n",
       "3       1  0.014525  0.176636 -0.006161 -0.02737  1.024900  6.10968  0.91063   \n",
       "4       1  0.010349  0.179248 -0.008526 -0.02737  0.935697  5.83902  0.91063   \n",
       "\n",
       "        E8       E9  ...     DH96         DH97      DH98     DH99    DH100  \\\n",
       "0 -1.37437 -0.10937  ...  1015.36  717032000.0  0.027384  2.53425  17.3882   \n",
       "1 -0.71937 -0.08737  ...  1015.78  705854000.0  0.016947  2.51513  16.5914   \n",
       "2 -0.71937 -0.08037  ...  1016.16  627018000.0  0.008129  2.25959  15.2312   \n",
       "3 -0.71937 -0.08037  ...  1015.61  559748000.0  0.007377  2.13924  14.4663   \n",
       "4 -0.75637 -0.08337  ...  1015.67  484473000.0  0.011448  1.93595  12.5493   \n",
       "\n",
       "     DH101    DH102      DH103      DH104  class  \n",
       "0  8.05589  1.80247  1413310.0  3028080.0      1  \n",
       "1  7.81769  1.52349  1390180.0  3016420.0      1  \n",
       "2  7.11684  1.25860  1234110.0  3004430.0      1  \n",
       "3  6.70236  1.26643  1102720.0  2992170.0      1  \n",
       "4  6.08647  1.22387   954322.0  2979610.0      1  \n",
       "\n",
       "[5 rows x 535 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NgZdY9yiDcoQ",
    "outputId": "840af6c0-539f-4567-b8dd-c68940e73674"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4480, 535)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Msi-xePvDcoR",
    "outputId": "1e6f941c-7982-4f62-d783-ebaf1339c14e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    1120\n",
       "1    1120\n",
       "2    1120\n",
       "3    1120\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nCfk5prDcoS"
   },
   "source": [
    "### Verwendung der Dataframe.info()-Funktion, um einen Ãœberblick Ã¼ber den Datensatz zu bekommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9OuY0tLmDcoS",
    "outputId": "1ece03cb-712b-41e9-8b7e-8b76c78a815d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4480 entries, 0 to 4479\n",
      "Columns: 535 entries, Person to class\n",
      "dtypes: float64(519), int64(16)\n",
      "memory usage: 18.3 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konvertierung aller Spalten in den float-Datentyp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vaEjsqlHDcoT"
   },
   "source": [
    "Da der Datensatz in gemischten Datentypen vorliegt, folgt die Konvertierung aller Spalten in den float-Datentyp (Der Float-Datentyp bietet sich in diesem Fall an, da die Daten Ã¼berwiegend im Float-Datentyp vorliegen und der Float-Datentyp genauere Ergebnisse fÃ¼r das Modell ausgeben wird)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BlUoeBUmDcoT"
   },
   "outputs": [],
   "source": [
    "data[[\"E21\",\"E22\",\"E57\",\"E62\",\"E64\",\"E114\",\"T94\",\"DA57\",\"DA58\",\"DA59\",\"DA62\",\"DH57\",\"DH58\",\"DH59\"]] = data[[\"E21\",\"E22\",\"E57\",\"E62\",\"E64\",\"E114\",\"T94\",\"DA57\",\"DA58\",\"DA59\",\"DA62\",\"DH57\",\"DH58\",\"DH59\"]].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bdv5J2IfDcoT",
    "outputId": "008f2908-38f2-4bc3-ee7f-14001d59be00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4480 entries, 0 to 4479\n",
      "Data columns (total 535 columns):\n",
      " #    Column  Dtype  \n",
      "---   ------  -----  \n",
      " 0    Person  int64  \n",
      " 1    E1      float64\n",
      " 2    E2      float64\n",
      " 3    E3      float64\n",
      " 4    E4      float64\n",
      " 5    E5      float64\n",
      " 6    E6      float64\n",
      " 7    E7      float64\n",
      " 8    E8      float64\n",
      " 9    E9      float64\n",
      " 10   E10     float64\n",
      " 11   E11     float64\n",
      " 12   E12     float64\n",
      " 13   E13     float64\n",
      " 14   E14     float64\n",
      " 15   E15     float64\n",
      " 16   E16     float64\n",
      " 17   E17     float64\n",
      " 18   E18     float64\n",
      " 19   E19     float64\n",
      " 20   E20     float64\n",
      " 21   E21     float64\n",
      " 22   E22     float64\n",
      " 23   E23     float64\n",
      " 24   E24     float64\n",
      " 25   E25     float64\n",
      " 26   E26     float64\n",
      " 27   E27     float64\n",
      " 28   E28     float64\n",
      " 29   E29     float64\n",
      " 30   E30     float64\n",
      " 31   E31     float64\n",
      " 32   E32     float64\n",
      " 33   E33     float64\n",
      " 34   E34     float64\n",
      " 35   E35     float64\n",
      " 36   E36     float64\n",
      " 37   E37     float64\n",
      " 38   E38     float64\n",
      " 39   E39     float64\n",
      " 40   E40     float64\n",
      " 41   E41     float64\n",
      " 42   E42     float64\n",
      " 43   E43     float64\n",
      " 44   E44     float64\n",
      " 45   E45     float64\n",
      " 46   E46     float64\n",
      " 47   E47     float64\n",
      " 48   E48     float64\n",
      " 49   E49     float64\n",
      " 50   E50     float64\n",
      " 51   E51     float64\n",
      " 52   E52     float64\n",
      " 53   E53     float64\n",
      " 54   E54     float64\n",
      " 55   E55     float64\n",
      " 56   E56     float64\n",
      " 57   E57     float64\n",
      " 58   E58     float64\n",
      " 59   E59     float64\n",
      " 60   E60     float64\n",
      " 61   E61     float64\n",
      " 62   E62     float64\n",
      " 63   E63     float64\n",
      " 64   E64     float64\n",
      " 65   E65     float64\n",
      " 66   E66     float64\n",
      " 67   E67     float64\n",
      " 68   E68     float64\n",
      " 69   E69     float64\n",
      " 70   E70     float64\n",
      " 71   E71     float64\n",
      " 72   E72     float64\n",
      " 73   E73     float64\n",
      " 74   E74     float64\n",
      " 75   E75     float64\n",
      " 76   E76     float64\n",
      " 77   E77     float64\n",
      " 78   E78     float64\n",
      " 79   E79     float64\n",
      " 80   E80     float64\n",
      " 81   E81     float64\n",
      " 82   E82     float64\n",
      " 83   E83     float64\n",
      " 84   E84     float64\n",
      " 85   E85     float64\n",
      " 86   E86     float64\n",
      " 87   E87     float64\n",
      " 88   E88     float64\n",
      " 89   E89     float64\n",
      " 90   E90     float64\n",
      " 91   E91     float64\n",
      " 92   E92     float64\n",
      " 93   E93     float64\n",
      " 94   E94     float64\n",
      " 95   E95     float64\n",
      " 96   E96     float64\n",
      " 97   E97     float64\n",
      " 98   E98     float64\n",
      " 99   E99     float64\n",
      " 100  E100    float64\n",
      " 101  E101    float64\n",
      " 102  E102    float64\n",
      " 103  E103    float64\n",
      " 104  E104    float64\n",
      " 105  E105    float64\n",
      " 106  E106    float64\n",
      " 107  E107    float64\n",
      " 108  E108    float64\n",
      " 109  E109    float64\n",
      " 110  E110    float64\n",
      " 111  E111    float64\n",
      " 112  E112    float64\n",
      " 113  E113    float64\n",
      " 114  E114    float64\n",
      " 115  E115    float64\n",
      " 116  E116    float64\n",
      " 117  E117    float64\n",
      " 118  E118    float64\n",
      " 119  E119    float64\n",
      " 120  E120    float64\n",
      " 121  E121    float64\n",
      " 122  E122    float64\n",
      " 123  E123    float64\n",
      " 124  E124    float64\n",
      " 125  E125    float64\n",
      " 126  E126    float64\n",
      " 127  E127    float64\n",
      " 128  E128    float64\n",
      " 129  E129    float64\n",
      " 130  E130    float64\n",
      " 131  E131    float64\n",
      " 132  E132    float64\n",
      " 133  E133    float64\n",
      " 134  E134    float64\n",
      " 135  E135    float64\n",
      " 136  E136    float64\n",
      " 137  E137    float64\n",
      " 138  E138    float64\n",
      " 139  E139    float64\n",
      " 140  E140    float64\n",
      " 141  E141    float64\n",
      " 142  E142    float64\n",
      " 143  E143    float64\n",
      " 144  E144    float64\n",
      " 145  E145    float64\n",
      " 146  E146    float64\n",
      " 147  E147    float64\n",
      " 148  E148    float64\n",
      " 149  E149    float64\n",
      " 150  E150    float64\n",
      " 151  E151    float64\n",
      " 152  E152    float64\n",
      " 153  E153    float64\n",
      " 154  E154    float64\n",
      " 155  E155    float64\n",
      " 156  E156    float64\n",
      " 157  E157    float64\n",
      " 158  E158    float64\n",
      " 159  E159    float64\n",
      " 160  E160    float64\n",
      " 161  E161    float64\n",
      " 162  E162    float64\n",
      " 163  E163    float64\n",
      " 164  E164    float64\n",
      " 165  E165    float64\n",
      " 166  E166    float64\n",
      " 167  E167    float64\n",
      " 168  E168    float64\n",
      " 169  E169    float64\n",
      " 170  E170    float64\n",
      " 171  E171    float64\n",
      " 172  E172    float64\n",
      " 173  E173    float64\n",
      " 174  E174    float64\n",
      " 175  T1      float64\n",
      " 176  T2      float64\n",
      " 177  T3      float64\n",
      " 178  T4      float64\n",
      " 179  T5      float64\n",
      " 180  T6      float64\n",
      " 181  T7      float64\n",
      " 182  T8      float64\n",
      " 183  T9      float64\n",
      " 184  T10     float64\n",
      " 185  T11     float64\n",
      " 186  T12     float64\n",
      " 187  T13     float64\n",
      " 188  T14     float64\n",
      " 189  T15     float64\n",
      " 190  T16     float64\n",
      " 191  T17     float64\n",
      " 192  T18     float64\n",
      " 193  T19     float64\n",
      " 194  T20     float64\n",
      " 195  T21     float64\n",
      " 196  T22     float64\n",
      " 197  T23     float64\n",
      " 198  T24     float64\n",
      " 199  T25     float64\n",
      " 200  T26     float64\n",
      " 201  T27     float64\n",
      " 202  T28     float64\n",
      " 203  T29     float64\n",
      " 204  T30     float64\n",
      " 205  T31     float64\n",
      " 206  T32     float64\n",
      " 207  T33     float64\n",
      " 208  T34     float64\n",
      " 209  T35     float64\n",
      " 210  T36     float64\n",
      " 211  T37     float64\n",
      " 212  T38     float64\n",
      " 213  T39     float64\n",
      " 214  T40     float64\n",
      " 215  T41     float64\n",
      " 216  T42     float64\n",
      " 217  T43     float64\n",
      " 218  T44     float64\n",
      " 219  T45     float64\n",
      " 220  T46     float64\n",
      " 221  T47     float64\n",
      " 222  T48     float64\n",
      " 223  T49     float64\n",
      " 224  T50     float64\n",
      " 225  T51     float64\n",
      " 226  T52     float64\n",
      " 227  T53     float64\n",
      " 228  T54     float64\n",
      " 229  T55     float64\n",
      " 230  T56     float64\n",
      " 231  T57     float64\n",
      " 232  T58     float64\n",
      " 233  T59     float64\n",
      " 234  T60     float64\n",
      " 235  T61     float64\n",
      " 236  T62     float64\n",
      " 237  T63     float64\n",
      " 238  T64     float64\n",
      " 239  T65     float64\n",
      " 240  T66     float64\n",
      " 241  T67     float64\n",
      " 242  T68     float64\n",
      " 243  T69     float64\n",
      " 244  T70     float64\n",
      " 245  T71     float64\n",
      " 246  T72     float64\n",
      " 247  T73     float64\n",
      " 248  T74     float64\n",
      " 249  T75     float64\n",
      " 250  T76     float64\n",
      " 251  T77     float64\n",
      " 252  T78     float64\n",
      " 253  T79     float64\n",
      " 254  T80     float64\n",
      " 255  T81     float64\n",
      " 256  T82     float64\n",
      " 257  T83     float64\n",
      " 258  T84     float64\n",
      " 259  T85     float64\n",
      " 260  T86     float64\n",
      " 261  T87     float64\n",
      " 262  T88     float64\n",
      " 263  T89     float64\n",
      " 264  T90     float64\n",
      " 265  T91     float64\n",
      " 266  T92     float64\n",
      " 267  T93     float64\n",
      " 268  T94     float64\n",
      " 269  T95     float64\n",
      " 270  T96     float64\n",
      " 271  T97     float64\n",
      " 272  T98     float64\n",
      " 273  T99     float64\n",
      " 274  T100    float64\n",
      " 275  T101    float64\n",
      " 276  T102    float64\n",
      " 277  T103    float64\n",
      " 278  T104    float64\n",
      " 279  T105    float64\n",
      " 280  T106    float64\n",
      " 281  T107    float64\n",
      " 282  T108    float64\n",
      " 283  T109    float64\n",
      " 284  T110    float64\n",
      " 285  T111    float64\n",
      " 286  T112    float64\n",
      " 287  T113    float64\n",
      " 288  T114    float64\n",
      " 289  T115    float64\n",
      " 290  T116    float64\n",
      " 291  T117    float64\n",
      " 292  T118    float64\n",
      " 293  T119    float64\n",
      " 294  T120    float64\n",
      " 295  T121    float64\n",
      " 296  T122    float64\n",
      " 297  T123    float64\n",
      " 298  T124    float64\n",
      " 299  T125    float64\n",
      " 300  T126    float64\n",
      " 301  T127    float64\n",
      " 302  T128    float64\n",
      " 303  T129    float64\n",
      " 304  T130    float64\n",
      " 305  T131    float64\n",
      " 306  T132    float64\n",
      " 307  T133    float64\n",
      " 308  T134    float64\n",
      " 309  T135    float64\n",
      " 310  T136    float64\n",
      " 311  T137    float64\n",
      " 312  T138    float64\n",
      " 313  T139    float64\n",
      " 314  T140    float64\n",
      " 315  T141    float64\n",
      " 316  T142    float64\n",
      " 317  T143    float64\n",
      " 318  T144    float64\n",
      " 319  T145    float64\n",
      " 320  T146    float64\n",
      " 321  T147    float64\n",
      " 322  T148    float64\n",
      " 323  T149    float64\n",
      " 324  T150    float64\n",
      " 325  T151    float64\n",
      " 326  DA1     float64\n",
      " 327  DA2     float64\n",
      " 328  DA3     float64\n",
      " 329  DA4     float64\n",
      " 330  DA5     float64\n",
      " 331  DA6     float64\n",
      " 332  DA7     float64\n",
      " 333  DA8     float64\n",
      " 334  DA9     float64\n",
      " 335  DA10    float64\n",
      " 336  DA11    float64\n",
      " 337  DA12    float64\n",
      " 338  DA13    float64\n",
      " 339  DA14    float64\n",
      " 340  DA15    float64\n",
      " 341  DA16    float64\n",
      " 342  DA17    float64\n",
      " 343  DA18    float64\n",
      " 344  DA19    float64\n",
      " 345  DA20    float64\n",
      " 346  DA21    float64\n",
      " 347  DA22    float64\n",
      " 348  DA23    float64\n",
      " 349  DA24    float64\n",
      " 350  DA25    float64\n",
      " 351  DA26    float64\n",
      " 352  DA27    float64\n",
      " 353  DA28    float64\n",
      " 354  DA29    float64\n",
      " 355  DA30    float64\n",
      " 356  DA31    float64\n",
      " 357  DA32    float64\n",
      " 358  DA33    float64\n",
      " 359  DA34    float64\n",
      " 360  DA35    float64\n",
      " 361  DA36    float64\n",
      " 362  DA37    float64\n",
      " 363  DA38    float64\n",
      " 364  DA39    float64\n",
      " 365  DA40    float64\n",
      " 366  DA41    float64\n",
      " 367  DA42    float64\n",
      " 368  DA43    float64\n",
      " 369  DA44    float64\n",
      " 370  DA45    float64\n",
      " 371  DA46    float64\n",
      " 372  DA47    float64\n",
      " 373  DA48    float64\n",
      " 374  DA49    float64\n",
      " 375  DA50    float64\n",
      " 376  DA51    float64\n",
      " 377  DA52    float64\n",
      " 378  DA53    float64\n",
      " 379  DA54    float64\n",
      " 380  DA55    float64\n",
      " 381  DA56    float64\n",
      " 382  DA57    float64\n",
      " 383  DA58    float64\n",
      " 384  DA59    float64\n",
      " 385  DA60    float64\n",
      " 386  DA61    float64\n",
      " 387  DA62    float64\n",
      " 388  DA63    float64\n",
      " 389  DA64    float64\n",
      " 390  DA65    float64\n",
      " 391  DA66    float64\n",
      " 392  DA67    float64\n",
      " 393  DA68    float64\n",
      " 394  DA69    float64\n",
      " 395  DA70    float64\n",
      " 396  DA71    float64\n",
      " 397  DA72    float64\n",
      " 398  DA73    float64\n",
      " 399  DA74    float64\n",
      " 400  DA75    float64\n",
      " 401  DA76    float64\n",
      " 402  DA77    float64\n",
      " 403  DA78    float64\n",
      " 404  DA79    float64\n",
      " 405  DA80    float64\n",
      " 406  DA81    float64\n",
      " 407  DA82    float64\n",
      " 408  DA83    float64\n",
      " 409  DA84    float64\n",
      " 410  DA85    float64\n",
      " 411  DA86    float64\n",
      " 412  DA87    float64\n",
      " 413  DA88    float64\n",
      " 414  DA89    float64\n",
      " 415  DA90    float64\n",
      " 416  DA91    float64\n",
      " 417  DA92    float64\n",
      " 418  DA93    float64\n",
      " 419  DA94    float64\n",
      " 420  DA95    float64\n",
      " 421  DA96    float64\n",
      " 422  DA97    float64\n",
      " 423  DA98    float64\n",
      " 424  DA99    float64\n",
      " 425  DA100   float64\n",
      " 426  DA101   float64\n",
      " 427  DA102   float64\n",
      " 428  DA103   float64\n",
      " 429  DA104   float64\n",
      " 430  DH1     float64\n",
      " 431  DH2     float64\n",
      " 432  DH3     float64\n",
      " 433  DH4     float64\n",
      " 434  DH5     float64\n",
      " 435  DH6     float64\n",
      " 436  DH7     float64\n",
      " 437  DH8     float64\n",
      " 438  DH9     float64\n",
      " 439  DH10    float64\n",
      " 440  DH11    float64\n",
      " 441  DH12    float64\n",
      " 442  DH13    float64\n",
      " 443  DH14    float64\n",
      " 444  DH15    float64\n",
      " 445  DH16    float64\n",
      " 446  DH17    float64\n",
      " 447  DH18    float64\n",
      " 448  DH19    float64\n",
      " 449  DH20    float64\n",
      " 450  DH21    float64\n",
      " 451  DH22    float64\n",
      " 452  DH23    float64\n",
      " 453  DH24    float64\n",
      " 454  DH25    float64\n",
      " 455  DH26    float64\n",
      " 456  DH27    float64\n",
      " 457  DH28    float64\n",
      " 458  DH29    float64\n",
      " 459  DH30    float64\n",
      " 460  DH31    float64\n",
      " 461  DH32    float64\n",
      " 462  DH33    float64\n",
      " 463  DH34    float64\n",
      " 464  DH35    float64\n",
      " 465  DH36    float64\n",
      " 466  DH37    float64\n",
      " 467  DH38    float64\n",
      " 468  DH39    float64\n",
      " 469  DH40    float64\n",
      " 470  DH41    float64\n",
      " 471  DH42    float64\n",
      " 472  DH43    float64\n",
      " 473  DH44    float64\n",
      " 474  DH45    float64\n",
      " 475  DH46    float64\n",
      " 476  DH47    float64\n",
      " 477  DH48    float64\n",
      " 478  DH49    float64\n",
      " 479  DH50    float64\n",
      " 480  DH51    float64\n",
      " 481  DH52    float64\n",
      " 482  DH53    float64\n",
      " 483  DH54    float64\n",
      " 484  DH55    float64\n",
      " 485  DH56    float64\n",
      " 486  DH57    float64\n",
      " 487  DH58    float64\n",
      " 488  DH59    float64\n",
      " 489  DH60    float64\n",
      " 490  DH61    float64\n",
      " 491  DH62    float64\n",
      " 492  DH63    float64\n",
      " 493  DH64    float64\n",
      " 494  DH65    float64\n",
      " 495  DH66    float64\n",
      " 496  DH67    float64\n",
      " 497  DH68    float64\n",
      " 498  DH69    float64\n",
      " 499  DH70    float64\n",
      " 500  DH71    float64\n",
      " 501  DH72    float64\n",
      " 502  DH73    float64\n",
      " 503  DH74    float64\n",
      " 504  DH75    float64\n",
      " 505  DH76    float64\n",
      " 506  DH77    float64\n",
      " 507  DH78    float64\n",
      " 508  DH79    float64\n",
      " 509  DH80    float64\n",
      " 510  DH81    float64\n",
      " 511  DH82    float64\n",
      " 512  DH83    float64\n",
      " 513  DH84    float64\n",
      " 514  DH85    float64\n",
      " 515  DH86    float64\n",
      " 516  DH87    float64\n",
      " 517  DH88    float64\n",
      " 518  DH89    float64\n",
      " 519  DH90    float64\n",
      " 520  DH91    float64\n",
      " 521  DH92    float64\n",
      " 522  DH93    float64\n",
      " 523  DH94    float64\n",
      " 524  DH95    float64\n",
      " 525  DH96    float64\n",
      " 526  DH97    float64\n",
      " 527  DH98    float64\n",
      " 528  DH99    float64\n",
      " 529  DH100   float64\n",
      " 530  DH101   float64\n",
      " 531  DH102   float64\n",
      " 532  DH103   float64\n",
      " 533  DH104   float64\n",
      " 534  class   int64  \n",
      "dtypes: float64(533), int64(2)\n",
      "memory usage: 18.3 MB\n"
     ]
    }
   ],
   "source": [
    "data.info(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OX24Si5VDcoU",
    "outputId": "f18fe24b-f0e8-4c3f-9363-be3f8dc7f3e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4480 entries, 0 to 4479\n",
      "Columns: 535 entries, Person to class\n",
      "dtypes: float64(533), int64(2)\n",
      "memory usage: 18.3 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzP7WwXqDcoU"
   },
   "source": [
    "### Verwendung der describe()-Funktion zur Berechnung statistischer Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4-McbFUJDcoU",
    "outputId": "1c7e2aed-a27e-49a9-884f-d3d117d57ac8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person</th>\n",
       "      <th>E1</th>\n",
       "      <th>E2</th>\n",
       "      <th>E3</th>\n",
       "      <th>E4</th>\n",
       "      <th>E5</th>\n",
       "      <th>E6</th>\n",
       "      <th>E7</th>\n",
       "      <th>E8</th>\n",
       "      <th>E9</th>\n",
       "      <th>...</th>\n",
       "      <th>DH96</th>\n",
       "      <th>DH97</th>\n",
       "      <th>DH98</th>\n",
       "      <th>DH99</th>\n",
       "      <th>DH100</th>\n",
       "      <th>DH101</th>\n",
       "      <th>DH102</th>\n",
       "      <th>DH103</th>\n",
       "      <th>DH104</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4480.000000</td>\n",
       "      <td>4480.000000</td>\n",
       "      <td>4480.000000</td>\n",
       "      <td>4480.000000</td>\n",
       "      <td>4480.000000</td>\n",
       "      <td>4480.000000</td>\n",
       "      <td>4480.000000</td>\n",
       "      <td>4480.000000</td>\n",
       "      <td>4480.000000</td>\n",
       "      <td>4480.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4480.000000</td>\n",
       "      <td>4.480000e+03</td>\n",
       "      <td>4480.000000</td>\n",
       "      <td>4480.000000</td>\n",
       "      <td>4480.000000</td>\n",
       "      <td>4480.000000</td>\n",
       "      <td>4480.000000</td>\n",
       "      <td>4.480000e+03</td>\n",
       "      <td>4.480000e+03</td>\n",
       "      <td>4480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.500000</td>\n",
       "      <td>0.069109</td>\n",
       "      <td>0.488721</td>\n",
       "      <td>0.064519</td>\n",
       "      <td>0.068895</td>\n",
       "      <td>0.640896</td>\n",
       "      <td>6.986733</td>\n",
       "      <td>1.504077</td>\n",
       "      <td>-1.243163</td>\n",
       "      <td>-0.260268</td>\n",
       "      <td>...</td>\n",
       "      <td>995.125291</td>\n",
       "      <td>1.783296e+10</td>\n",
       "      <td>0.146855</td>\n",
       "      <td>46.787567</td>\n",
       "      <td>378.001879</td>\n",
       "      <td>144.291078</td>\n",
       "      <td>9.347557</td>\n",
       "      <td>3.513370e+07</td>\n",
       "      <td>1.359751e+07</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.544685</td>\n",
       "      <td>0.461571</td>\n",
       "      <td>0.688014</td>\n",
       "      <td>0.513720</td>\n",
       "      <td>0.636866</td>\n",
       "      <td>1.341187</td>\n",
       "      <td>7.005764</td>\n",
       "      <td>1.357288</td>\n",
       "      <td>1.231516</td>\n",
       "      <td>0.747809</td>\n",
       "      <td>...</td>\n",
       "      <td>107.699426</td>\n",
       "      <td>3.441611e+10</td>\n",
       "      <td>0.431288</td>\n",
       "      <td>87.299176</td>\n",
       "      <td>715.895192</td>\n",
       "      <td>264.241472</td>\n",
       "      <td>16.177566</td>\n",
       "      <td>6.779186e+07</td>\n",
       "      <td>2.849531e+07</td>\n",
       "      <td>1.118159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.401350</td>\n",
       "      <td>0.044061</td>\n",
       "      <td>-1.629660</td>\n",
       "      <td>-2.780330</td>\n",
       "      <td>-7.320410</td>\n",
       "      <td>1.076340</td>\n",
       "      <td>0.118958</td>\n",
       "      <td>-4.031040</td>\n",
       "      <td>-3.931120</td>\n",
       "      <td>...</td>\n",
       "      <td>220.550000</td>\n",
       "      <td>7.194500e+02</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.008857</td>\n",
       "      <td>0.113070</td>\n",
       "      <td>0.034914</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>7.315860e+00</td>\n",
       "      <td>3.062260e+01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.750000</td>\n",
       "      <td>-0.014160</td>\n",
       "      <td>0.138413</td>\n",
       "      <td>-0.043896</td>\n",
       "      <td>-0.064297</td>\n",
       "      <td>-0.096772</td>\n",
       "      <td>3.572295</td>\n",
       "      <td>0.563736</td>\n",
       "      <td>-1.631850</td>\n",
       "      <td>-0.237739</td>\n",
       "      <td>...</td>\n",
       "      <td>1015.330000</td>\n",
       "      <td>1.435125e+08</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>1.345875</td>\n",
       "      <td>8.916457</td>\n",
       "      <td>4.406465</td>\n",
       "      <td>0.872344</td>\n",
       "      <td>2.872438e+05</td>\n",
       "      <td>2.679085e+05</td>\n",
       "      <td>1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.500000</td>\n",
       "      <td>-0.000825</td>\n",
       "      <td>0.208430</td>\n",
       "      <td>-0.015432</td>\n",
       "      <td>-0.026010</td>\n",
       "      <td>0.509039</td>\n",
       "      <td>4.924720</td>\n",
       "      <td>0.972716</td>\n",
       "      <td>-0.789900</td>\n",
       "      <td>-0.120764</td>\n",
       "      <td>...</td>\n",
       "      <td>1015.740000</td>\n",
       "      <td>1.218840e+09</td>\n",
       "      <td>0.017072</td>\n",
       "      <td>4.844600</td>\n",
       "      <td>32.761550</td>\n",
       "      <td>15.043550</td>\n",
       "      <td>2.941755</td>\n",
       "      <td>2.400135e+06</td>\n",
       "      <td>1.193080e+06</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.250000</td>\n",
       "      <td>0.009368</td>\n",
       "      <td>0.414216</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>-0.002398</td>\n",
       "      <td>1.455420</td>\n",
       "      <td>8.153475</td>\n",
       "      <td>1.838640</td>\n",
       "      <td>-0.334751</td>\n",
       "      <td>-0.066397</td>\n",
       "      <td>...</td>\n",
       "      <td>1015.840000</td>\n",
       "      <td>1.279192e+10</td>\n",
       "      <td>0.085110</td>\n",
       "      <td>35.001100</td>\n",
       "      <td>277.930000</td>\n",
       "      <td>112.850000</td>\n",
       "      <td>10.233175</td>\n",
       "      <td>2.519182e+07</td>\n",
       "      <td>6.489048e+06</td>\n",
       "      <td>3.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.920770</td>\n",
       "      <td>3.985120</td>\n",
       "      <td>4.076450</td>\n",
       "      <td>4.544780</td>\n",
       "      <td>9.045220</td>\n",
       "      <td>116.388000</td>\n",
       "      <td>4.644590</td>\n",
       "      <td>3.557610</td>\n",
       "      <td>4.041960</td>\n",
       "      <td>...</td>\n",
       "      <td>1018.630000</td>\n",
       "      <td>1.224190e+11</td>\n",
       "      <td>5.710930</td>\n",
       "      <td>320.499000</td>\n",
       "      <td>2605.500000</td>\n",
       "      <td>989.677000</td>\n",
       "      <td>138.119000</td>\n",
       "      <td>2.410860e+08</td>\n",
       "      <td>1.187810e+08</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 535 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Person           E1           E2           E3           E4  \\\n",
       "count  4480.000000  4480.000000  4480.000000  4480.000000  4480.000000   \n",
       "mean     20.500000     0.069109     0.488721     0.064519     0.068895   \n",
       "std      11.544685     0.461571     0.688014     0.513720     0.636866   \n",
       "min       1.000000    -1.401350     0.044061    -1.629660    -2.780330   \n",
       "25%      10.750000    -0.014160     0.138413    -0.043896    -0.064297   \n",
       "50%      20.500000    -0.000825     0.208430    -0.015432    -0.026010   \n",
       "75%      30.250000     0.009368     0.414216     0.001261    -0.002398   \n",
       "max      40.000000     3.920770     3.985120     4.076450     4.544780   \n",
       "\n",
       "                E5           E6           E7           E8           E9  ...  \\\n",
       "count  4480.000000  4480.000000  4480.000000  4480.000000  4480.000000  ...   \n",
       "mean      0.640896     6.986733     1.504077    -1.243163    -0.260268  ...   \n",
       "std       1.341187     7.005764     1.357288     1.231516     0.747809  ...   \n",
       "min      -7.320410     1.076340     0.118958    -4.031040    -3.931120  ...   \n",
       "25%      -0.096772     3.572295     0.563736    -1.631850    -0.237739  ...   \n",
       "50%       0.509039     4.924720     0.972716    -0.789900    -0.120764  ...   \n",
       "75%       1.455420     8.153475     1.838640    -0.334751    -0.066397  ...   \n",
       "max       9.045220   116.388000     4.644590     3.557610     4.041960  ...   \n",
       "\n",
       "              DH96          DH97         DH98         DH99        DH100  \\\n",
       "count  4480.000000  4.480000e+03  4480.000000  4480.000000  4480.000000   \n",
       "mean    995.125291  1.783296e+10     0.146855    46.787567   378.001879   \n",
       "std     107.699426  3.441611e+10     0.431288    87.299176   715.895192   \n",
       "min     220.550000  7.194500e+02     0.000012     0.008857     0.113070   \n",
       "25%    1015.330000  1.435125e+08     0.005085     1.345875     8.916457   \n",
       "50%    1015.740000  1.218840e+09     0.017072     4.844600    32.761550   \n",
       "75%    1015.840000  1.279192e+10     0.085110    35.001100   277.930000   \n",
       "max    1018.630000  1.224190e+11     5.710930   320.499000  2605.500000   \n",
       "\n",
       "             DH101        DH102         DH103         DH104        class  \n",
       "count  4480.000000  4480.000000  4.480000e+03  4.480000e+03  4480.000000  \n",
       "mean    144.291078     9.347557  3.513370e+07  1.359751e+07     2.500000  \n",
       "std     264.241472    16.177566  6.779186e+07  2.849531e+07     1.118159  \n",
       "min       0.034914     0.001795  7.315860e+00  3.062260e+01     1.000000  \n",
       "25%       4.406465     0.872344  2.872438e+05  2.679085e+05     1.750000  \n",
       "50%      15.043550     2.941755  2.400135e+06  1.193080e+06     2.500000  \n",
       "75%     112.850000    10.233175  2.519182e+07  6.489048e+06     3.250000  \n",
       "max     989.677000   138.119000  2.410860e+08  1.187810e+08     4.000000  \n",
       "\n",
       "[8 rows x 535 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_T2S1H6DcoV"
   },
   "source": [
    "### Untersuchung auf fehlende Werte im Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hol7NE2fDcoV"
   },
   "outputs": [],
   "source": [
    "def check_NaN(data):\n",
    "    null_checking = []\n",
    "    for column in data.columns:\n",
    "        not_null = data[column].isnull().value_counts()[0]\n",
    "        try:\n",
    "            is_null = data[column].isnull().value_counts()[1]\n",
    "        except:\n",
    "            is_null = 0\n",
    "        temp_dict = {'name': column, 'is_null': is_null, 'not_null': not_null}\n",
    "        null_checking.append(temp_dict)\n",
    "    df_ = pd.DataFrame(null_checking)\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UOdaQ_1BDcoV",
    "outputId": "ab023d1f-515f-4f49-c2bc-f27d6adce0ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>is_null</th>\n",
       "      <th>not_null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Person</td>\n",
       "      <td>0</td>\n",
       "      <td>4480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E1</td>\n",
       "      <td>0</td>\n",
       "      <td>4480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E2</td>\n",
       "      <td>0</td>\n",
       "      <td>4480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E3</td>\n",
       "      <td>0</td>\n",
       "      <td>4480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E4</td>\n",
       "      <td>0</td>\n",
       "      <td>4480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>DH101</td>\n",
       "      <td>0</td>\n",
       "      <td>4480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>DH102</td>\n",
       "      <td>0</td>\n",
       "      <td>4480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>DH103</td>\n",
       "      <td>0</td>\n",
       "      <td>4480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>DH104</td>\n",
       "      <td>0</td>\n",
       "      <td>4480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>class</td>\n",
       "      <td>0</td>\n",
       "      <td>4480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>535 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  is_null  not_null\n",
       "0    Person        0      4480\n",
       "1        E1        0      4480\n",
       "2        E2        0      4480\n",
       "3        E3        0      4480\n",
       "4        E4        0      4480\n",
       "..      ...      ...       ...\n",
       "530   DH101        0      4480\n",
       "531   DH102        0      4480\n",
       "532   DH103        0      4480\n",
       "533   DH104        0      4480\n",
       "534   class        0      4480\n",
       "\n",
       "[535 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_NaN(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "56T1CqySDcoW"
   },
   "outputs": [],
   "source": [
    "check_for_nan = data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "EA63zEShDcoW",
    "outputId": "fb98fe91-ddbe-4c4a-978b-3ed8aea66e48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_for_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xvRyVh3EPFo"
   },
   "source": [
    "### Untersuchung auf Duplikate im Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AuzmlPm_DcoW"
   },
   "outputs": [],
   "source": [
    "def check_duplicates(data):\n",
    "    dup_checking = []\n",
    "    for column in data.columns:\n",
    "        not_duplicated = data[column].duplicated().value_counts()[0]\n",
    "        try:\n",
    "            duplicated = data[column].duplicated().value_counts()[1]\n",
    "        except:\n",
    "            duplicated = 0\n",
    "        temp_dict = {\n",
    "            'name': column,\n",
    "            'duplicated': duplicated,\n",
    "            'not_duplicated': not_duplicated\n",
    "        }\n",
    "        dup_checking.append(temp_dict)\n",
    "    df_ = pd.DataFrame(dup_checking)\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "X0TN4hBiDcoX",
    "outputId": "ddd3867a-39fc-4304-ca00-82cdb349fcea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>duplicated</th>\n",
       "      <th>not_duplicated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Person</td>\n",
       "      <td>4440</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E1</td>\n",
       "      <td>4</td>\n",
       "      <td>4476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E2</td>\n",
       "      <td>11</td>\n",
       "      <td>4469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E3</td>\n",
       "      <td>9</td>\n",
       "      <td>4471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E4</td>\n",
       "      <td>2197</td>\n",
       "      <td>2283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>DH101</td>\n",
       "      <td>9</td>\n",
       "      <td>4471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>DH102</td>\n",
       "      <td>6</td>\n",
       "      <td>4474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>DH103</td>\n",
       "      <td>69</td>\n",
       "      <td>4411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>DH104</td>\n",
       "      <td>13</td>\n",
       "      <td>4467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>class</td>\n",
       "      <td>4476</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>535 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  duplicated  not_duplicated\n",
       "0    Person        4440              40\n",
       "1        E1           4            4476\n",
       "2        E2          11            4469\n",
       "3        E3           9            4471\n",
       "4        E4        2197            2283\n",
       "..      ...         ...             ...\n",
       "530   DH101           9            4471\n",
       "531   DH102           6            4474\n",
       "532   DH103          69            4411\n",
       "533   DH104          13            4467\n",
       "534   class        4476               4\n",
       "\n",
       "[535 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_duplicates(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpMHFOtLDcoX"
   },
   "source": [
    "### Untersuchung auf korrelierende Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdZgg7y3E7OZ"
   },
   "source": [
    "Die hohe Anzahl korrelierender Features sowie zahlreiche Duplikate im Datensatz lassen darauf schlieÃŸen, dass Feature Selection in der Phase des Preprocessings eine wichtige Kompente darstellt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "F3l55B9RDcoX"
   },
   "outputs": [],
   "source": [
    "def top_correlated_features(data, limit=.75, verbose=False):\n",
    "    df_corr = data.corr().abs().unstack().reset_index().sort_values(\n",
    "        0, ascending=False)\n",
    "    df_corr.columns = [\"feature_0\", 'feature_1', 'correlation']\n",
    "    df_corr['keep_me'] = df_corr.apply(\n",
    "        lambda x: False if x['feature_0'] == x['feature_1'] else True, axis=1)\n",
    "    df_corr['feature_combo'] = df_corr.apply(\n",
    "        lambda x: ' and '.join(set(x[['feature_0', 'feature_1']])), axis=1)\n",
    "\n",
    "    corr_features = df_corr[df_corr.keep_me == True][[\n",
    "        'feature_combo', 'correlation'\n",
    "    ]].drop_duplicates().reset_index(drop='index')\n",
    "    # features with correlation more than 75%\n",
    "    if verbose == True:\n",
    "        return corr_features\n",
    "    else:\n",
    "        return corr_features[corr_features.correlation > limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "IZ4aEPiqDcoY",
    "outputId": "28e38bb9-2318-41c8-dee6-415a1433f55c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_combo</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T77 and T75</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T75 and T77</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T89 and T91</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T89 and T92</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E111 and E112</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9061</th>\n",
       "      <td>E88 and E170</td>\n",
       "      <td>0.750473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9062</th>\n",
       "      <td>E69 and E168</td>\n",
       "      <td>0.750443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9063</th>\n",
       "      <td>E130 and E16</td>\n",
       "      <td>0.750223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9064</th>\n",
       "      <td>E102 and E55</td>\n",
       "      <td>0.750124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9065</th>\n",
       "      <td>E131 and E16</td>\n",
       "      <td>0.750006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9066 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_combo  correlation\n",
       "0       T77 and T75     1.000000\n",
       "1       T75 and T77     1.000000\n",
       "2       T89 and T91     1.000000\n",
       "3       T89 and T92     1.000000\n",
       "4     E111 and E112     1.000000\n",
       "...             ...          ...\n",
       "9061   E88 and E170     0.750473\n",
       "9062   E69 and E168     0.750443\n",
       "9063   E130 and E16     0.750223\n",
       "9064   E102 and E55     0.750124\n",
       "9065   E131 and E16     0.750006\n",
       "\n",
       "[9066 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_correlated_features(data, limit=.75, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzlAgRtsHHYQ"
   },
   "source": [
    "### Darstellung des Wertebereichs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuVYuXgEHpKY"
   },
   "source": [
    "Auch wenn die oben angezeigte Grafik nur einen kleinen Ausschnitt der Daten zeigt, ist bereits hier erkennbar, dass die Daten zur Weiterverarbeitung skaliert werden mÃ¼ssen, da die Datenwerte teils sehr weit auseinanderliegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "YWElfdilHUEY"
   },
   "outputs": [],
   "source": [
    "tile_size=20\n",
    "axis_title_size=20\n",
    "axis_size=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "TWDqMYpJaQAW",
    "outputId": "bc50da77-5e68-4d7a-c508-7d227fd986bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T122',\n",
       " 'E172',\n",
       " 'DA9',\n",
       " 'DA25',\n",
       " 'DA16',\n",
       " 'E170',\n",
       " 'E23',\n",
       " 'E48',\n",
       " 'DH79',\n",
       " 'DA22',\n",
       " 'DA35',\n",
       " 'T140',\n",
       " 'DA27',\n",
       " 'E58',\n",
       " 'E116',\n",
       " 'T101',\n",
       " 'E35',\n",
       " 'T128',\n",
       " 'E91',\n",
       " 'E144',\n",
       " 'T75',\n",
       " 'DA101',\n",
       " 'DH92',\n",
       " 'DA71',\n",
       " 'E159',\n",
       " 'T31',\n",
       " 'DH46',\n",
       " 'T95',\n",
       " 'E139',\n",
       " 'T39']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = random.sample(list(data.columns), 30)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "39O1-nonHbWi",
    "outputId": "795b0914-b129-4d5e-c028-c498765d600c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "maxfs = [[data[[x]].min()[x], data[[x]].max()[x]] for x in features]\n",
    "features2 = [[i,i] for f, i in enumerate(features)]\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(20,15))\n",
    "ax.tick_params(labelsize=axis_size, which='both', axis=\"both\", direction='out')\n",
    "\n",
    "ax.set_xlabel('Value range', fontsize=axis_title_size)\n",
    "\n",
    "ax.set_xlim(-15, 23000)\n",
    "\n",
    "plt.margins(0.025)\n",
    "\n",
    "for i in range(20):\n",
    "    ax.plot(maxfs[i], features2[i], lw=25, color= 'darkseagreen', solid_capstyle=\"butt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9XYFXC4Dcoa"
   },
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vd4UzY4cIHc4"
   },
   "source": [
    "### Splitten der Daten in Features, die Zielvariable 'class' und die Group-Variable \"Person\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "Td75mTKoDcob"
   },
   "outputs": [],
   "source": [
    "data_input = data.drop(['Person', 'class'], axis = 1)\n",
    "data_person = data['Person']\n",
    "data_labels_raw = data['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLzq251BIZw5"
   },
   "source": [
    "### Splitten der Daten in Trainings- und Test-Datendaten (90% Trainingsdaten, 10% Testdaten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "rGH_H5-nDcoc"
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels_raw, test_labels_raw = train_test_split(data_input, data_labels_raw, test_size = 0.1, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skalierung der Daten, um eine Verzerrung des Ergebnisse durch Outliers zu vermeiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAml02p0JJPi"
   },
   "source": [
    "### Feature Importance: Visualisierung der wichtigsten Features im Datensatz; Anwendung von GridSearch zur ErschlieÃŸung der besten Paramterkombination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "tRKId8J4Dcod"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 200building tree 2 of 200\n",
      "\n",
      "building tree 3 of 200building tree 4 of 200\n",
      "building tree 5 of 200\n",
      "\n",
      "building tree 6 of 200\n",
      "building tree 7 of 200\n",
      "building tree 8 of 200\n",
      "building tree 9 of 200\n",
      "building tree 10 of 200building tree 11 of 200\n",
      "building tree 12 of 200building tree 13 of 200\n",
      "building tree 14 of 200building tree 15 of 200\n",
      "\n",
      "building tree 16 of 200\n",
      "\n",
      "\n",
      "building tree 17 of 200\n",
      "building tree 18 of 200\n",
      "building tree 19 of 200building tree 20 of 200\n",
      "\n",
      "building tree 21 of 200\n",
      "building tree 22 of 200\n",
      "building tree 23 of 200building tree 24 of 200\n",
      "\n",
      "building tree 25 of 200building tree 26 of 200\n",
      "\n",
      "building tree 27 of 200\n",
      "building tree 28 of 200\n",
      "building tree 29 of 200\n",
      "building tree 30 of 200\n",
      "building tree 31 of 200\n",
      "building tree 32 of 200\n",
      "building tree 33 of 200\n",
      "building tree 34 of 200\n",
      "building tree 35 of 200\n",
      "building tree 36 of 200\n",
      "building tree 37 of 200building tree 38 of 200\n",
      "\n",
      "building tree 39 of 200\n",
      "building tree 40 of 200\n",
      "building tree 41 of 200building tree 42 of 200\n",
      "building tree 43 of 200\n",
      "building tree 44 of 200\n",
      "\n",
      "building tree 45 of 200\n",
      "building tree 46 of 200\n",
      "building tree 47 of 200\n",
      "building tree 48 of 200\n",
      "building tree 49 of 200\n",
      "building tree 50 of 200\n",
      "building tree 51 of 200\n",
      "building tree 52 of 200\n",
      "building tree 53 of 200\n",
      "building tree 54 of 200building tree 55 of 200\n",
      "\n",
      "building tree 56 of 200\n",
      "building tree 57 of 200\n",
      "building tree 58 of 200\n",
      "building tree 59 of 200\n",
      "building tree 60 of 200building tree 61 of 200\n",
      "\n",
      "building tree 62 of 200building tree 63 of 200\n",
      "\n",
      "building tree 64 of 200\n",
      "building tree 65 of 200\n",
      "building tree 66 of 200\n",
      "building tree 67 of 200\n",
      "building tree 68 of 200\n",
      "building tree 69 of 200\n",
      "building tree 70 of 200\n",
      "building tree 71 of 200building tree 72 of 200\n",
      "\n",
      "building tree 73 of 200\n",
      "building tree 74 of 200building tree 75 of 200\n",
      "\n",
      "building tree 76 of 200building tree 77 of 200\n",
      "building tree 78 of 200\n",
      "\n",
      "building tree 79 of 200\n",
      "building tree 80 of 200\n",
      "building tree 81 of 200\n",
      "building tree 82 of 200\n",
      "building tree 83 of 200\n",
      "building tree 84 of 200\n",
      "building tree 85 of 200building tree 86 of 200\n",
      "\n",
      "building tree 87 of 200\n",
      "building tree 88 of 200building tree 89 of 200building tree 90 of 200\n",
      "\n",
      "\n",
      "building tree 91 of 200\n",
      "building tree 92 of 200building tree 93 of 200\n",
      "\n",
      "building tree 94 of 200\n",
      "building tree 95 of 200\n",
      "building tree 96 of 200\n",
      "building tree 97 of 200\n",
      "building tree 98 of 200\n",
      "building tree 99 of 200\n",
      "building tree 100 of 200\n",
      "building tree 101 of 200\n",
      "building tree 102 of 200building tree 103 of 200\n",
      "\n",
      "building tree 104 of 200\n",
      "building tree 105 of 200\n",
      "building tree 106 of 200\n",
      "building tree 107 of 200\n",
      "building tree 108 of 200\n",
      "building tree 109 of 200\n",
      "building tree 110 of 200\n",
      "building tree 111 of 200\n",
      "building tree 112 of 200\n",
      "building tree 113 of 200\n",
      "building tree 114 of 200\n",
      "building tree 115 of 200\n",
      "building tree 116 of 200\n",
      "building tree 117 of 200\n",
      "building tree 118 of 200\n",
      "building tree 119 of 200building tree 120 of 200\n",
      "\n",
      "building tree 121 of 200building tree 122 of 200building tree 123 of 200\n",
      "\n",
      "\n",
      "building tree 124 of 200building tree 125 of 200\n",
      "\n",
      "building tree 126 of 200building tree 127 of 200\n",
      "building tree 128 of 200\n",
      "\n",
      "building tree 129 of 200\n",
      "building tree 130 of 200\n",
      "building tree 131 of 200\n",
      "building tree 132 of 200\n",
      "building tree 133 of 200\n",
      "building tree 134 of 200\n",
      "building tree 135 of 200building tree 136 of 200\n",
      "building tree 137 of 200\n",
      "building tree 138 of 200building tree 139 of 200\n",
      "\n",
      "\n",
      "building tree 140 of 200\n",
      "building tree 141 of 200\n",
      "building tree 142 of 200\n",
      "building tree 143 of 200\n",
      "building tree 144 of 200\n",
      "building tree 145 of 200\n",
      "building tree 146 of 200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 147 of 200building tree 148 of 200\n",
      "\n",
      "building tree 149 of 200\n",
      "building tree 150 of 200\n",
      "building tree 151 of 200\n",
      "building tree 152 of 200\n",
      "building tree 153 of 200\n",
      "building tree 154 of 200building tree 155 of 200\n",
      "building tree 156 of 200\n",
      "\n",
      "building tree 157 of 200\n",
      "building tree 158 of 200\n",
      "building tree 159 of 200\n",
      "building tree 160 of 200\n",
      "building tree 161 of 200\n",
      "building tree 162 of 200building tree 163 of 200\n",
      "\n",
      "building tree 164 of 200\n",
      "building tree 165 of 200building tree 166 of 200\n",
      "\n",
      "building tree 167 of 200\n",
      "building tree 168 of 200\n",
      "building tree 169 of 200building tree 170 of 200\n",
      "\n",
      "building tree 171 of 200building tree 172 of 200building tree 173 of 200\n",
      "building tree 174 of 200\n",
      "\n",
      "\n",
      "building tree 175 of 200\n",
      "building tree 176 of 200\n",
      "building tree 177 of 200\n",
      "building tree 178 of 200\n",
      "building tree 179 of 200\n",
      "building tree 180 of 200building tree 181 of 200\n",
      "\n",
      "building tree 182 of 200\n",
      "building tree 183 of 200\n",
      "building tree 184 of 200\n",
      "building tree 185 of 200\n",
      "building tree 186 of 200\n",
      "building tree 187 of 200\n",
      "building tree 188 of 200building tree 189 of 200\n",
      "building tree 190 of 200\n",
      "\n",
      "building tree 191 of 200building tree 192 of 200building tree 193 of 200\n",
      "\n",
      "\n",
      "building tree 194 of 200\n",
      "building tree 195 of 200\n",
      "building tree 196 of 200building tree 197 of 200\n",
      "\n",
      "building tree 198 of 200\n",
      "building tree 199 of 200\n",
      "building tree 200 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    1.5s finished\n"
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(estimator=RandomForestClassifier(n_jobs=-1, verbose = 2), param_grid={\n",
    "    'n_estimators': [200, 500, 1000],        \n",
    "    'max_depth': [4, 5, 6],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}, n_jobs=-1)\n",
    "    \n",
    "clf.fit(train_data, train_labels_raw)\n",
    "    \n",
    "clf = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "XIoE9NyuDcod",
    "outputId": "52f88803-30cd-4d35-f51c-b96ee969f25d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=6, n_estimators=200,\n",
       "                       n_jobs=-1, verbose=2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "hWSLOtkGDcod",
    "outputId": "e1069662-2390-488a-a5a1-cf170139c82c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_labels = list(data_input.columns.values[:-1])\n",
    "len(feat_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIOsWpm2JqDU"
   },
   "source": [
    "### Die Funktion \"feature_importances_\" gibt anschlieÃŸend die wichtigsten 100 Features (wurde manuell definiert) in Form eines Dictionaries aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "tucaWxyVDcod"
   },
   "outputs": [],
   "source": [
    "imp_dict = dict()\n",
    "    \n",
    "for feature in zip(feat_labels, clf.feature_importances_):\n",
    "    imp_dict[feature[0]] = feature[1]\n",
    "imp_dict = {k: v for k, v in sorted(imp_dict.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Uwd5irkdDcoe",
    "outputId": "39aa2420-11fa-451a-fff5-08a715b00c95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E67': 0.03992056125259841,\n",
       " 'T13': 0.028587872309896182,\n",
       " 'E69': 0.02603187407968347,\n",
       " 'T28': 0.02576642359924407,\n",
       " 'E76': 0.020626502006085578,\n",
       " 'E26': 0.02047857338451169,\n",
       " 'E75': 0.020065381563020835,\n",
       " 'E70': 0.019818264438569398,\n",
       " 'T2': 0.015150291397231168,\n",
       " 'E18': 0.015078421592594857,\n",
       " 'T150': 0.014573293074822085,\n",
       " 'T48': 0.014165701762361973,\n",
       " 'E73': 0.014000893530906328,\n",
       " 'T17': 0.013856926843772776,\n",
       " 'E23': 0.013779708252043929,\n",
       " 'E77': 0.013385765084825973,\n",
       " 'T132': 0.013141007235447436,\n",
       " 'E53': 0.013021366089782447,\n",
       " 'E45': 0.012993962389629396,\n",
       " 'E43': 0.012927145174517136,\n",
       " 'T7': 0.012669725332467416,\n",
       " 'E46': 0.012663579431392425,\n",
       " 'E52': 0.012271378897492162,\n",
       " 'E51': 0.012259457535582316,\n",
       " 'E62': 0.011924860721284456,\n",
       " 'T52': 0.01183036636146229,\n",
       " 'E17': 0.011427998994290551,\n",
       " 'E15': 0.010619078618931426,\n",
       " 'T87': 0.010568107845393256,\n",
       " 'T32': 0.009741468818917097,\n",
       " 'T90': 0.009148595406113241,\n",
       " 'T59': 0.008971558951887308,\n",
       " 'T116': 0.008692345202539215,\n",
       " 'T102': 0.008636806626022862,\n",
       " 'T144': 0.008470838814279897,\n",
       " 'T101': 0.008454791145975197,\n",
       " 'T76': 0.008239646245661116,\n",
       " 'T143': 0.007956211566790768,\n",
       " 'T60': 0.007930311103955307,\n",
       " 'T43': 0.007446707350848236,\n",
       " 'T66': 0.007389870295744798,\n",
       " 'T88': 0.00734860301280811,\n",
       " 'T142': 0.006898907135496025,\n",
       " 'T40': 0.006875679494639537,\n",
       " 'T37': 0.006778170690756957,\n",
       " 'E49': 0.006667462535456759,\n",
       " 'E24': 0.006605393989079164,\n",
       " 'DH28': 0.006446176777311089,\n",
       " 'T22': 0.006391868714239179,\n",
       " 'T74': 0.006348863560976689,\n",
       " 'T151': 0.006278677466566768,\n",
       " 'E54': 0.006249213478447268,\n",
       " 'E25': 0.006225791784517649,\n",
       " 'T83': 0.00609819057917801,\n",
       " 'T149': 0.006094206511533988,\n",
       " 'T84': 0.00604633305217035,\n",
       " 'T67': 0.005876567894206763,\n",
       " 'T77': 0.005779190087104286,\n",
       " 'T29': 0.0055939602659758544,\n",
       " 'T130': 0.005153896596359216,\n",
       " 'T100': 0.005014738351100483,\n",
       " 'T53': 0.004984865898393161,\n",
       " 'T147': 0.004816448778688715,\n",
       " 'T104': 0.004801501222666176,\n",
       " 'T49': 0.00460315792424195,\n",
       " 'T58': 0.004564452645995451,\n",
       " 'T55': 0.004478797317672448,\n",
       " 'T141': 0.004461399598217087,\n",
       " 'T50': 0.00437026642371861,\n",
       " 'T54': 0.0042438944605908075,\n",
       " 'T44': 0.0040059925489412266,\n",
       " 'T82': 0.0039518348431549334,\n",
       " 'T14': 0.00383851083750855,\n",
       " 'T78': 0.0036701861312244417,\n",
       " 'T56': 0.003666442409228938,\n",
       " 'T89': 0.0036000210131985617,\n",
       " 'T145': 0.0035565143932133614,\n",
       " 'T99': 0.003305501399795943,\n",
       " 'T131': 0.0032638813915923603,\n",
       " 'T95': 0.003144365337827376,\n",
       " 'E11': 0.0030696223763282027,\n",
       " 'T86': 0.003015985508195964,\n",
       " 'E10': 0.002976412747669868,\n",
       " 'T31': 0.0029461321865340033,\n",
       " 'T115': 0.002894455116132707,\n",
       " 'T133': 0.0028257133627901387,\n",
       " 'T81': 0.002803719396863863,\n",
       " 'T25': 0.002758729050072848,\n",
       " 'T146': 0.0027532373429086632,\n",
       " 'T137': 0.0027499309445410776,\n",
       " 'T148': 0.00271623003290254,\n",
       " 'T73': 0.0026291709502393196,\n",
       " 'T47': 0.00257327607079316,\n",
       " 'T139': 0.0025561285658479665,\n",
       " 'DH24': 0.0024213750719800442,\n",
       " 'T98': 0.0023920985176227026,\n",
       " 'T140': 0.0023708944010163314,\n",
       " 'E4': 0.0023568110927169755,\n",
       " 'E94': 0.00234929142110685,\n",
       " 'T129': 0.0023480986450172977,\n",
       " 'T65': 0.0022792571201664027,\n",
       " 'DA28': 0.002179743899889076,\n",
       " 'E56': 0.0021226503110703386,\n",
       " 'T19': 0.0021140654475990993,\n",
       " 'T10': 0.002046237906983401,\n",
       " 'T45': 0.002043911575133003,\n",
       " 'E14': 0.002031820473185729,\n",
       " 'E78': 0.0019366490715936456,\n",
       " 'E28': 0.0019062147665833515,\n",
       " 'T46': 0.0018827349057233891,\n",
       " 'T1': 0.0017622251692237295,\n",
       " 'T85': 0.0017518820820272044,\n",
       " 'E7': 0.0017289661792776034,\n",
       " 'T105': 0.001725056821588439,\n",
       " 'T16': 0.0016977463929163889,\n",
       " 'E74': 0.0016741353073649271,\n",
       " 'T75': 0.0016208788302958166,\n",
       " 'T57': 0.001615389880336408,\n",
       " 'T3': 0.0015475572759719454,\n",
       " 'E164': 0.0015326802877745115,\n",
       " 'T4': 0.0015191242917588332,\n",
       " 'T41': 0.0014920089816946847,\n",
       " 'T92': 0.001483996499930184,\n",
       " 'T91': 0.001464205486051131,\n",
       " 'T18': 0.0014625128672443616,\n",
       " 'T134': 0.0014142191810191315,\n",
       " 'T15': 0.0014059652983413717,\n",
       " 'T30': 0.0013921413234229956,\n",
       " 'T106': 0.0013885056403377402,\n",
       " 'E150': 0.001362334839315505,\n",
       " 'E83': 0.0013106953629290056,\n",
       " 'T69': 0.0012944407293752642,\n",
       " 'DA56': 0.0012843426557061716,\n",
       " 'E108': 0.0012779425513205788,\n",
       " 'E122': 0.0012750524112700625,\n",
       " 'E41': 0.001272764212903648,\n",
       " 'T138': 0.0012428319153574919,\n",
       " 'E13': 0.0012210677128173329,\n",
       " 'T96': 0.0012118761185025038,\n",
       " 'T9': 0.0011645553984295906,\n",
       " 'E2': 0.0011380604302892922,\n",
       " 'T124': 0.0011374330242247804,\n",
       " 'E168': 0.001121242157758334,\n",
       " 'E64': 0.0011120622324926337,\n",
       " 'T24': 0.0010711858596925345,\n",
       " 'E8': 0.0010697727718883081,\n",
       " 'T11': 0.0010639930423068113,\n",
       " 'T12': 0.001057164517983091,\n",
       " 'T62': 0.0010554633000046964,\n",
       " 'T26': 0.0010340186944513836,\n",
       " 'E80': 0.001002219855212726,\n",
       " 'E30': 0.0009810875290320754,\n",
       " 'DH76': 0.0009551202117762204,\n",
       " 'T122': 0.000941471835912058,\n",
       " 'E5': 0.0009349926198055523,\n",
       " 'E37': 0.0009205572820082693,\n",
       " 'E22': 0.0009095978795878993,\n",
       " 'DA53': 0.0008300346284467908,\n",
       " 'E136': 0.0008174997321343243,\n",
       " 'DA44': 0.0008034018323616096,\n",
       " 'T27': 0.0007985216098080157,\n",
       " 'DH71': 0.0007891928945159975,\n",
       " 'DA14': 0.0007823314259474741,\n",
       " 'E42': 0.0007776994868418663,\n",
       " 'T23': 0.0007560619570649107,\n",
       " 'DH31': 0.0007478405371503715,\n",
       " 'E9': 0.0007362662801643914,\n",
       " 'E3': 0.0007202455241620682,\n",
       " 'DA38': 0.0007164933273012431,\n",
       " 'E60': 0.0007150628310142021,\n",
       " 'T33': 0.0007006064246009634,\n",
       " 'DA37': 0.0006895733122020556,\n",
       " 'DA52': 0.0006833257569216376,\n",
       " 'T34': 0.000682852657265226,\n",
       " 'E6': 0.0006801514276754835,\n",
       " 'DH23': 0.0006401045009496766,\n",
       " 'DH14': 0.0006028935205755372,\n",
       " 'DH46': 0.000586789296418057,\n",
       " 'DH90': 0.0005790029589873955,\n",
       " 'E57': 0.0005769754501352797,\n",
       " 'E16': 0.0005656097794277039,\n",
       " 'DH57': 0.0005631097693697352,\n",
       " 'DA8': 0.000561982782251895,\n",
       " 'DH42': 0.0005614751339714584,\n",
       " 'E27': 0.0005559978940196067,\n",
       " 'DH54': 0.0005522199286171983,\n",
       " 'DA3': 0.0005311665205894603,\n",
       " 'T8': 0.00053093153280547,\n",
       " 'DA91': 0.0005305766537773153,\n",
       " 'DH56': 0.0005295082083820097,\n",
       " 'T39': 0.0005292011379083246,\n",
       " 'DH3': 0.0005256423008512106,\n",
       " 'DH12': 0.0005249816159720769,\n",
       " 'T61': 0.0005200352218144691,\n",
       " 'E31': 0.0005166936109482947,\n",
       " 'DA42': 0.0005106854237658279,\n",
       " 'DH53': 0.0005077715800959467,\n",
       " 'DH36': 0.000505411898425134,\n",
       " 'DA54': 0.0005050115318126596,\n",
       " 'DA101': 0.0005022006739873406,\n",
       " 'DA97': 0.0004990116442338408,\n",
       " 'DH101': 0.000497408576826509,\n",
       " 'DA12': 0.0004929867929135825,\n",
       " 'DH100': 0.0004900738352060107,\n",
       " 'DA39': 0.0004893479627402946,\n",
       " 'E171': 0.0004840955859867702,\n",
       " 'E65': 0.0004834459855344154,\n",
       " 'DA31': 0.00047707157049471606,\n",
       " 'DA83': 0.0004752813878852896,\n",
       " 'T63': 0.0004702592919929932,\n",
       " 'DA22': 0.00046967282705385354,\n",
       " 'DA77': 0.00046947269490604153,\n",
       " 'DA65': 0.0004686947415195351,\n",
       " 'DH35': 0.00046420197952441245,\n",
       " 'DH51': 0.00045969647446924346,\n",
       " 'DA66': 0.0004584378586383319,\n",
       " 'DH4': 0.00045470678743567887,\n",
       " 'DA32': 0.0004547032413150387,\n",
       " 'DH62': 0.00045101825397865074,\n",
       " 'DA13': 0.0004503679561117596,\n",
       " 'DH1': 0.00044488492032146,\n",
       " 'DH72': 0.00044312423572484094,\n",
       " 'DH99': 0.000441436847399029,\n",
       " 'DH25': 0.0004403976622011112,\n",
       " 'DA11': 0.0004363004050464728,\n",
       " 'DH93': 0.00043331454235709193,\n",
       " 'DH59': 0.0004320038152023527,\n",
       " 'DH73': 0.00043165922700594446,\n",
       " 'DA2': 0.0004312789059673564,\n",
       " 'E90': 0.00042830296293027933,\n",
       " 'DH37': 0.00042615085546448986,\n",
       " 'DA104': 0.0004249221589398236,\n",
       " 'DA93': 0.00042244026820716844,\n",
       " 'T38': 0.0004217899776828512,\n",
       " 'T112': 0.0004206834709626088,\n",
       " 'DA41': 0.0004125681301839821,\n",
       " 'DA30': 0.0004119789996053805,\n",
       " 'DA50': 0.00041114786464532203,\n",
       " 'DH78': 0.0004091807037425915,\n",
       " 'DH27': 0.00040410539237088983,\n",
       " 'DA75': 0.0004030487156674549,\n",
       " 'DA10': 0.000398989450315328,\n",
       " 'DA35': 0.00039679231361748407,\n",
       " 'DH85': 0.0003958733869505519,\n",
       " 'E32': 0.0003935769725692395,\n",
       " 'DH79': 0.0003832248156991571,\n",
       " 'DH87': 0.0003766256944181031,\n",
       " 'DA49': 0.00037330321844039393,\n",
       " 'DA29': 0.00036938195612477837,\n",
       " 'T36': 0.00036804256177016414,\n",
       " 'DH10': 0.00036704322981978744,\n",
       " 'DA43': 0.00036468152000905605,\n",
       " 'DA9': 0.0003625662949973583,\n",
       " 'E39': 0.00036078367417130227,\n",
       " 'E147': 0.0003603079744236605,\n",
       " 'DA63': 0.00035368611529704234,\n",
       " 'DH92': 0.00035200151348925064,\n",
       " 'DH80': 0.0003519068925836213,\n",
       " 'DH39': 0.00035175022518694316,\n",
       " 'E35': 0.00034643458401254005,\n",
       " 'DH11': 0.0003421603975530197,\n",
       " 'DA36': 0.000341642728123503,\n",
       " 'DH8': 0.00033635492109540456,\n",
       " 'DH91': 0.0003354947538387699,\n",
       " 'DH65': 0.000334851665923041,\n",
       " 'DA16': 0.0003343552889782471,\n",
       " 'E92': 0.0003343159447427838,\n",
       " 'DH45': 0.0003341984746867124,\n",
       " 'DH7': 0.00033109086410619976,\n",
       " 'DA55': 0.00033052074452995743,\n",
       " 'E29': 0.000329880531172757,\n",
       " 'DH29': 0.00032967181492605185,\n",
       " 'DH9': 0.00032939639175090914,\n",
       " 'DA46': 0.00032907770853718064,\n",
       " 'DH50': 0.0003283733866914104,\n",
       " 'DH89': 0.00032812209357591283,\n",
       " 'DH30': 0.0003244407740649484,\n",
       " 'DA62': 0.00032268997400633313,\n",
       " 'E44': 0.00032103986508824124,\n",
       " 'DH32': 0.00031777889565734224,\n",
       " 'T109': 0.0003176808058214816,\n",
       " 'E38': 0.000315806360480838,\n",
       " 'DA78': 0.00031257590825814246,\n",
       " 'DH69': 0.0003111315380353913,\n",
       " 'E88': 0.00031081956169605717,\n",
       " 'E158': 0.00030955511739051353,\n",
       " 'DH102': 0.0003075604039294133,\n",
       " 'DH49': 0.0003070897313440617,\n",
       " 'DH61': 0.0003068675380461539,\n",
       " 'DH94': 0.0003055548009100164,\n",
       " 'T35': 0.0003046722120267569,\n",
       " 'DH16': 0.00030176320199340397,\n",
       " 'DA90': 0.0002996686244195426,\n",
       " 'DA92': 0.0002954956461634324,\n",
       " 'DA4': 0.0002950497156406862,\n",
       " 'DH86': 0.0002940429854012372,\n",
       " 'E91': 0.0002912015527566235,\n",
       " 'DH66': 0.00029044448845127313,\n",
       " 'DH22': 0.0002896841064930457,\n",
       " 'DH21': 0.0002881617625307822,\n",
       " 'DH2': 0.0002866545362844782,\n",
       " 'DA79': 0.0002865469999191368,\n",
       " 'DH84': 0.0002864177966655032,\n",
       " 'DA7': 0.00028456077920994077,\n",
       " 'DH13': 0.0002798607686786451,\n",
       " 'DH63': 0.00027815665302101183,\n",
       " 'E79': 0.0002760001263744764,\n",
       " 'T72': 0.0002740527357097996,\n",
       " 'DA71': 0.00027367961510944556,\n",
       " 'DH75': 0.0002706885690076842,\n",
       " 'DA40': 0.00026327486578459216,\n",
       " 'E68': 0.0002630142117404804,\n",
       " 'DA73': 0.0002619197262272528,\n",
       " 'T97': 0.0002613197382024835,\n",
       " 'DA1': 0.0002593199190917428,\n",
       " 'DH40': 0.00025917703500168534,\n",
       " 'DA27': 0.00025904041996027216,\n",
       " 'DH74': 0.0002579570401522346,\n",
       " 'DH38': 0.0002578622089751601,\n",
       " 'DA99': 0.00025740618233680143,\n",
       " 'E48': 0.0002559291411942921,\n",
       " 'DA45': 0.000252304215986771,\n",
       " 'E89': 0.00024226517292240117,\n",
       " 'E33': 0.00024068169231703388,\n",
       " 'DA5': 0.00023868962001143124,\n",
       " 'DA24': 0.00023306731064531502,\n",
       " 'E59': 0.0002319482955867838,\n",
       " 'DH43': 0.00022787236956086154,\n",
       " 'E85': 0.00022776901691911686,\n",
       " 'DA64': 0.00022687707334114992,\n",
       " 'DH58': 0.0002265146506611411,\n",
       " 'DA80': 0.0002208331042737383,\n",
       " 'DA76': 0.00021906356982806936,\n",
       " 'DA69': 0.00021709677031917575,\n",
       " 'DA72': 0.00021475338718790734,\n",
       " 'T79': 0.00021361775426190688,\n",
       " 'E50': 0.00021114675874091968,\n",
       " 'DA89': 0.00021110654636795123,\n",
       " 'E1': 0.00021086669345925685,\n",
       " 'DA60': 0.0002056519498672093,\n",
       " 'DA88': 0.00020258681149975256,\n",
       " 'DH41': 0.0002013041049025333,\n",
       " 'T5': 0.00019928264328061647,\n",
       " 'DH64': 0.0001987251665148959,\n",
       " 'DA85': 0.00019631363733727206,\n",
       " 'DH20': 0.00019475003189617422,\n",
       " 'DA33': 0.0001923795179042863,\n",
       " 'DA103': 0.0001923582058280894,\n",
       " 'E161': 0.0001923191238328,\n",
       " 'DH6': 0.00018978643696906483,\n",
       " 'DA51': 0.00018948518662713487,\n",
       " 'DA100': 0.00018662381932664257,\n",
       " 'DA21': 0.000184537107926513,\n",
       " 'E63': 0.00018295760413856549,\n",
       " 'T107': 0.00018222812712269395,\n",
       " 'T64': 0.00018106069813892775,\n",
       " 'E133': 0.000179418058931944,\n",
       " 'DA48': 0.0001768257878229618,\n",
       " 'E61': 0.00017563685302783954,\n",
       " 'DH77': 0.00017448686808625637,\n",
       " 'T6': 0.00016868702540130746,\n",
       " 'DH97': 0.00016426898570077447,\n",
       " 'DA25': 0.00015973873214164745,\n",
       " 'DA86': 0.00015848650486269456,\n",
       " 'DH96': 0.0001570854282212708,\n",
       " 'E173': 0.00015632111796307836,\n",
       " 'E40': 0.0001553700588888424,\n",
       " 'DH52': 0.00015090026622636716,\n",
       " 'E126': 0.0001488689654791352,\n",
       " 'DH70': 0.00014729210564030378,\n",
       " 'DH103': 0.00014544972429374466,\n",
       " 'DH44': 0.00013946199721331562,\n",
       " 'E138': 0.00013797539609907837,\n",
       " 'DH83': 0.00013508796968403702,\n",
       " 'E66': 0.00013207899440224717,\n",
       " 'E169': 0.00013200134644415038,\n",
       " 'DH48': 0.0001318974528914568,\n",
       " 'DA94': 0.0001317679061087395,\n",
       " 'E12': 0.00013134336653616236,\n",
       " 'E58': 0.00012895742032689798,\n",
       " 'E112': 0.0001231520555923758,\n",
       " 'DH98': 0.00011785373940766548,\n",
       " 'E55': 0.00011614748324436695,\n",
       " 'T117': 0.00011470852470815076,\n",
       " 'DH47': 0.00011393755704729903,\n",
       " 'E34': 0.00011360794563128447,\n",
       " 'T123': 0.00011267638295910798,\n",
       " 'T114': 0.00011195440179787625,\n",
       " 'DH88': 0.000111513310071279,\n",
       " 'T20': 0.00011005451418990993,\n",
       " 'E36': 0.0001097004185053621,\n",
       " 'E19': 0.00010778582770157702,\n",
       " 'E21': 0.00010642863110139962,\n",
       " 'T113': 0.00010308171180209018,\n",
       " 'DH60': 0.00010186930248019018,\n",
       " 'E20': 0.00010049433613447102,\n",
       " 'DH55': 9.900608519032766e-05,\n",
       " 'E132': 9.195104518378873e-05,\n",
       " 'DH34': 8.934631132774453e-05,\n",
       " 'T51': 8.915554083577384e-05,\n",
       " 'E162': 8.679505249369361e-05,\n",
       " 'E82': 8.66378483042806e-05,\n",
       " 'E110': 8.648964600757113e-05,\n",
       " 'DH19': 8.578171691861245e-05,\n",
       " 'E156': 8.41292730134256e-05,\n",
       " 'T71': 8.256999475592622e-05,\n",
       " 'DA74': 8.093730093993698e-05,\n",
       " 'DH17': 7.994238477471376e-05,\n",
       " 'T126': 7.905813559224648e-05,\n",
       " 'E149': 7.871180382917599e-05,\n",
       " 'DH18': 7.546619193355232e-05,\n",
       " 'E137': 7.539023419654704e-05,\n",
       " 'E115': 7.43254806342859e-05,\n",
       " 'E101': 7.3488451449092e-05,\n",
       " 'DA20': 7.170992239755645e-05,\n",
       " 'T68': 7.010033938673972e-05,\n",
       " 'DA17': 6.710483867199395e-05,\n",
       " 'E154': 6.669013619012764e-05,\n",
       " 'E131': 6.622452976493462e-05,\n",
       " 'E47': 6.577161720712146e-05,\n",
       " 'DA87': 6.554198626302368e-05,\n",
       " 'E130': 6.481332866483916e-05,\n",
       " 'DH15': 5.910199849449715e-05,\n",
       " 'E157': 5.829414657355438e-05,\n",
       " 'DA102': 5.8098493168682634e-05,\n",
       " 'T93': 5.7475709049486884e-05,\n",
       " 'E172': 5.4781965716690734e-05,\n",
       " 'T110': 5.4398351571812105e-05,\n",
       " 'T111': 5.0269566204221356e-05,\n",
       " 'DA34': 4.964495812949248e-05,\n",
       " 'DH68': 4.921839201007367e-05,\n",
       " 'DH82': 4.918808192196709e-05,\n",
       " 'T119': 4.82669222990491e-05,\n",
       " 'E125': 4.771629855426837e-05,\n",
       " 'DA58': 4.760016075806894e-05,\n",
       " 'E145': 4.587467926242216e-05,\n",
       " 'E81': 4.5799023650964386e-05,\n",
       " 'E116': 4.475292099138557e-05,\n",
       " 'E109': 4.391968906514206e-05,\n",
       " 'DA18': 4.247984453246511e-05,\n",
       " 'E140': 4.243737079325877e-05,\n",
       " 'E118': 4.233254065259703e-05,\n",
       " 'DH67': 3.710948724877875e-05,\n",
       " 'DA98': 3.7070755318655666e-05,\n",
       " 'DH26': 3.577768543186332e-05,\n",
       " 'DH33': 3.5485829802481336e-05,\n",
       " 'E105': 3.5302035048611666e-05,\n",
       " 'E139': 3.470885198716662e-05,\n",
       " 'T118': 3.409020764092151e-05,\n",
       " 'DH95': 3.115283663006459e-05,\n",
       " 'E93': 3.0328611125030506e-05,\n",
       " 'E111': 2.9909851354117654e-05,\n",
       " 'DA81': 2.9542215871950875e-05,\n",
       " 'T42': 2.875369823121251e-05,\n",
       " 'DA6': 2.768430223897818e-05,\n",
       " 'T120': 2.754553232595552e-05,\n",
       " 'DA19': 2.5975404489105694e-05,\n",
       " 'DH5': 2.389099197185455e-05,\n",
       " 'E98': 2.3533299347030077e-05,\n",
       " 'E155': 2.2755591735271844e-05,\n",
       " 'E141': 2.2720432051784424e-05,\n",
       " 'E72': 2.184871073394745e-05,\n",
       " 'E121': 2.1799688716332807e-05,\n",
       " 'DA96': 2.1350779733048074e-05,\n",
       " 'DA57': 2.1144769274868307e-05,\n",
       " 'E71': 2.03134028813335e-05,\n",
       " 'E84': 2.0067826526443773e-05,\n",
       " 'E165': 1.9439751066136975e-05,\n",
       " 'DA47': 1.9296159265263747e-05,\n",
       " 'DH81': 1.9096217414894906e-05,\n",
       " 'DA84': 1.8843882133877415e-05,\n",
       " 'E142': 1.813247320309424e-05,\n",
       " 'DA68': 1.7786889118153233e-05,\n",
       " 'E113': 1.7503548796570923e-05,\n",
       " 'E159': 1.707960893625548e-05,\n",
       " 'E102': 1.6887949199590255e-05,\n",
       " 'E104': 1.567416250115892e-05,\n",
       " 'E135': 1.547694716508649e-05,\n",
       " 'DA23': 1.510893098175047e-05,\n",
       " 'T108': 1.3865214519802001e-05,\n",
       " 'E148': 1.221035183236012e-05,\n",
       " 'E117': 1.1803656057990725e-05,\n",
       " 'E174': 1.1592325344445737e-05,\n",
       " 'E124': 1.0893455174371853e-05,\n",
       " 'E87': 1.0764858537859527e-05,\n",
       " 'T127': 1.0303747497803978e-05,\n",
       " 'E134': 1.0288288410668039e-05,\n",
       " 'E106': 1.0217520633020517e-05,\n",
       " 'E163': 9.906956010920682e-06,\n",
       " 'DA67': 9.015744564449247e-06,\n",
       " 'DA59': 8.79728685194212e-06,\n",
       " 'E120': 8.797213839323114e-06,\n",
       " 'DA95': 8.55957362587662e-06,\n",
       " 'E95': 8.497275157688548e-06,\n",
       " 'T125': 8.284223937881677e-06,\n",
       " 'E127': 7.859237638346149e-06,\n",
       " 'E153': 7.543179344864464e-06,\n",
       " 'E128': 7.302241423909126e-06,\n",
       " 'E123': 7.245937821994902e-06,\n",
       " 'E152': 6.909397976399602e-06,\n",
       " 'T70': 6.6935537433277155e-06,\n",
       " 'T21': 6.510698115066067e-06,\n",
       " 'E119': 6.237954351432784e-06,\n",
       " 'E170': 4.846018915421951e-06,\n",
       " 'E107': 4.638634735711464e-06,\n",
       " 'E146': 4.554868787694198e-06,\n",
       " 'E129': 4.468074405403062e-06,\n",
       " 'E96': 4.3484208930302594e-06,\n",
       " 'T103': 4.179754773137805e-06,\n",
       " 'DA82': 3.1267806224381118e-06,\n",
       " 'E103': 2.4875643945725095e-06,\n",
       " 'E86': 0.0,\n",
       " 'E97': 0.0,\n",
       " 'E99': 0.0,\n",
       " 'E100': 0.0,\n",
       " 'E114': 0.0,\n",
       " 'E143': 0.0,\n",
       " 'E144': 0.0,\n",
       " 'E151': 0.0,\n",
       " 'E160': 0.0,\n",
       " 'E166': 0.0,\n",
       " 'E167': 0.0,\n",
       " 'T80': 0.0,\n",
       " 'T94': 0.0,\n",
       " 'T121': 0.0,\n",
       " 'T128': 0.0,\n",
       " 'T135': 0.0,\n",
       " 'T136': 0.0,\n",
       " 'DA15': 0.0,\n",
       " 'DA26': 0.0,\n",
       " 'DA61': 0.0,\n",
       " 'DA70': 0.0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "lTx-5HFjDcoe",
    "outputId": "108c7726-a8ce-4d27-c811-6fa81a56430a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_features: 100\n",
      "the_rest_features 432\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(25,8))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "top_features = dict(list(imp_dict.items())[0:100])\n",
    "the_rest_features = dict(list(imp_dict.items())[100:])\n",
    "print(\"top_features:\", len(top_features))\n",
    "print(\"the_rest_features\", len(the_rest_features))\n",
    "ax.bar(top_features.keys(), top_features.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "0wqLMs85Dcof"
   },
   "outputs": [],
   "source": [
    "best_features_set_X = data_input[top_features]\n",
    "complete_set_X = data_input\n",
    "the_rest_set_X = data_input[the_rest_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "prnrDJZ4Dcof"
   },
   "outputs": [],
   "source": [
    "important_X_train, important_X_test, important_y_train, important_y_test = train_test_split(best_features_set_X, data_person, test_size=0.2, random_state=40)\n",
    "the_rest_X_train, the_rest_X_test, the_rest_y_train, the_rest_y_test = train_test_split(the_rest_set_X, data_person, test_size=0.2, random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHo5zIAIKSXF"
   },
   "source": [
    "### Korrelationsmatrix der wichtigsten Features\n",
    "Werte im positiven Bereich verdeutlichen eine positive Korrelation, Werte im negativen Bereich verdeutlichen eine negative Korrelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "63FTf8jZDcog",
    "outputId": "85cb4d01-03c2-4dd2-8803-36e324539624"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E67</th>\n",
       "      <th>T13</th>\n",
       "      <th>E69</th>\n",
       "      <th>T28</th>\n",
       "      <th>E76</th>\n",
       "      <th>E26</th>\n",
       "      <th>E75</th>\n",
       "      <th>E70</th>\n",
       "      <th>T2</th>\n",
       "      <th>E18</th>\n",
       "      <th>...</th>\n",
       "      <th>T148</th>\n",
       "      <th>T73</th>\n",
       "      <th>T47</th>\n",
       "      <th>T139</th>\n",
       "      <th>DH24</th>\n",
       "      <th>T98</th>\n",
       "      <th>T140</th>\n",
       "      <th>E4</th>\n",
       "      <th>E94</th>\n",
       "      <th>T129</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E67</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001277</td>\n",
       "      <td>0.997368</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.945858</td>\n",
       "      <td>-0.775504</td>\n",
       "      <td>0.925112</td>\n",
       "      <td>0.981906</td>\n",
       "      <td>0.012326</td>\n",
       "      <td>-0.782538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179374</td>\n",
       "      <td>-0.042839</td>\n",
       "      <td>0.086626</td>\n",
       "      <td>-0.056974</td>\n",
       "      <td>0.270871</td>\n",
       "      <td>-0.058546</td>\n",
       "      <td>-0.065076</td>\n",
       "      <td>0.199101</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>-0.025968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T13</th>\n",
       "      <td>-0.001277</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001943</td>\n",
       "      <td>0.998012</td>\n",
       "      <td>0.070766</td>\n",
       "      <td>-0.129117</td>\n",
       "      <td>-0.078108</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.946986</td>\n",
       "      <td>-0.116752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050556</td>\n",
       "      <td>-0.015682</td>\n",
       "      <td>-0.095695</td>\n",
       "      <td>-0.019972</td>\n",
       "      <td>0.289603</td>\n",
       "      <td>-0.020452</td>\n",
       "      <td>-0.022206</td>\n",
       "      <td>0.082118</td>\n",
       "      <td>0.321773</td>\n",
       "      <td>-0.011303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E69</th>\n",
       "      <td>0.997368</td>\n",
       "      <td>-0.001943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.948364</td>\n",
       "      <td>-0.772436</td>\n",
       "      <td>0.924621</td>\n",
       "      <td>0.989386</td>\n",
       "      <td>0.012655</td>\n",
       "      <td>-0.784590</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.176232</td>\n",
       "      <td>-0.039939</td>\n",
       "      <td>0.080450</td>\n",
       "      <td>-0.053803</td>\n",
       "      <td>0.270584</td>\n",
       "      <td>-0.055391</td>\n",
       "      <td>-0.062050</td>\n",
       "      <td>0.199396</td>\n",
       "      <td>0.021863</td>\n",
       "      <td>-0.022744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T28</th>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.998012</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070359</td>\n",
       "      <td>-0.127175</td>\n",
       "      <td>-0.073263</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>0.936717</td>\n",
       "      <td>-0.114361</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049788</td>\n",
       "      <td>-0.015677</td>\n",
       "      <td>-0.091890</td>\n",
       "      <td>-0.019850</td>\n",
       "      <td>0.267234</td>\n",
       "      <td>-0.020324</td>\n",
       "      <td>-0.022046</td>\n",
       "      <td>0.081241</td>\n",
       "      <td>0.310972</td>\n",
       "      <td>-0.011353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E76</th>\n",
       "      <td>0.945858</td>\n",
       "      <td>0.070766</td>\n",
       "      <td>0.948364</td>\n",
       "      <td>0.070359</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.809610</td>\n",
       "      <td>0.773102</td>\n",
       "      <td>0.935783</td>\n",
       "      <td>0.086990</td>\n",
       "      <td>-0.814641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181989</td>\n",
       "      <td>-0.041786</td>\n",
       "      <td>0.073580</td>\n",
       "      <td>-0.056429</td>\n",
       "      <td>0.294010</td>\n",
       "      <td>-0.057997</td>\n",
       "      <td>-0.064850</td>\n",
       "      <td>0.293801</td>\n",
       "      <td>0.207897</td>\n",
       "      <td>-0.023863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T98</th>\n",
       "      <td>-0.058546</td>\n",
       "      <td>-0.020452</td>\n",
       "      <td>-0.055391</td>\n",
       "      <td>-0.020324</td>\n",
       "      <td>-0.057997</td>\n",
       "      <td>0.021443</td>\n",
       "      <td>-0.050275</td>\n",
       "      <td>-0.051615</td>\n",
       "      <td>-0.022052</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316297</td>\n",
       "      <td>0.974793</td>\n",
       "      <td>0.032712</td>\n",
       "      <td>0.999794</td>\n",
       "      <td>-0.047201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994967</td>\n",
       "      <td>-0.038212</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.944664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T140</th>\n",
       "      <td>-0.065076</td>\n",
       "      <td>-0.022206</td>\n",
       "      <td>-0.062050</td>\n",
       "      <td>-0.022046</td>\n",
       "      <td>-0.064850</td>\n",
       "      <td>0.026424</td>\n",
       "      <td>-0.056157</td>\n",
       "      <td>-0.057970</td>\n",
       "      <td>-0.024005</td>\n",
       "      <td>0.027624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318571</td>\n",
       "      <td>0.954385</td>\n",
       "      <td>0.025335</td>\n",
       "      <td>0.993628</td>\n",
       "      <td>-0.051787</td>\n",
       "      <td>0.994967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.040267</td>\n",
       "      <td>0.050943</td>\n",
       "      <td>0.909811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E4</th>\n",
       "      <td>0.199101</td>\n",
       "      <td>0.082118</td>\n",
       "      <td>0.199396</td>\n",
       "      <td>0.081241</td>\n",
       "      <td>0.293801</td>\n",
       "      <td>-0.196630</td>\n",
       "      <td>0.058653</td>\n",
       "      <td>0.204750</td>\n",
       "      <td>0.097517</td>\n",
       "      <td>-0.195732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080655</td>\n",
       "      <td>-0.030916</td>\n",
       "      <td>0.035548</td>\n",
       "      <td>-0.037495</td>\n",
       "      <td>0.152844</td>\n",
       "      <td>-0.038212</td>\n",
       "      <td>-0.040267</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058721</td>\n",
       "      <td>-0.025441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E94</th>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.321773</td>\n",
       "      <td>0.021863</td>\n",
       "      <td>0.310972</td>\n",
       "      <td>0.207897</td>\n",
       "      <td>-0.322703</td>\n",
       "      <td>-0.201856</td>\n",
       "      <td>0.030433</td>\n",
       "      <td>0.310670</td>\n",
       "      <td>-0.306751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009074</td>\n",
       "      <td>0.050917</td>\n",
       "      <td>-0.101848</td>\n",
       "      <td>0.052052</td>\n",
       "      <td>0.150330</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.050943</td>\n",
       "      <td>0.058721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T129</th>\n",
       "      <td>-0.025968</td>\n",
       "      <td>-0.011303</td>\n",
       "      <td>-0.022744</td>\n",
       "      <td>-0.011353</td>\n",
       "      <td>-0.023863</td>\n",
       "      <td>-0.002820</td>\n",
       "      <td>-0.022106</td>\n",
       "      <td>-0.020277</td>\n",
       "      <td>-0.012014</td>\n",
       "      <td>-0.002153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258076</td>\n",
       "      <td>0.983062</td>\n",
       "      <td>0.048992</td>\n",
       "      <td>0.948191</td>\n",
       "      <td>-0.023893</td>\n",
       "      <td>0.944664</td>\n",
       "      <td>0.909811</td>\n",
       "      <td>-0.025441</td>\n",
       "      <td>0.052527</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           E67       T13       E69       T28       E76       E26       E75  \\\n",
       "E67   1.000000 -0.001277  0.997368  0.000941  0.945858 -0.775504  0.925112   \n",
       "T13  -0.001277  1.000000 -0.001943  0.998012  0.070766 -0.129117 -0.078108   \n",
       "E69   0.997368 -0.001943  1.000000  0.000077  0.948364 -0.772436  0.924621   \n",
       "T28   0.000941  0.998012  0.000077  1.000000  0.070359 -0.127175 -0.073263   \n",
       "E76   0.945858  0.070766  0.948364  0.070359  1.000000 -0.809610  0.773102   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "T98  -0.058546 -0.020452 -0.055391 -0.020324 -0.057997  0.021443 -0.050275   \n",
       "T140 -0.065076 -0.022206 -0.062050 -0.022046 -0.064850  0.026424 -0.056157   \n",
       "E4    0.199101  0.082118  0.199396  0.081241  0.293801 -0.196630  0.058653   \n",
       "E94   0.014194  0.321773  0.021863  0.310972  0.207897 -0.322703 -0.201856   \n",
       "T129 -0.025968 -0.011303 -0.022744 -0.011353 -0.023863 -0.002820 -0.022106   \n",
       "\n",
       "           E70        T2       E18  ...      T148       T73       T47  \\\n",
       "E67   0.981906  0.012326 -0.782538  ... -0.179374 -0.042839  0.086626   \n",
       "T13   0.000659  0.946986 -0.116752  ... -0.050556 -0.015682 -0.095695   \n",
       "E69   0.989386  0.012655 -0.784590  ... -0.176232 -0.039939  0.080450   \n",
       "T28   0.002312  0.936717 -0.114361  ... -0.049788 -0.015677 -0.091890   \n",
       "E76   0.935783  0.086990 -0.814641  ... -0.181989 -0.041786  0.073580   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "T98  -0.051615 -0.022052  0.022472  ...  0.316297  0.974793  0.032712   \n",
       "T140 -0.057970 -0.024005  0.027624  ...  0.318571  0.954385  0.025335   \n",
       "E4    0.204750  0.097517 -0.195732  ... -0.080655 -0.030916  0.035548   \n",
       "E94   0.030433  0.310670 -0.306751  ... -0.009074  0.050917 -0.101848   \n",
       "T129 -0.020277 -0.012014 -0.002153  ...  0.258076  0.983062  0.048992   \n",
       "\n",
       "          T139      DH24       T98      T140        E4       E94      T129  \n",
       "E67  -0.056974  0.270871 -0.058546 -0.065076  0.199101  0.014194 -0.025968  \n",
       "T13  -0.019972  0.289603 -0.020452 -0.022206  0.082118  0.321773 -0.011303  \n",
       "E69  -0.053803  0.270584 -0.055391 -0.062050  0.199396  0.021863 -0.022744  \n",
       "T28  -0.019850  0.267234 -0.020324 -0.022046  0.081241  0.310972 -0.011353  \n",
       "E76  -0.056429  0.294010 -0.057997 -0.064850  0.293801  0.207897 -0.023863  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "T98   0.999794 -0.047201  1.000000  0.994967 -0.038212  0.052000  0.944664  \n",
       "T140  0.993628 -0.051787  0.994967  1.000000 -0.040267  0.050943  0.909811  \n",
       "E4   -0.037495  0.152844 -0.038212 -0.040267  1.000000  0.058721 -0.025441  \n",
       "E94   0.052052  0.150330  0.052000  0.050943  0.058721  1.000000  0.052527  \n",
       "T129  0.948191 -0.023893  0.944664  0.909811 -0.025441  0.052527  1.000000  \n",
       "\n",
       "[100 rows x 100 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_set_X.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimierungen groÃŸes ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/sabrinagreifzu/Documents/Masterstudium Data Science/Machine Learning und Deep Learning/Thomas/activity_recognition_with_index 3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition eines Ablageorts fÃ¼r das spÃ¤tere Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_models = '../models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitten der Daten in Features, die Zielvariable 'class' und die Group-Variable \"Person\"\n",
    "data_input = data.drop(['Person', 'class'], axis = 1)\n",
    "data_person = data['Person']\n",
    "data_labels_raw = data['class']\n",
    "\n",
    "# Splitten der Daten in Trainings- und Testset\n",
    "train_data, test_data, train_labels_raw, test_labels_raw = train_test_split(\n",
    "                      data_input, data_labels_raw, test_size = 0.1, random_state=123)\n",
    "\n",
    "# Skalieren der Daten, um sicherzustellen, dass jede Variable den gleichen Einfluss auf das Endergebnis hat\n",
    "scaler = MinMaxScaler().fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)\n",
    "\n",
    "# One-hot-encoding \n",
    "encoder = LabelBinarizer().fit(train_labels_raw)\n",
    "train_labels = encoder.transform(train_labels_raw)\n",
    "test_labels = encoder.transform(test_labels_raw)\n",
    "\n",
    "\n",
    "#Extrahieren von Features und Zielvariable\n",
    "n_attributes = data_input.shape[1]\n",
    "n_classes = train_labels.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erstellung des Neuronalen Netzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMyANN(hyperparams):\n",
    "\n",
    "    #Hyperparameter fÃ¼r Keras-Tuner\n",
    "    hp_units = hyperparams.Int('units', min_value=500, max_value=600, step=20)\n",
    "    hp_activations = hyperparams.Choice('activation', values=['relu', 'tanh', 'elu'])\n",
    "    hp_lr = hyperparams.Choice('learning_rate', values=[0.01, 0.05, 0.001, 0.005, 0.0001, 0.0005])\n",
    "    hp_nbr_hidden_layers = hyperparams.Int('nbr_hidden_layers', min_value=2, max_value=4, step=1)\n",
    "\n",
    "    model = Sequential()  \n",
    "    model.add( InputLayer(input_shape=(n_attributes, ), name=\"input_1D_vector\")) \n",
    "\n",
    "    for i in range(hp_nbr_hidden_layers):\n",
    "        model.add( Dense(units=hp_units, activation=hp_activations,\n",
    "                             name=\"hidden\" +str(i)+ \"_\" +str(hp_units)+ \"nodes\")) #hidden layer\n",
    "\n",
    "\n",
    "    model.add( Dense(units=n_classes, activation='softmax', name=\"output_softmax\"))\n",
    "    \n",
    "    optim = Adam(learning_rate = hp_lr) \n",
    "    \n",
    "    #model.compile(loss='mse', optimizer=optim, metrics=['accuracy'])\n",
    "    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=optim, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verwendung des Keras-Tuners zur ErschlieÃŸung der besten Hyperparameter-Kombination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project ../models/ann_512_opt/ann_512_opt/oracle.json\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "INFO:tensorflow:Reloading Tuner from ../models/ann_512_opt/ann_512_opt/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "keras_tuner = RandomSearch(\n",
    "    createMyANN, \n",
    "    objective= 'val_accuracy', \n",
    "    max_trials=20,  \n",
    "    executions_per_trial=1,  \n",
    "    directory= path_models + 'ann_512_opt',\n",
    "    project_name='ann_512_opt')\n",
    "\n",
    "import time\n",
    "time_start = time.time()\n",
    "\n",
    "\n",
    "keras_tuner.search(train_data, train_labels, validation_split=0.1, \n",
    "             epochs=500, verbose=2,\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=50,\n",
    "                                                      restore_best_weights=True)])\n",
    "\n",
    "time_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for model training: 0:0:0 [h:m:s]\n"
     ]
    }
   ],
   "source": [
    "hours = (time_end - time_start) // 3600\n",
    "minutes = ((time_end - time_start) % 3600) // 60\n",
    "seconds = round((time_end - time_start - hours * 3600 - minutes * 60), 0)\n",
    "print(f\"Elapsed time for model training: {int(hours)}:{int(minutes)}:{int(seconds)} [h:m:s]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beste Hyperparameter-Kombination aus dem Keras-Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparamters:\n",
      "{'units': 520, 'activation': 'relu', 'learning_rate': 0.0005, 'nbr_hidden_layers': 3}\n",
      "Results summary\n",
      "Results in ../models/ann_512_opt/ann_512_opt\n",
      "Showing 1 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 520\n",
      "activation: relu\n",
      "learning_rate: 0.0005\n",
      "nbr_hidden_layers: 3\n",
      "Score: 0.9876237511634827\n",
      "Best model:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden0_520nodes (Dense)     (None, 520)               277680    \n",
      "_________________________________________________________________\n",
      "hidden1_520nodes (Dense)     (None, 520)               270920    \n",
      "_________________________________________________________________\n",
      "hidden2_520nodes (Dense)     (None, 520)               270920    \n",
      "_________________________________________________________________\n",
      "output_softmax (Dense)       (None, 4)                 2084      \n",
      "=================================================================\n",
      "Total params: 821,604\n",
      "Trainable params: 821,604\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#keras_tuner.search_space_summary()\n",
    "\n",
    "hyperparams_best = keras_tuner.get_best_hyperparameters()[0].values\n",
    "\n",
    "print(\"Best hyperparamters:\")\n",
    "print(hyperparams_best)\n",
    "\n",
    "keras_tuner.results_summary(1)\n",
    "\n",
    "model = keras_tuner.get_best_models(num_models=1)[0] \n",
    "print(\"Best model:\")\n",
    "model.summary() \n",
    "\n",
    "tf.keras.utils.plot_model(model)\n",
    "\n",
    "model.save(path_models + \"ann_512_opt.h5\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'units': 520, 'activation': 'relu', 'learning_rate': 0.0005, 'nbr_hidden_layers': 3}\n"
     ]
    }
   ],
   "source": [
    "print(hyperparams_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anwendung des Modells auf Testdatensatz und Ausgabe der Accuracy sowie Visualisierung der Ergebnisse Ã¼ber Confusion-Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Results auf test data #########\n",
      "Accuracy (test):  0.9665178571428571\n",
      "[[104   1   2   0]\n",
      " [  0 101   7   0]\n",
      " [  0   5 101   0]\n",
      " [  0   0   0 127]]\n"
     ]
    }
   ],
   "source": [
    "# classification of test set\n",
    "print(\"######## Results auf test data #########\")\n",
    "pred = model.predict(test_data)\n",
    "predictions = np.argmax(model.predict(test_data), axis=-1)  # neural network outputs to classes\n",
    "cm = confusion_matrix(test_labels_raw, predictions+1)\n",
    "\n",
    "acc = accuracy_score(test_labels_raw, predictions+1)\n",
    "print(\"Accuracy (test): \", acc)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimierungen Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/sabrinagreifzu/Documents/Masterstudium Data Science/Machine Learning und Deep Learning/Thomas/activity_recognition_with_index 3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition eines Ablageorts fÃ¼r das spÃ¤tere Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_models = '../models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitten in Features, Zielvarialbe 'class' und Group-Variable 'Person'\n",
    "data_input = data.drop(['Person', 'class'], axis = 1)\n",
    "data_person = data['Person']\n",
    "data_labels_raw = data['class']\n",
    "\n",
    "## Splitten der Daten in Trainings- und Test-Set\n",
    "train_data, test_data, train_labels_raw, test_labels_raw = train_test_split(\n",
    "                      data_input, data_labels_raw, test_size = 0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One-hot-encoding \n",
    "encoder = LabelBinarizer().fit(train_labels_raw)\n",
    "train_labels = encoder.transform(train_labels_raw)\n",
    "test_labels = encoder.transform(test_labels_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition des Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc=RandomForestClassifier(random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anwendung von GridSearchCV zur ErschlieÃŸung der besten Parameterkombination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=100; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=100; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=100; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=100; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=100; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=200; total time=   3.5s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=200; total time=   3.4s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=200; total time=   3.4s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=200; total time=   3.4s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=200; total time=   3.5s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=500; total time=   9.4s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=500; total time=   9.6s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=500; total time=  10.2s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=500; total time=   8.8s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=500; total time=   9.1s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200; total time=   4.0s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200; total time=   3.7s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200; total time=   4.0s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200; total time=   4.3s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=500; total time=  10.4s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=500; total time=  10.7s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=500; total time=   9.3s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=500; total time=   8.6s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=500; total time=   8.6s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=500; total time=   4.1s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=500; total time=   4.1s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=500; total time=   4.1s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=500; total time=   4.1s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=500; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=100; total time=   2.1s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=100; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=100; total time=   2.1s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=100; total time=   2.2s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=100; total time=   2.1s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=200; total time=   4.2s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=200; total time=   4.2s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=200; total time=   4.1s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=200; total time=   4.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=200; total time=   4.1s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=500; total time=  10.1s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=500; total time=  10.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=500; total time=  10.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=500; total time=  10.2s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=500; total time=  10.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100; total time=   2.1s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200; total time=   4.1s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200; total time=   4.1s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200; total time=   4.1s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200; total time=   4.1s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200; total time=   4.1s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=500; total time=  10.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=500; total time=  10.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=500; total time=  10.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=500; total time=  10.1s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=500; total time=  10.1s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=200; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=200; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=200; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=200; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=200; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=500; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=500; total time=   4.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=500; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=500; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=500; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=auto, n_estimators=100; total time=   2.3s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=auto, n_estimators=100; total time=   2.3s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=auto, n_estimators=100; total time=   2.3s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=auto, n_estimators=100; total time=   2.3s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=auto, n_estimators=100; total time=   2.3s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=auto, n_estimators=200; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=auto, n_estimators=200; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=auto, n_estimators=200; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=auto, n_estimators=200; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=auto, n_estimators=200; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=auto, n_estimators=500; total time=  11.4s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=auto, n_estimators=500; total time=  11.3s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=auto, n_estimators=500; total time=  11.4s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=auto, n_estimators=500; total time=  11.4s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=auto, n_estimators=500; total time=  12.7s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=100; total time=   2.3s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=100; total time=   2.3s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=100; total time=   2.3s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=100; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=100; total time=   2.8s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=500; total time=  11.3s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=500; total time=  11.3s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=500; total time=  11.2s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=500; total time=  11.3s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=500; total time=  11.5s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=log2, n_estimators=100; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=log2, n_estimators=100; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=log2, n_estimators=100; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=log2, n_estimators=100; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=log2, n_estimators=100; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=log2, n_estimators=200; total time=   2.2s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=log2, n_estimators=200; total time=   2.1s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=log2, n_estimators=200; total time=   2.2s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=log2, n_estimators=200; total time=   2.1s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=log2, n_estimators=200; total time=   2.1s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=log2, n_estimators=500; total time=   5.3s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=log2, n_estimators=500; total time=   5.2s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=log2, n_estimators=500; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=log2, n_estimators=500; total time=   5.3s\n",
      "[CV] END criterion=gini, max_depth=6, max_features=log2, n_estimators=500; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=auto, n_estimators=100; total time=   2.8s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=auto, n_estimators=100; total time=   2.6s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=auto, n_estimators=100; total time=   2.6s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=auto, n_estimators=100; total time=   2.6s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=auto, n_estimators=100; total time=   2.6s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=auto, n_estimators=200; total time=   5.1s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=auto, n_estimators=200; total time=   5.1s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=auto, n_estimators=200; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=auto, n_estimators=200; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=auto, n_estimators=200; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=auto, n_estimators=500; total time=  12.6s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=auto, n_estimators=500; total time=  12.5s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=auto, n_estimators=500; total time=  13.5s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=auto, n_estimators=500; total time=  12.5s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=auto, n_estimators=500; total time=  12.5s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=100; total time=   2.5s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=100; total time=   2.5s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=100; total time=   2.5s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=100; total time=   2.5s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=100; total time=   2.5s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200; total time=   5.1s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200; total time=   5.1s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=500; total time=  12.5s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=500; total time=  12.4s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=500; total time=  12.5s\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "[CV] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=500; total time=  12.6s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=500; total time=  12.5s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=log2, n_estimators=100; total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=7, max_features=log2, n_estimators=100; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=log2, n_estimators=100; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=log2, n_estimators=100; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=log2, n_estimators=100; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=log2, n_estimators=200; total time=   2.4s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=log2, n_estimators=200; total time=   2.4s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=log2, n_estimators=200; total time=   2.4s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=log2, n_estimators=200; total time=   2.3s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=log2, n_estimators=200; total time=   2.3s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=log2, n_estimators=500; total time=   5.8s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=log2, n_estimators=500; total time=   6.6s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=log2, n_estimators=500; total time=   6.7s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=log2, n_estimators=500; total time=   5.8s\n",
      "[CV] END criterion=gini, max_depth=7, max_features=log2, n_estimators=500; total time=   5.8s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=auto, n_estimators=100; total time=   2.7s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=auto, n_estimators=100; total time=   2.7s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=auto, n_estimators=100; total time=   2.7s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=auto, n_estimators=100; total time=   2.8s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=auto, n_estimators=100; total time=   2.7s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=auto, n_estimators=200; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=auto, n_estimators=200; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=auto, n_estimators=200; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=auto, n_estimators=200; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=auto, n_estimators=200; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=auto, n_estimators=500; total time=  13.5s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=auto, n_estimators=500; total time=  13.4s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=auto, n_estimators=500; total time=  13.5s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=auto, n_estimators=500; total time=  14.0s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=auto, n_estimators=500; total time=  13.5s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=100; total time=   2.7s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=100; total time=   2.7s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=100; total time=   2.7s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=100; total time=   2.8s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=100; total time=   2.8s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=200; total time=   5.5s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=200; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=200; total time=   5.3s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=200; total time=   5.7s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=200; total time=   5.6s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=500; total time=  13.6s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=500; total time=  13.5s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=500; total time=  13.7s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=500; total time=  13.5s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=500; total time=  14.2s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=log2, n_estimators=100; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=log2, n_estimators=100; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=log2, n_estimators=100; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=log2, n_estimators=100; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=log2, n_estimators=100; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=log2, n_estimators=200; total time=   2.5s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=log2, n_estimators=200; total time=   2.5s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=log2, n_estimators=200; total time=   2.5s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=log2, n_estimators=200; total time=   2.5s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=log2, n_estimators=200; total time=   2.5s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=log2, n_estimators=500; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=log2, n_estimators=500; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=log2, n_estimators=500; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=log2, n_estimators=500; total time=   6.1s\n",
      "[CV] END criterion=gini, max_depth=8, max_features=log2, n_estimators=500; total time=   6.2s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=100; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=100; total time=   4.1s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=100; total time=   3.8s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=100; total time=   3.6s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=100; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=200; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=200; total time=   6.9s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=200; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=200; total time=   6.9s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=200; total time=   6.9s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=500; total time=  17.3s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=500; total time=  17.5s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=500; total time=  17.2s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=500; total time=  17.2s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=500; total time=  17.3s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100; total time=   3.7s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200; total time=   6.9s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200; total time=   6.9s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200; total time=   6.9s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200; total time=   6.9s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200; total time=   6.9s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=500; total time=  17.7s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=500; total time=  17.2s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=500; total time=  17.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=500; total time=  17.8s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=500; total time=  17.2s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100; total time=   1.5s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100; total time=   1.5s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100; total time=   1.5s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100; total time=   1.5s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100; total time=   1.5s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200; total time=   3.0s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200; total time=   3.0s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200; total time=   3.0s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200; total time=   3.0s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200; total time=   3.0s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=500; total time=   7.5s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=500; total time=   7.5s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=500; total time=   7.5s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=500; total time=   7.8s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=500; total time=   7.5s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=100; total time=   4.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=100; total time=   4.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=100; total time=   4.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=100; total time=   4.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=100; total time=   4.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=200; total time=   8.0s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=200; total time=   8.0s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=200; total time=   8.0s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=200; total time=   8.5s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=200; total time=   8.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=500; total time=  20.9s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=500; total time=  20.3s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=500; total time=  20.0s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=500; total time=  20.2s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=500; total time=  20.2s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100; total time=   4.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100; total time=   4.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100; total time=   4.2s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100; total time=   5.0s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100; total time=   4.3s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200; total time=   8.6s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200; total time=   8.0s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200; total time=   8.0s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200; total time=   8.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200; total time=   8.2s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=500; total time=  20.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=500; total time=  20.4s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=500; total time=  20.0s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=500; total time=  20.2s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=500; total time=  20.3s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=200; total time=   3.6s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=200; total time=   3.6s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=200; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=200; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=200; total time=   4.0s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=500; total time=   9.4s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=500; total time=   8.8s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=500; total time=   8.7s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=500; total time=   8.7s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=500; total time=   8.8s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=100; total time=   4.6s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=100; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=100; total time=   4.6s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=100; total time=   4.6s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=100; total time=   4.6s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=200; total time=   9.1s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=200; total time=   9.6s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=200; total time=   9.0s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=200; total time=   9.1s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=200; total time=   9.1s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=500; total time=  22.6s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=500; total time=  22.6s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=500; total time=  22.8s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=500; total time=  22.6s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=500; total time=  22.9s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=100; total time=   5.5s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=100; total time=   5.4s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=100; total time=   5.1s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=100; total time=   4.9s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=100; total time=   4.6s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200; total time=   9.0s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200; total time=   9.0s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200; total time=   9.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200; total time=   9.3s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200; total time=   9.4s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=500; total time=  23.2s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=500; total time=  22.7s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=500; total time=  22.8s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=500; total time=  22.6s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=500; total time=  22.7s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=100; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=100; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=100; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=100; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=100; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=200; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=200; total time=   4.0s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=200; total time=   3.9s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=200; total time=   4.0s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=200; total time=   4.0s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=500; total time=   9.9s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=500; total time=   9.9s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=500; total time=   9.9s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=500; total time=  10.2s\n",
      "[CV] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=500; total time=   9.9s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=100; total time=   5.0s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=100; total time=   4.9s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=100; total time=   5.0s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=100; total time=   5.0s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=100; total time=   5.0s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=200; total time=   9.9s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=200; total time=  10.0s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=200; total time=   9.9s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=200; total time=   9.9s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=200; total time=  10.0s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=500; total time=  25.3s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=500; total time=  25.1s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=500; total time=  24.8s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=500; total time=  24.9s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=500; total time=  24.9s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=100; total time=   5.0s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=100; total time=   5.0s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=100; total time=   5.1s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=100; total time=   5.0s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=100; total time=   5.0s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200; total time=  10.4s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200; total time=   9.9s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200; total time=   9.9s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200; total time=   9.9s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200; total time=  10.2s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=500; total time=  25.8s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=500; total time=  24.8s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=500; total time=  24.8s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=500; total time=  26.5s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=500; total time=  24.9s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=100; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=100; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=100; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=100; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=100; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=200; total time=   4.4s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=200; total time=   4.4s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=200; total time=   4.4s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=200; total time=   4.3s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=200; total time=   4.4s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=500; total time=  10.8s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=500; total time=  11.6s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=500; total time=  10.8s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=500; total time=  10.8s\n",
      "[CV] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=500; total time=  10.8s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=100; total time=   5.4s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=100; total time=   5.4s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=100; total time=   5.4s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=100; total time=   5.4s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=100; total time=   5.4s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=200; total time=  10.8s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=200; total time=  10.7s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=200; total time=  10.7s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=200; total time=  10.7s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=200; total time=  10.8s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=500; total time=  27.7s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=500; total time=  27.3s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=500; total time=  26.7s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=500; total time=  26.9s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=500; total time=  27.7s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=100; total time=   5.4s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=100; total time=   5.3s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=100; total time=   5.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=100; total time=   5.4s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=100; total time=   5.4s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=200; total time=  10.7s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=200; total time=  10.8s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=200; total time=  10.7s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=200; total time=  10.7s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=200; total time=  10.8s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=500; total time=  27.4s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=500; total time=  26.9s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=500; total time=  27.5s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=500; total time=  26.9s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=500; total time=  28.2s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=100; total time=   2.4s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=100; total time=   2.4s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=100; total time=   2.4s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=100; total time=   2.4s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=100; total time=   2.4s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=200; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=200; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=200; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=200; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=200; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=500; total time=  12.2s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=500; total time=  12.6s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=500; total time=  11.6s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=500; total time=  11.8s\n",
      "[CV] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=500; total time=  11.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=123),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [4, 5, 6, 7, 8],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [100, 200, 500]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5, verbose = 2)\n",
    "CV_rfc.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beste Parameterkombination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 8,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veranschaulichung der Ã¼ber GridSearchCV gestesteten Parameterkombinationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 1.7620863 ,  3.39702034,  9.27459826,  1.91341119,  4.12820497,\n",
       "         9.37126245,  0.8509984 ,  1.64705896,  4.04534678,  2.0731215 ,\n",
       "         4.08271098,  9.91668029,  2.00891275,  4.00563006,  9.90093069,\n",
       "         0.94831595,  1.85295401,  4.59812369,  2.28053889,  4.53820782,\n",
       "        11.50473514,  2.52429295,  4.50959892, 11.18018188,  1.08841467,\n",
       "         2.09206862,  5.15874143,  2.57160311,  4.98416996, 12.56315265,\n",
       "         2.48222446,  4.98209491, 12.33617744,  1.18997779,  2.29480391,\n",
       "         5.96687384,  2.69078269,  5.33685799, 13.43456917,  2.71346793,\n",
       "         5.42939596, 13.53506608,  1.25683279,  2.44850335,  6.02273593,\n",
       "         3.65534301,  6.8914546 , 17.14719958,  3.51151834,  6.84951081,\n",
       "        17.28526082,  1.48893309,  2.97565637,  7.43204975,  4.05249338,\n",
       "         8.07518392, 20.1519742 ,  4.28090029,  8.13873734, 20.06441932,\n",
       "         1.75569105,  3.58071609,  8.73402901,  4.52807355,  9.12060146,\n",
       "        22.56086841,  5.08499761,  9.08529072, 22.66333046,  1.96831908,\n",
       "         3.99750662,  9.78272076,  4.94052095,  9.87225575, 24.85533013,\n",
       "         4.97316976, 10.01376376, 25.22486038,  2.17048292,  4.30782614,\n",
       "        10.82302337,  5.36406302, 10.68246403, 27.13129563,  5.33851795,\n",
       "        10.67848301, 27.22934442,  2.33769522,  4.62537265, 11.81697183]),\n",
       " 'std_fit_time': array([0.04655123, 0.02934345, 0.49481646, 0.04088452, 0.43846348,\n",
       "        0.86435608, 0.0099258 , 0.01939694, 0.19042654, 0.07609485,\n",
       "        0.07823288, 0.05113939, 0.00623692, 0.00982828, 0.0518763 ,\n",
       "        0.01856268, 0.01227865, 0.03303324, 0.01613428, 0.03835122,\n",
       "        0.54836441, 0.29653178, 0.03115617, 0.09773882, 0.0413816 ,\n",
       "        0.02333855, 0.07029838, 0.09367686, 0.04798808, 0.38071686,\n",
       "        0.01356515, 0.0238247 , 0.03964635, 0.01702801, 0.03747092,\n",
       "        0.41124817, 0.02963565, 0.02566548, 0.20177635, 0.02740477,\n",
       "        0.1395758 , 0.28165253, 0.0147888 , 0.01586716, 0.03983155,\n",
       "        0.22163163, 0.04125484, 0.09090698, 0.09165552, 0.00169585,\n",
       "        0.25738423, 0.00848942, 0.0105304 , 0.11491068, 0.0087372 ,\n",
       "        0.16638707, 0.3059431 , 0.32189183, 0.22872237, 0.14607081,\n",
       "        0.00651859, 0.18204843, 0.26636419, 0.02661775, 0.22134467,\n",
       "        0.10804009, 0.32237176, 0.16853124, 0.19446795, 0.01521614,\n",
       "        0.19470032, 0.11732803, 0.02453048, 0.02656117, 0.18604883,\n",
       "        0.03538884, 0.18614751, 0.67416311, 0.0127159 , 0.03791808,\n",
       "        0.30353783, 0.01257675, 0.04418555, 0.39223337, 0.04573973,\n",
       "        0.04834576, 0.48658116, 0.00813409, 0.02890385, 0.384926  ]),\n",
       " 'mean_score_time': array([0.03533821, 0.06186395, 0.14835463, 0.0372046 , 0.0749918 ,\n",
       "        0.14499087, 0.03614202, 0.06181836, 0.14328561, 0.03689976,\n",
       "        0.06324577, 0.14732447, 0.0345871 , 0.0631494 , 0.14512944,\n",
       "        0.03462105, 0.06227117, 0.14660683, 0.03547902, 0.06252947,\n",
       "        0.14897733, 0.03582697, 0.06371236, 0.14716964, 0.03753252,\n",
       "        0.06335697, 0.1493361 , 0.03737278, 0.06450057, 0.15247927,\n",
       "        0.03551002, 0.06521492, 0.15322366, 0.03827944, 0.06345744,\n",
       "        0.16827459, 0.03610306, 0.06585274, 0.15430379, 0.03705215,\n",
       "        0.06724982, 0.15631032, 0.03655329, 0.06712666, 0.15768323,\n",
       "        0.03691463, 0.06112342, 0.14315066, 0.03392515, 0.06127586,\n",
       "        0.14231081, 0.03366246, 0.06137543, 0.14480166, 0.03446531,\n",
       "        0.06388578, 0.14662895, 0.05078321, 0.06215329, 0.14769111,\n",
       "        0.03472743, 0.06404371, 0.14742427, 0.03509364, 0.06399674,\n",
       "        0.14958324, 0.04327712, 0.06359625, 0.15093622, 0.03752403,\n",
       "        0.06322899, 0.14867935, 0.03556986, 0.06450868, 0.15096126,\n",
       "        0.03902493, 0.0672544 , 0.15102396, 0.03561106, 0.06449857,\n",
       "        0.1547317 , 0.03677177, 0.06551728, 0.15655642, 0.03567619,\n",
       "        0.06578288, 0.15557055, 0.03632622, 0.065696  , 0.15597458]),\n",
       " 'std_score_time': array([0.00126847, 0.00084364, 0.00479318, 0.00229127, 0.01477687,\n",
       "        0.00114168, 0.00230008, 0.00125828, 0.00136515, 0.00231479,\n",
       "        0.00111163, 0.00303433, 0.00044174, 0.0009559 , 0.00219581,\n",
       "        0.00212705, 0.00094455, 0.00200239, 0.00110771, 0.00077785,\n",
       "        0.00117859, 0.00191445, 0.0007134 , 0.0027319 , 0.00375249,\n",
       "        0.00078478, 0.00063754, 0.0030614 , 0.00112662, 0.00178747,\n",
       "        0.00074028, 0.00131906, 0.00553023, 0.00288853, 0.00359452,\n",
       "        0.028213  , 0.00057132, 0.00086666, 0.00240243, 0.00190331,\n",
       "        0.00239175, 0.00185879, 0.0011415 , 0.00187569, 0.00149121,\n",
       "        0.00578151, 0.00065273, 0.00112539, 0.00054812, 0.00090267,\n",
       "        0.00162864, 0.00063739, 0.00058964, 0.00065559, 0.00029405,\n",
       "        0.0028306 , 0.001334  , 0.0191083 , 0.00193741, 0.00093401,\n",
       "        0.00112432, 0.00211979, 0.00160509, 0.00090496, 0.00076146,\n",
       "        0.0009421 , 0.01414953, 0.00117497, 0.00542313, 0.00627302,\n",
       "        0.00065906, 0.00156478, 0.00026202, 0.00100843, 0.00092058,\n",
       "        0.00795196, 0.00570783, 0.00232748, 0.00065302, 0.00111979,\n",
       "        0.00600772, 0.0013713 , 0.0015288 , 0.00276042, 0.00044961,\n",
       "        0.00112205, 0.00282963, 0.00107204, 0.00083218, 0.00146578]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=['auto', 'auto', 'auto', 'sqrt', 'sqrt', 'sqrt', 'log2',\n",
       "                    'log2', 'log2', 'auto', 'auto', 'auto', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', 'log2', 'auto', 'auto', 'auto',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'auto',\n",
       "                    'auto', 'auto', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2',\n",
       "                    'log2', 'auto', 'auto', 'auto', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'log2', 'log2', 'log2', 'auto', 'auto', 'auto', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'auto', 'auto',\n",
       "                    'auto', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2',\n",
       "                    'auto', 'auto', 'auto', 'sqrt', 'sqrt', 'sqrt', 'log2',\n",
       "                    'log2', 'log2', 'auto', 'auto', 'auto', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', 'log2', 'auto', 'auto', 'auto',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[100, 200, 500, 100, 200, 500, 100, 200, 500, 100, 200,\n",
       "                    500, 100, 200, 500, 100, 200, 500, 100, 200, 500, 100,\n",
       "                    200, 500, 100, 200, 500, 100, 200, 500, 100, 200, 500,\n",
       "                    100, 200, 500, 100, 200, 500, 100, 200, 500, 100, 200,\n",
       "                    500, 100, 200, 500, 100, 200, 500, 100, 200, 500, 100,\n",
       "                    200, 500, 100, 200, 500, 100, 200, 500, 100, 200, 500,\n",
       "                    100, 200, 500, 100, 200, 500, 100, 200, 500, 100, 200,\n",
       "                    500, 100, 200, 500, 100, 200, 500, 100, 200, 500, 100,\n",
       "                    200, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 500}],\n",
       " 'split0_test_score': array([0.54151177, 0.55762082, 0.56133829, 0.54151177, 0.55762082,\n",
       "        0.56133829, 0.43494424, 0.42998761, 0.42627014, 0.65799257,\n",
       "        0.66047088, 0.65551425, 0.65799257, 0.66047088, 0.65551425,\n",
       "        0.54894672, 0.55390335, 0.53283767, 0.73358116, 0.73605948,\n",
       "        0.73605948, 0.73358116, 0.73605948, 0.73605948, 0.64312268,\n",
       "        0.64807931, 0.64312268, 0.77819083, 0.7732342 , 0.77075589,\n",
       "        0.77819083, 0.7732342 , 0.77075589, 0.73853779, 0.73358116,\n",
       "        0.72366791, 0.80421314, 0.82156134, 0.81784387, 0.80421314,\n",
       "        0.82156134, 0.81784387, 0.79801735, 0.7905824 , 0.78438662,\n",
       "        0.51920694, 0.54151177, 0.53283767, 0.51920694, 0.54151177,\n",
       "        0.53283767, 0.41759603, 0.41883519, 0.42131351, 0.64064436,\n",
       "        0.64807931, 0.64436183, 0.64064436, 0.64807931, 0.64436183,\n",
       "        0.52416357, 0.52416357, 0.51425031, 0.71871128, 0.72366791,\n",
       "        0.72118959, 0.71871128, 0.72366791, 0.72118959, 0.63320942,\n",
       "        0.64436183, 0.63816605, 0.76332094, 0.77447336, 0.76827757,\n",
       "        0.76332094, 0.77447336, 0.76827757, 0.73110285, 0.73853779,\n",
       "        0.72738538, 0.80173482, 0.80916976, 0.81164808, 0.80173482,\n",
       "        0.80916976, 0.81164808, 0.78934325, 0.79182156, 0.79677819]),\n",
       " 'split1_test_score': array([0.59355638, 0.58364312, 0.57868649, 0.59355638, 0.58364312,\n",
       "        0.57868649, 0.43494424, 0.44733581, 0.43742255, 0.70508055,\n",
       "        0.69640644, 0.68401487, 0.70508055, 0.69640644, 0.68401487,\n",
       "        0.55885998, 0.57496902, 0.55018587, 0.77199504, 0.76703841,\n",
       "        0.7645601 , 0.77199504, 0.76703841, 0.7645601 , 0.67410161,\n",
       "        0.6716233 , 0.67410161, 0.81412639, 0.81536555, 0.81784387,\n",
       "        0.81412639, 0.81536555, 0.81784387, 0.78438662, 0.7819083 ,\n",
       "        0.77447336, 0.86121437, 0.86245353, 0.85501859, 0.86121437,\n",
       "        0.86245353, 0.85501859, 0.8228005 , 0.83271375, 0.84262701,\n",
       "        0.52168525, 0.54275093, 0.53407683, 0.52168525, 0.54275093,\n",
       "        0.53407683, 0.44237918, 0.43122677, 0.42750929, 0.67410161,\n",
       "        0.6716233 , 0.66542751, 0.67410161, 0.6716233 , 0.66542751,\n",
       "        0.53407683, 0.54151177, 0.52292441, 0.74845105, 0.75092937,\n",
       "        0.74969021, 0.74845105, 0.75092937, 0.74969021, 0.65799257,\n",
       "        0.64436183, 0.64312268, 0.81784387, 0.81908302, 0.81412639,\n",
       "        0.81784387, 0.81908302, 0.81412639, 0.77075589, 0.76579926,\n",
       "        0.76208178, 0.85625774, 0.85873606, 0.86245353, 0.85625774,\n",
       "        0.85873606, 0.86245353, 0.83023544, 0.83271375, 0.83023544]),\n",
       " 'split2_test_score': array([0.53101737, 0.54094293, 0.53598015, 0.53101737, 0.54094293,\n",
       "        0.53598015, 0.41687345, 0.43424318, 0.43052109, 0.691067  ,\n",
       "        0.6674938 , 0.66377171, 0.691067  , 0.6674938 , 0.66377171,\n",
       "        0.51488834, 0.51488834, 0.52233251, 0.7617866 , 0.77171216,\n",
       "        0.76674938, 0.7617866 , 0.77171216, 0.76674938, 0.64516129,\n",
       "        0.64640199, 0.65012407, 0.8101737 , 0.81761787, 0.82382134,\n",
       "        0.8101737 , 0.81761787, 0.82382134, 0.74565757, 0.74813896,\n",
       "        0.75310174, 0.85856079, 0.86972705, 0.86600496, 0.85856079,\n",
       "        0.86972705, 0.86600496, 0.83126551, 0.8337469 , 0.83746898,\n",
       "        0.48138958, 0.48263027, 0.4764268 , 0.48138958, 0.48263027,\n",
       "        0.4764268 , 0.42059553, 0.42307692, 0.42059553, 0.66377171,\n",
       "        0.64888337, 0.65012407, 0.66377171, 0.64888337, 0.65012407,\n",
       "        0.50124069, 0.50496278, 0.5       , 0.74937965, 0.75310174,\n",
       "        0.74317618, 0.74937965, 0.75310174, 0.74317618, 0.64019851,\n",
       "        0.64640199, 0.64640199, 0.79900744, 0.80521092, 0.80397022,\n",
       "        0.79900744, 0.80521092, 0.80397022, 0.73945409, 0.74565757,\n",
       "        0.74193548, 0.86476427, 0.86972705, 0.86228288, 0.86476427,\n",
       "        0.86972705, 0.86228288, 0.83002481, 0.83126551, 0.8325062 ]),\n",
       " 'split3_test_score': array([0.5471464 , 0.55707196, 0.56327543, 0.5471464 , 0.55707196,\n",
       "        0.56327543, 0.40818859, 0.41439206, 0.40942928, 0.66377171,\n",
       "        0.6674938 , 0.66501241, 0.66377171, 0.6674938 , 0.66501241,\n",
       "        0.52605459, 0.52977667, 0.53722084, 0.74441687, 0.74069479,\n",
       "        0.74193548, 0.74441687, 0.74069479, 0.74193548, 0.63027295,\n",
       "        0.64516129, 0.63523573, 0.79032258, 0.80148883, 0.80521092,\n",
       "        0.79032258, 0.80148883, 0.80521092, 0.71712159, 0.72456576,\n",
       "        0.72208437, 0.84739454, 0.84739454, 0.84863524, 0.84739454,\n",
       "        0.84739454, 0.84863524, 0.81265509, 0.82258065, 0.82258065,\n",
       "        0.52233251, 0.52977667, 0.53598015, 0.52233251, 0.52977667,\n",
       "        0.53598015, 0.4057072 , 0.40942928, 0.40694789, 0.64764268,\n",
       "        0.65508685, 0.65260546, 0.64764268, 0.65508685, 0.65260546,\n",
       "        0.53225806, 0.5248139 , 0.5235732 , 0.73573201, 0.73449132,\n",
       "        0.72828784, 0.73573201, 0.73449132, 0.72828784, 0.61662531,\n",
       "        0.62779156, 0.62779156, 0.7853598 , 0.78908189, 0.78039702,\n",
       "        0.7853598 , 0.78908189, 0.78039702, 0.71712159, 0.72580645,\n",
       "        0.71712159, 0.84615385, 0.85111663, 0.84987593, 0.84615385,\n",
       "        0.85111663, 0.84987593, 0.79404467, 0.80645161, 0.80645161]),\n",
       " 'split4_test_score': array([0.58188586, 0.58933002, 0.58188586, 0.58188586, 0.58933002,\n",
       "        0.58188586, 0.46277916, 0.46774194, 0.45905707, 0.70719603,\n",
       "        0.69975186, 0.69602978, 0.70719603, 0.69975186, 0.69602978,\n",
       "        0.56327543, 0.56823821, 0.56575682, 0.76799007, 0.76923077,\n",
       "        0.76550868, 0.76799007, 0.76923077, 0.76550868, 0.68238213,\n",
       "        0.69354839, 0.68610422, 0.81141439, 0.81141439, 0.81141439,\n",
       "        0.81141439, 0.81141439, 0.81141439, 0.75434243, 0.77419355,\n",
       "        0.77295285, 0.85856079, 0.85483871, 0.86104218, 0.85856079,\n",
       "        0.85483871, 0.86104218, 0.82133995, 0.83622829, 0.82754342,\n",
       "        0.54094293, 0.55583127, 0.55707196, 0.54094293, 0.55583127,\n",
       "        0.55707196, 0.44913151, 0.44913151, 0.44913151, 0.67369727,\n",
       "        0.66501241, 0.66501241, 0.67369727, 0.66501241, 0.66501241,\n",
       "        0.52977667, 0.52977667, 0.54342432, 0.76550868, 0.76426799,\n",
       "        0.75186104, 0.76550868, 0.76426799, 0.75186104, 0.66377171,\n",
       "        0.67990074, 0.66129032, 0.82009926, 0.82009926, 0.82009926,\n",
       "        0.82009926, 0.82009926, 0.82009926, 0.74937965, 0.75434243,\n",
       "        0.74937965, 0.85111663, 0.85235732, 0.85111663, 0.85111663,\n",
       "        0.85235732, 0.85111663, 0.82382134, 0.82382134, 0.82258065]),\n",
       " 'mean_test_score': array([0.55902356, 0.56572177, 0.56423324, 0.55902356, 0.56572177,\n",
       "        0.56423324, 0.43154593, 0.43874012, 0.43254003, 0.68502157,\n",
       "        0.67832336, 0.6728686 , 0.68502157, 0.67832336, 0.6728686 ,\n",
       "        0.54240501, 0.54835512, 0.54166674, 0.75595395, 0.75694712,\n",
       "        0.75496263, 0.75595395, 0.75694712, 0.75496263, 0.65500813,\n",
       "        0.66096285, 0.65773766, 0.80084558, 0.80382417, 0.80580928,\n",
       "        0.80084558, 0.80382417, 0.80580928, 0.7480092 , 0.75247755,\n",
       "        0.74925604, 0.84598873, 0.85119503, 0.84970897, 0.84598873,\n",
       "        0.85119503, 0.84970897, 0.81721568, 0.8231704 , 0.82292134,\n",
       "        0.51711144, 0.53050018, 0.52727868, 0.51711144, 0.53050018,\n",
       "        0.52727868, 0.42708189, 0.42633993, 0.42509955, 0.65997153,\n",
       "        0.65773705, 0.65550626, 0.65997153, 0.65773705, 0.65550626,\n",
       "        0.52430317, 0.52504574, 0.52083445, 0.74355654, 0.74529166,\n",
       "        0.73884097, 0.74355654, 0.74529166, 0.73884097, 0.6423595 ,\n",
       "        0.64856359, 0.64335452, 0.79712626, 0.80158969, 0.79737409,\n",
       "        0.79712626, 0.80158969, 0.79737409, 0.74156281, 0.7460287 ,\n",
       "        0.73958078, 0.84400546, 0.84822136, 0.84747541, 0.84400546,\n",
       "        0.84822136, 0.84747541, 0.8134939 , 0.81721476, 0.81771042]),\n",
       " 'std_test_score': array([0.0242787 , 0.01807186, 0.01629753, 0.0242787 , 0.01807186,\n",
       "        0.01629753, 0.01875878, 0.01791451, 0.01615232, 0.02055597,\n",
       "        0.01636734, 0.01487499, 0.02055597, 0.01636734, 0.01487499,\n",
       "        0.01883421, 0.02280177, 0.01499626, 0.01462772, 0.01530464,\n",
       "        0.01318555, 0.01462772, 0.01530464, 0.01318555, 0.01981893,\n",
       "        0.01899029, 0.01923716, 0.01413552, 0.01626211, 0.0185999 ,\n",
       "        0.01413552, 0.01626211, 0.0185999 , 0.02196683, 0.02232809,\n",
       "        0.02282671, 0.0214248 , 0.01658955, 0.01696308, 0.0214248 ,\n",
       "        0.01658955, 0.01696308, 0.01126918, 0.01694563, 0.02052487,\n",
       "        0.01947594, 0.02531818, 0.02693097, 0.01947594, 0.02531818,\n",
       "        0.02693097, 0.01618101, 0.01338862, 0.0137655 , 0.01362378,\n",
       "        0.00921349, 0.00837113, 0.01362378, 0.00921349, 0.00837113,\n",
       "        0.01200551, 0.01181244, 0.01413928, 0.01560943, 0.0144022 ,\n",
       "        0.01207445, 0.01560943, 0.0144022 , 0.01207445, 0.01705003,\n",
       "        0.01704979, 0.01095591, 0.02117435, 0.01762654, 0.01987667,\n",
       "        0.02117435, 0.01762654, 0.01987667, 0.01802537, 0.01360282,\n",
       "        0.01588081, 0.0220138 , 0.02060859, 0.01868809, 0.0220138 ,\n",
       "        0.02060859, 0.01868809, 0.01800963, 0.01576039, 0.01388834]),\n",
       " 'rank_test_score': array([71, 67, 69, 71, 67, 69, 87, 85, 86, 49, 51, 53, 49, 51, 53, 74, 73,\n",
       "        75, 33, 31, 35, 33, 31, 35, 63, 55, 58, 25, 21, 19, 25, 21, 19, 39,\n",
       "        37, 38,  9,  1,  3,  9,  1,  3, 16, 13, 14, 83, 76, 78, 83, 76, 78,\n",
       "        88, 89, 90, 56, 59, 61, 56, 59, 61, 81, 80, 82, 43, 41, 47, 43, 41,\n",
       "        47, 66, 64, 65, 29, 23, 27, 29, 23, 27, 45, 40, 46, 11,  5,  7, 11,\n",
       "         5,  7, 18, 17, 15], dtype=int32)}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anwendung der besten Parameterkombination im Modell, Trainieren des Modells und anschlieÃŸende Anwendung des Modells auf den zuvor definierten Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=200, max_depth=8, max_features = 'auto', criterion = 'gini')\n",
    "model = model.fit(train_data,train_labels)\n",
    "y_pred = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speicherung des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_random_forest.joblib']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(rfc, \"my_random_forest.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung der Ergebnisse aus dem Random Forest-Modell Ã¼ber Confusion-Matrix, classification report und Accuracy Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Results auf test data #########\n",
      "Accuracy (test):  0.8727678571428571\n",
      "[[102   1   4   0]\n",
      " [ 11  90   7   0]\n",
      " [ 12  19  75   0]\n",
      " [  3   0   0 124]]\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Results auf test data #########\")\n",
    "\n",
    "pred= model.predict(test_data)\n",
    "predictions = np.argmax(model.predict(test_data), axis=-1)\n",
    "cm= confusion_matrix(test_labels_raw, predictions+1)\n",
    "acc = accuracy_score(test_labels_raw, predictions+1) \n",
    "\n",
    "#confusion_matrix(\n",
    "#test_labels.values.argmax(axis=1), predictions.argmax(axis=1))\n",
    "#predictions = np.argmax(model.predict(test_data), axis=-1)\n",
    "print(\"Accuracy (test): \", acc)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Ã¼ber RFECV (Recursive feature elimination and cross-validated selection)\n",
    "Verwendung des zuvor Ã¼ber GridSearchCV optimierten RandomForestClassifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 533 features.\n",
      "Fitting estimator with 532 features.\n",
      "Fitting estimator with 531 features.\n",
      "Fitting estimator with 530 features.\n",
      "Fitting estimator with 529 features.\n",
      "Fitting estimator with 528 features.\n",
      "Fitting estimator with 527 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 525 features.\n",
      "Fitting estimator with 524 features.\n",
      "Fitting estimator with 523 features.\n",
      "Fitting estimator with 522 features.\n",
      "Fitting estimator with 521 features.\n",
      "Fitting estimator with 520 features.\n",
      "Fitting estimator with 519 features.\n",
      "Fitting estimator with 518 features.\n",
      "Fitting estimator with 517 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 515 features.\n",
      "Fitting estimator with 514 features.\n",
      "Fitting estimator with 513 features.\n",
      "Fitting estimator with 512 features.\n",
      "Fitting estimator with 511 features.\n",
      "Fitting estimator with 510 features.\n",
      "Fitting estimator with 509 features.\n",
      "Fitting estimator with 508 features.\n",
      "Fitting estimator with 507 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 505 features.\n",
      "Fitting estimator with 504 features.\n",
      "Fitting estimator with 503 features.\n",
      "Fitting estimator with 502 features.\n",
      "Fitting estimator with 501 features.\n",
      "Fitting estimator with 500 features.\n",
      "Fitting estimator with 499 features.\n",
      "Fitting estimator with 498 features.\n",
      "Fitting estimator with 497 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 495 features.\n",
      "Fitting estimator with 494 features.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Fitting estimator with 493 features.\n",
      "Fitting estimator with 492 features.\n",
      "Fitting estimator with 491 features.\n",
      "Fitting estimator with 490 features.\n",
      "Fitting estimator with 489 features.\n",
      "Fitting estimator with 488 features.\n",
      "Fitting estimator with 487 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 485 features.\n",
      "Fitting estimator with 484 features.\n",
      "Fitting estimator with 483 features.\n",
      "Fitting estimator with 482 features.\n",
      "Fitting estimator with 481 features.\n",
      "Fitting estimator with 480 features.\n",
      "Fitting estimator with 479 features.\n",
      "Fitting estimator with 478 features.\n",
      "Fitting estimator with 477 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 475 features.\n",
      "Fitting estimator with 474 features.\n",
      "Fitting estimator with 473 features.\n",
      "Fitting estimator with 472 features.\n",
      "Fitting estimator with 471 features.\n",
      "Fitting estimator with 470 features.\n",
      "Fitting estimator with 469 features.\n",
      "Fitting estimator with 468 features.\n",
      "Fitting estimator with 467 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 465 features.\n",
      "Fitting estimator with 464 features.\n",
      "Fitting estimator with 463 features.\n",
      "Fitting estimator with 462 features.\n",
      "Fitting estimator with 461 features.\n",
      "Fitting estimator with 460 features.\n",
      "Fitting estimator with 459 features.\n",
      "Fitting estimator with 458 features.\n",
      "Fitting estimator with 457 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 455 features.\n",
      "Fitting estimator with 454 features.\n",
      "Fitting estimator with 453 features.\n",
      "Fitting estimator with 452 features.\n",
      "Fitting estimator with 451 features.\n",
      "Fitting estimator with 450 features.\n",
      "Fitting estimator with 449 features.\n",
      "Fitting estimator with 448 features.\n",
      "Fitting estimator with 447 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 445 features.\n",
      "Fitting estimator with 444 features.\n",
      "Fitting estimator with 443 features.\n",
      "Fitting estimator with 442 features.\n",
      "Fitting estimator with 441 features.\n",
      "Fitting estimator with 440 features.\n",
      "Fitting estimator with 439 features.\n",
      "Fitting estimator with 438 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 435 features.\n",
      "Fitting estimator with 434 features.\n",
      "Fitting estimator with 433 features.\n",
      "Fitting estimator with 432 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 430 features.\n",
      "Fitting estimator with 429 features.\n",
      "Fitting estimator with 428 features.\n",
      "Fitting estimator with 427 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 425 features.\n",
      "Fitting estimator with 424 features.\n",
      "Fitting estimator with 423 features.\n",
      "Fitting estimator with 422 features.\n",
      "Fitting estimator with 421 features.\n",
      "Fitting estimator with 420 features.\n",
      "Fitting estimator with 419 features.\n",
      "Fitting estimator with 418 features.\n",
      "Fitting estimator with 417 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 415 features.\n",
      "Fitting estimator with 414 features.\n",
      "Fitting estimator with 413 features.\n",
      "Fitting estimator with 412 features.\n",
      "Fitting estimator with 411 features.\n",
      "Fitting estimator with 410 features.\n",
      "Fitting estimator with 409 features.\n",
      "Fitting estimator with 408 features.\n",
      "Fitting estimator with 407 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 405 features.\n",
      "Fitting estimator with 404 features.\n",
      "Fitting estimator with 403 features.\n",
      "Fitting estimator with 402 features.\n",
      "Fitting estimator with 401 features.\n",
      "Fitting estimator with 400 features.\n",
      "Fitting estimator with 399 features.\n",
      "Fitting estimator with 398 features.\n",
      "Fitting estimator with 397 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 395 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 393 features.\n",
      "Fitting estimator with 392 features.\n",
      "Fitting estimator with 391 features.\n",
      "Fitting estimator with 390 features.\n",
      "Fitting estimator with 389 features.\n",
      "Fitting estimator with 388 features.\n",
      "Fitting estimator with 387 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 385 features.\n",
      "Fitting estimator with 384 features.\n",
      "Fitting estimator with 383 features.\n",
      "Fitting estimator with 382 features.\n",
      "Fitting estimator with 381 features.\n",
      "Fitting estimator with 380 features.\n",
      "Fitting estimator with 379 features.\n",
      "Fitting estimator with 378 features.\n",
      "Fitting estimator with 377 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 375 features.\n",
      "Fitting estimator with 374 features.\n",
      "Fitting estimator with 373 features.\n",
      "Fitting estimator with 372 features.\n",
      "Fitting estimator with 371 features.\n",
      "Fitting estimator with 370 features.\n",
      "Fitting estimator with 369 features.\n",
      "Fitting estimator with 368 features.\n",
      "Fitting estimator with 367 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 365 features.\n",
      "Fitting estimator with 364 features.\n",
      "Fitting estimator with 363 features.\n",
      "Fitting estimator with 362 features.\n",
      "Fitting estimator with 361 features.\n",
      "Fitting estimator with 360 features.\n",
      "Fitting estimator with 359 features.\n",
      "Fitting estimator with 358 features.\n",
      "Fitting estimator with 357 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 355 features.\n",
      "Fitting estimator with 354 features.\n",
      "Fitting estimator with 353 features.\n",
      "Fitting estimator with 352 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 350 features.\n",
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 348 features.\n",
      "Fitting estimator with 347 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 345 features.\n",
      "Fitting estimator with 344 features.\n",
      "Fitting estimator with 343 features.\n",
      "Fitting estimator with 342 features.\n",
      "Fitting estimator with 341 features.\n",
      "Fitting estimator with 340 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 338 features.\n",
      "Fitting estimator with 337 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 335 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 334 features.\n",
      "Fitting estimator with 333 features.\n",
      "Fitting estimator with 332 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 330 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 328 features.\n",
      "Fitting estimator with 327 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 325 features.\n",
      "Fitting estimator with 324 features.\n",
      "Fitting estimator with 323 features.\n",
      "Fitting estimator with 322 features.\n",
      "Fitting estimator with 321 features.\n",
      "Fitting estimator with 320 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 318 features.\n",
      "Fitting estimator with 317 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 315 features.\n",
      "Fitting estimator with 314 features.\n",
      "Fitting estimator with 313 features.\n",
      "Fitting estimator with 312 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 310 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 307 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 305 features.\n",
      "Fitting estimator with 304 features.\n",
      "Fitting estimator with 303 features.\n",
      "Fitting estimator with 302 features.\n",
      "Fitting estimator with 301 features.\n",
      "Fitting estimator with 300 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 298 features.\n",
      "Fitting estimator with 297 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 295 features.\n",
      "Fitting estimator with 294 features.\n",
      "Fitting estimator with 293 features.\n",
      "Fitting estimator with 292 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 290 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 288 features.\n",
      "Fitting estimator with 287 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 285 features.\n",
      "Fitting estimator with 284 features.\n",
      "Fitting estimator with 283 features.\n",
      "Fitting estimator with 282 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 280 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 278 features.\n",
      "Fitting estimator with 277 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 275 features.\n",
      "Fitting estimator with 274 features.\n",
      "Fitting estimator with 273 features.\n",
      "Fitting estimator with 272 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 270 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 268 features.\n",
      "Fitting estimator with 267 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 264 features.\n",
      "Fitting estimator with 263 features.\n",
      "Fitting estimator with 262 features.\n",
      "Fitting estimator with 261 features.\n",
      "Fitting estimator with 260 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 258 features.\n",
      "Fitting estimator with 257 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 255 features.\n",
      "Fitting estimator with 254 features.\n",
      "Fitting estimator with 253 features.\n",
      "Fitting estimator with 252 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 250 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 248 features.\n",
      "Fitting estimator with 247 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 245 features.\n",
      "Fitting estimator with 244 features.\n",
      "Fitting estimator with 243 features.\n",
      "Fitting estimator with 242 features.\n",
      "Fitting estimator with 241 features.\n",
      "Fitting estimator with 240 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 238 features.\n",
      "Fitting estimator with 237 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 235 features.\n",
      "Fitting estimator with 234 features.\n",
      "Fitting estimator with 233 features.\n",
      "Fitting estimator with 232 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 230 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 228 features.\n",
      "Fitting estimator with 227 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 225 features.\n",
      "Fitting estimator with 224 features.\n",
      "Fitting estimator with 223 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 221 features.\n",
      "Fitting estimator with 220 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 218 features.\n",
      "Fitting estimator with 217 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 215 features.\n",
      "Fitting estimator with 214 features.\n",
      "Fitting estimator with 213 features.\n",
      "Fitting estimator with 212 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 210 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 208 features.\n",
      "Fitting estimator with 207 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 205 features.\n",
      "Fitting estimator with 204 features.\n",
      "Fitting estimator with 203 features.\n",
      "Fitting estimator with 202 features.\n",
      "Fitting estimator with 201 features.\n",
      "Fitting estimator with 200 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 198 features.\n",
      "Fitting estimator with 197 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 195 features.\n",
      "Fitting estimator with 194 features.\n",
      "Fitting estimator with 193 features.\n",
      "Fitting estimator with 192 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 190 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 188 features.\n",
      "Fitting estimator with 187 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 185 features.\n",
      "Fitting estimator with 184 features.\n",
      "Fitting estimator with 183 features.\n",
      "Fitting estimator with 182 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 180 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 178 features.\n",
      "Fitting estimator with 177 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 174 features.\n",
      "Fitting estimator with 173 features.\n",
      "Fitting estimator with 172 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 170 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 168 features.\n",
      "Fitting estimator with 167 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 165 features.\n",
      "Fitting estimator with 164 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 162 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 160 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 158 features.\n",
      "Fitting estimator with 157 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 155 features.\n",
      "Fitting estimator with 154 features.\n",
      "Fitting estimator with 153 features.\n",
      "Fitting estimator with 152 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 150 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 148 features.\n",
      "Fitting estimator with 147 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 145 features.\n",
      "Fitting estimator with 144 features.\n",
      "Fitting estimator with 143 features.\n",
      "Fitting estimator with 142 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 140 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 138 features.\n",
      "Fitting estimator with 137 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 135 features.\n",
      "Fitting estimator with 134 features.\n",
      "Fitting estimator with 133 features.\n",
      "Fitting estimator with 132 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 130 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 128 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 125 features.\n",
      "Fitting estimator with 124 features.\n",
      "Fitting estimator with 123 features.\n",
      "Fitting estimator with 122 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 120 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 118 features.\n",
      "Fitting estimator with 117 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 114 features.\n",
      "Fitting estimator with 113 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 112 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 110 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 108 features.\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 104 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 533 features.\n",
      "Fitting estimator with 532 features.\n",
      "Fitting estimator with 531 features.\n",
      "Fitting estimator with 530 features.\n",
      "Fitting estimator with 529 features.\n",
      "Fitting estimator with 528 features.\n",
      "Fitting estimator with 527 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 525 features.\n",
      "Fitting estimator with 524 features.\n",
      "Fitting estimator with 523 features.\n",
      "Fitting estimator with 522 features.\n",
      "Fitting estimator with 521 features.\n",
      "Fitting estimator with 520 features.\n",
      "Fitting estimator with 519 features.\n",
      "Fitting estimator with 518 features.\n",
      "Fitting estimator with 517 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 515 features.\n",
      "Fitting estimator with 514 features.\n",
      "Fitting estimator with 513 features.\n",
      "Fitting estimator with 512 features.\n",
      "Fitting estimator with 511 features.\n",
      "Fitting estimator with 510 features.\n",
      "Fitting estimator with 509 features.\n",
      "Fitting estimator with 508 features.\n",
      "Fitting estimator with 507 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 505 features.\n",
      "Fitting estimator with 504 features.\n",
      "Fitting estimator with 503 features.\n",
      "Fitting estimator with 502 features.\n",
      "Fitting estimator with 501 features.\n",
      "Fitting estimator with 500 features.\n",
      "Fitting estimator with 499 features.\n",
      "Fitting estimator with 498 features.\n",
      "Fitting estimator with 497 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 495 features.\n",
      "Fitting estimator with 494 features.\n",
      "Fitting estimator with 493 features.\n",
      "Fitting estimator with 492 features.\n",
      "Fitting estimator with 491 features.\n",
      "Fitting estimator with 490 features.\n",
      "Fitting estimator with 489 features.\n",
      "Fitting estimator with 488 features.\n",
      "Fitting estimator with 487 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 485 features.\n",
      "Fitting estimator with 484 features.\n",
      "Fitting estimator with 483 features.\n",
      "Fitting estimator with 482 features.\n",
      "Fitting estimator with 481 features.\n",
      "Fitting estimator with 480 features.\n",
      "Fitting estimator with 479 features.\n",
      "Fitting estimator with 478 features.\n",
      "Fitting estimator with 477 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 475 features.\n",
      "Fitting estimator with 474 features.\n",
      "Fitting estimator with 473 features.\n",
      "Fitting estimator with 472 features.\n",
      "Fitting estimator with 471 features.\n",
      "Fitting estimator with 470 features.\n",
      "Fitting estimator with 469 features.\n",
      "Fitting estimator with 468 features.\n",
      "Fitting estimator with 467 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 465 features.\n",
      "Fitting estimator with 464 features.\n",
      "Fitting estimator with 463 features.\n",
      "Fitting estimator with 462 features.\n",
      "Fitting estimator with 461 features.\n",
      "Fitting estimator with 460 features.\n",
      "Fitting estimator with 459 features.\n",
      "Fitting estimator with 458 features.\n",
      "Fitting estimator with 457 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 455 features.\n",
      "Fitting estimator with 454 features.\n",
      "Fitting estimator with 453 features.\n",
      "Fitting estimator with 452 features.\n",
      "Fitting estimator with 451 features.\n",
      "Fitting estimator with 450 features.\n",
      "Fitting estimator with 449 features.\n",
      "Fitting estimator with 448 features.\n",
      "Fitting estimator with 447 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 445 features.\n",
      "Fitting estimator with 444 features.\n",
      "Fitting estimator with 443 features.\n",
      "Fitting estimator with 442 features.\n",
      "Fitting estimator with 441 features.\n",
      "Fitting estimator with 440 features.\n",
      "Fitting estimator with 439 features.\n",
      "Fitting estimator with 438 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 435 features.\n",
      "Fitting estimator with 434 features.\n",
      "Fitting estimator with 433 features.\n",
      "Fitting estimator with 432 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 430 features.\n",
      "Fitting estimator with 429 features.\n",
      "Fitting estimator with 428 features.\n",
      "Fitting estimator with 427 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 425 features.\n",
      "Fitting estimator with 424 features.\n",
      "Fitting estimator with 423 features.\n",
      "Fitting estimator with 422 features.\n",
      "Fitting estimator with 421 features.\n",
      "Fitting estimator with 420 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 419 features.\n",
      "Fitting estimator with 418 features.\n",
      "Fitting estimator with 417 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 415 features.\n",
      "Fitting estimator with 414 features.\n",
      "Fitting estimator with 413 features.\n",
      "Fitting estimator with 412 features.\n",
      "Fitting estimator with 411 features.\n",
      "Fitting estimator with 410 features.\n",
      "Fitting estimator with 409 features.\n",
      "Fitting estimator with 408 features.\n",
      "Fitting estimator with 407 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 405 features.\n",
      "Fitting estimator with 404 features.\n",
      "Fitting estimator with 403 features.\n",
      "Fitting estimator with 402 features.\n",
      "Fitting estimator with 401 features.\n",
      "Fitting estimator with 400 features.\n",
      "Fitting estimator with 399 features.\n",
      "Fitting estimator with 398 features.\n",
      "Fitting estimator with 397 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 395 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 393 features.\n",
      "Fitting estimator with 392 features.\n",
      "Fitting estimator with 391 features.\n",
      "Fitting estimator with 390 features.\n",
      "Fitting estimator with 389 features.\n",
      "Fitting estimator with 388 features.\n",
      "Fitting estimator with 387 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 385 features.\n",
      "Fitting estimator with 384 features.\n",
      "Fitting estimator with 383 features.\n",
      "Fitting estimator with 382 features.\n",
      "Fitting estimator with 381 features.\n",
      "Fitting estimator with 380 features.\n",
      "Fitting estimator with 379 features.\n",
      "Fitting estimator with 378 features.\n",
      "Fitting estimator with 377 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 375 features.\n",
      "Fitting estimator with 374 features.\n",
      "Fitting estimator with 373 features.\n",
      "Fitting estimator with 372 features.\n",
      "Fitting estimator with 371 features.\n",
      "Fitting estimator with 370 features.\n",
      "Fitting estimator with 369 features.\n",
      "Fitting estimator with 368 features.\n",
      "Fitting estimator with 367 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 365 features.\n",
      "Fitting estimator with 364 features.\n",
      "Fitting estimator with 363 features.\n",
      "Fitting estimator with 362 features.\n",
      "Fitting estimator with 361 features.\n",
      "Fitting estimator with 360 features.\n",
      "Fitting estimator with 359 features.\n",
      "Fitting estimator with 358 features.\n",
      "Fitting estimator with 357 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 355 features.\n",
      "Fitting estimator with 354 features.\n",
      "Fitting estimator with 353 features.\n",
      "Fitting estimator with 352 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 350 features.\n",
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 348 features.\n",
      "Fitting estimator with 347 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 345 features.\n",
      "Fitting estimator with 344 features.\n",
      "Fitting estimator with 343 features.\n",
      "Fitting estimator with 342 features.\n",
      "Fitting estimator with 341 features.\n",
      "Fitting estimator with 340 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 338 features.\n",
      "Fitting estimator with 337 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 335 features.\n",
      "Fitting estimator with 334 features.\n",
      "Fitting estimator with 333 features.\n",
      "Fitting estimator with 332 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 330 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 328 features.\n",
      "Fitting estimator with 327 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 325 features.\n",
      "Fitting estimator with 324 features.\n",
      "Fitting estimator with 323 features.\n",
      "Fitting estimator with 322 features.\n",
      "Fitting estimator with 321 features.\n",
      "Fitting estimator with 320 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 318 features.\n",
      "Fitting estimator with 317 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 315 features.\n",
      "Fitting estimator with 314 features.\n",
      "Fitting estimator with 313 features.\n",
      "Fitting estimator with 312 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 310 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 307 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 305 features.\n",
      "Fitting estimator with 304 features.\n",
      "Fitting estimator with 303 features.\n",
      "Fitting estimator with 302 features.\n",
      "Fitting estimator with 301 features.\n",
      "Fitting estimator with 300 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 298 features.\n",
      "Fitting estimator with 297 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 295 features.\n",
      "Fitting estimator with 294 features.\n",
      "Fitting estimator with 293 features.\n",
      "Fitting estimator with 292 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 290 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 288 features.\n",
      "Fitting estimator with 287 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 285 features.\n",
      "Fitting estimator with 284 features.\n",
      "Fitting estimator with 283 features.\n",
      "Fitting estimator with 282 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 280 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 278 features.\n",
      "Fitting estimator with 277 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 275 features.\n",
      "Fitting estimator with 274 features.\n",
      "Fitting estimator with 273 features.\n",
      "Fitting estimator with 272 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 270 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 268 features.\n",
      "Fitting estimator with 267 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 264 features.\n",
      "Fitting estimator with 263 features.\n",
      "Fitting estimator with 262 features.\n",
      "Fitting estimator with 261 features.\n",
      "Fitting estimator with 260 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 258 features.\n",
      "Fitting estimator with 257 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 255 features.\n",
      "Fitting estimator with 254 features.\n",
      "Fitting estimator with 253 features.\n",
      "Fitting estimator with 252 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 250 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 248 features.\n",
      "Fitting estimator with 247 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 245 features.\n",
      "Fitting estimator with 244 features.\n",
      "Fitting estimator with 243 features.\n",
      "Fitting estimator with 242 features.\n",
      "Fitting estimator with 241 features.\n",
      "Fitting estimator with 240 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 238 features.\n",
      "Fitting estimator with 237 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 235 features.\n",
      "Fitting estimator with 234 features.\n",
      "Fitting estimator with 233 features.\n",
      "Fitting estimator with 232 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 230 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 228 features.\n",
      "Fitting estimator with 227 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 225 features.\n",
      "Fitting estimator with 224 features.\n",
      "Fitting estimator with 223 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 221 features.\n",
      "Fitting estimator with 220 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 218 features.\n",
      "Fitting estimator with 217 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 215 features.\n",
      "Fitting estimator with 214 features.\n",
      "Fitting estimator with 213 features.\n",
      "Fitting estimator with 212 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 210 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 208 features.\n",
      "Fitting estimator with 207 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 205 features.\n",
      "Fitting estimator with 204 features.\n",
      "Fitting estimator with 203 features.\n",
      "Fitting estimator with 202 features.\n",
      "Fitting estimator with 201 features.\n",
      "Fitting estimator with 200 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 198 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 197 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 195 features.\n",
      "Fitting estimator with 194 features.\n",
      "Fitting estimator with 193 features.\n",
      "Fitting estimator with 192 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 190 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 188 features.\n",
      "Fitting estimator with 187 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 185 features.\n",
      "Fitting estimator with 184 features.\n",
      "Fitting estimator with 183 features.\n",
      "Fitting estimator with 182 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 180 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 178 features.\n",
      "Fitting estimator with 177 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 174 features.\n",
      "Fitting estimator with 173 features.\n",
      "Fitting estimator with 172 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 170 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 168 features.\n",
      "Fitting estimator with 167 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 165 features.\n",
      "Fitting estimator with 164 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 162 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 160 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 158 features.\n",
      "Fitting estimator with 157 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 155 features.\n",
      "Fitting estimator with 154 features.\n",
      "Fitting estimator with 153 features.\n",
      "Fitting estimator with 152 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 150 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 148 features.\n",
      "Fitting estimator with 147 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 145 features.\n",
      "Fitting estimator with 144 features.\n",
      "Fitting estimator with 143 features.\n",
      "Fitting estimator with 142 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 140 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 138 features.\n",
      "Fitting estimator with 137 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 135 features.\n",
      "Fitting estimator with 134 features.\n",
      "Fitting estimator with 133 features.\n",
      "Fitting estimator with 132 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 130 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 128 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 125 features.\n",
      "Fitting estimator with 124 features.\n",
      "Fitting estimator with 123 features.\n",
      "Fitting estimator with 122 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 120 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 118 features.\n",
      "Fitting estimator with 117 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 114 features.\n",
      "Fitting estimator with 113 features.\n",
      "Fitting estimator with 112 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 110 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 108 features.\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 104 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 533 features.\n",
      "Fitting estimator with 532 features.\n",
      "Fitting estimator with 531 features.\n",
      "Fitting estimator with 530 features.\n",
      "Fitting estimator with 529 features.\n",
      "Fitting estimator with 528 features.\n",
      "Fitting estimator with 527 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 525 features.\n",
      "Fitting estimator with 524 features.\n",
      "Fitting estimator with 523 features.\n",
      "Fitting estimator with 522 features.\n",
      "Fitting estimator with 521 features.\n",
      "Fitting estimator with 520 features.\n",
      "Fitting estimator with 519 features.\n",
      "Fitting estimator with 518 features.\n",
      "Fitting estimator with 517 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 515 features.\n",
      "Fitting estimator with 514 features.\n",
      "Fitting estimator with 513 features.\n",
      "Fitting estimator with 512 features.\n",
      "Fitting estimator with 511 features.\n",
      "Fitting estimator with 510 features.\n",
      "Fitting estimator with 509 features.\n",
      "Fitting estimator with 508 features.\n",
      "Fitting estimator with 507 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 505 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 504 features.\n",
      "Fitting estimator with 503 features.\n",
      "Fitting estimator with 502 features.\n",
      "Fitting estimator with 501 features.\n",
      "Fitting estimator with 500 features.\n",
      "Fitting estimator with 499 features.\n",
      "Fitting estimator with 498 features.\n",
      "Fitting estimator with 497 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 495 features.\n",
      "Fitting estimator with 494 features.\n",
      "Fitting estimator with 493 features.\n",
      "Fitting estimator with 492 features.\n",
      "Fitting estimator with 491 features.\n",
      "Fitting estimator with 490 features.\n",
      "Fitting estimator with 489 features.\n",
      "Fitting estimator with 488 features.\n",
      "Fitting estimator with 487 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 485 features.\n",
      "Fitting estimator with 484 features.\n",
      "Fitting estimator with 483 features.\n",
      "Fitting estimator with 482 features.\n",
      "Fitting estimator with 481 features.\n",
      "Fitting estimator with 480 features.\n",
      "Fitting estimator with 479 features.\n",
      "Fitting estimator with 478 features.\n",
      "Fitting estimator with 477 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 475 features.\n",
      "Fitting estimator with 474 features.\n",
      "Fitting estimator with 473 features.\n",
      "Fitting estimator with 472 features.\n",
      "Fitting estimator with 471 features.\n",
      "Fitting estimator with 470 features.\n",
      "Fitting estimator with 469 features.\n",
      "Fitting estimator with 468 features.\n",
      "Fitting estimator with 467 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 465 features.\n",
      "Fitting estimator with 464 features.\n",
      "Fitting estimator with 463 features.\n",
      "Fitting estimator with 462 features.\n",
      "Fitting estimator with 461 features.\n",
      "Fitting estimator with 460 features.\n",
      "Fitting estimator with 459 features.\n",
      "Fitting estimator with 458 features.\n",
      "Fitting estimator with 457 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 455 features.\n",
      "Fitting estimator with 454 features.\n",
      "Fitting estimator with 453 features.\n",
      "Fitting estimator with 452 features.\n",
      "Fitting estimator with 451 features.\n",
      "Fitting estimator with 450 features.\n",
      "Fitting estimator with 449 features.\n",
      "Fitting estimator with 448 features.\n",
      "Fitting estimator with 447 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 445 features.\n",
      "Fitting estimator with 444 features.\n",
      "Fitting estimator with 443 features.\n",
      "Fitting estimator with 442 features.\n",
      "Fitting estimator with 441 features.\n",
      "Fitting estimator with 440 features.\n",
      "Fitting estimator with 439 features.\n",
      "Fitting estimator with 438 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 435 features.\n",
      "Fitting estimator with 434 features.\n",
      "Fitting estimator with 433 features.\n",
      "Fitting estimator with 432 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 430 features.\n",
      "Fitting estimator with 429 features.\n",
      "Fitting estimator with 428 features.\n",
      "Fitting estimator with 427 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 425 features.\n",
      "Fitting estimator with 424 features.\n",
      "Fitting estimator with 423 features.\n",
      "Fitting estimator with 422 features.\n",
      "Fitting estimator with 421 features.\n",
      "Fitting estimator with 420 features.\n",
      "Fitting estimator with 419 features.\n",
      "Fitting estimator with 418 features.\n",
      "Fitting estimator with 417 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 415 features.\n",
      "Fitting estimator with 414 features.\n",
      "Fitting estimator with 413 features.\n",
      "Fitting estimator with 412 features.\n",
      "Fitting estimator with 411 features.\n",
      "Fitting estimator with 410 features.\n",
      "Fitting estimator with 409 features.\n",
      "Fitting estimator with 408 features.\n",
      "Fitting estimator with 407 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 405 features.\n",
      "Fitting estimator with 404 features.\n",
      "Fitting estimator with 403 features.\n",
      "Fitting estimator with 402 features.\n",
      "Fitting estimator with 401 features.\n",
      "Fitting estimator with 400 features.\n",
      "Fitting estimator with 399 features.\n",
      "Fitting estimator with 398 features.\n",
      "Fitting estimator with 397 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 395 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 393 features.\n",
      "Fitting estimator with 392 features.\n",
      "Fitting estimator with 391 features.\n",
      "Fitting estimator with 390 features.\n",
      "Fitting estimator with 389 features.\n",
      "Fitting estimator with 388 features.\n",
      "Fitting estimator with 387 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 385 features.\n",
      "Fitting estimator with 384 features.\n",
      "Fitting estimator with 383 features.\n",
      "Fitting estimator with 382 features.\n",
      "Fitting estimator with 381 features.\n",
      "Fitting estimator with 380 features.\n",
      "Fitting estimator with 379 features.\n",
      "Fitting estimator with 378 features.\n",
      "Fitting estimator with 377 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 375 features.\n",
      "Fitting estimator with 374 features.\n",
      "Fitting estimator with 373 features.\n",
      "Fitting estimator with 372 features.\n",
      "Fitting estimator with 371 features.\n",
      "Fitting estimator with 370 features.\n",
      "Fitting estimator with 369 features.\n",
      "Fitting estimator with 368 features.\n",
      "Fitting estimator with 367 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 365 features.\n",
      "Fitting estimator with 364 features.\n",
      "Fitting estimator with 363 features.\n",
      "Fitting estimator with 362 features.\n",
      "Fitting estimator with 361 features.\n",
      "Fitting estimator with 360 features.\n",
      "Fitting estimator with 359 features.\n",
      "Fitting estimator with 358 features.\n",
      "Fitting estimator with 357 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 355 features.\n",
      "Fitting estimator with 354 features.\n",
      "Fitting estimator with 353 features.\n",
      "Fitting estimator with 352 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 350 features.\n",
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 348 features.\n",
      "Fitting estimator with 347 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 345 features.\n",
      "Fitting estimator with 344 features.\n",
      "Fitting estimator with 343 features.\n",
      "Fitting estimator with 342 features.\n",
      "Fitting estimator with 341 features.\n",
      "Fitting estimator with 340 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 338 features.\n",
      "Fitting estimator with 337 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 335 features.\n",
      "Fitting estimator with 334 features.\n",
      "Fitting estimator with 333 features.\n",
      "Fitting estimator with 332 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 330 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 328 features.\n",
      "Fitting estimator with 327 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 325 features.\n",
      "Fitting estimator with 324 features.\n",
      "Fitting estimator with 323 features.\n",
      "Fitting estimator with 322 features.\n",
      "Fitting estimator with 321 features.\n",
      "Fitting estimator with 320 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 318 features.\n",
      "Fitting estimator with 317 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 315 features.\n",
      "Fitting estimator with 314 features.\n",
      "Fitting estimator with 313 features.\n",
      "Fitting estimator with 312 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 310 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 307 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 305 features.\n",
      "Fitting estimator with 304 features.\n",
      "Fitting estimator with 303 features.\n",
      "Fitting estimator with 302 features.\n",
      "Fitting estimator with 301 features.\n",
      "Fitting estimator with 300 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 298 features.\n",
      "Fitting estimator with 297 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 295 features.\n",
      "Fitting estimator with 294 features.\n",
      "Fitting estimator with 293 features.\n",
      "Fitting estimator with 292 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 290 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 288 features.\n",
      "Fitting estimator with 287 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 285 features.\n",
      "Fitting estimator with 284 features.\n",
      "Fitting estimator with 283 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 282 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 280 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 278 features.\n",
      "Fitting estimator with 277 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 275 features.\n",
      "Fitting estimator with 274 features.\n",
      "Fitting estimator with 273 features.\n",
      "Fitting estimator with 272 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 270 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 268 features.\n",
      "Fitting estimator with 267 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 264 features.\n",
      "Fitting estimator with 263 features.\n",
      "Fitting estimator with 262 features.\n",
      "Fitting estimator with 261 features.\n",
      "Fitting estimator with 260 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 258 features.\n",
      "Fitting estimator with 257 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 255 features.\n",
      "Fitting estimator with 254 features.\n",
      "Fitting estimator with 253 features.\n",
      "Fitting estimator with 252 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 250 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 248 features.\n",
      "Fitting estimator with 247 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 245 features.\n",
      "Fitting estimator with 244 features.\n",
      "Fitting estimator with 243 features.\n",
      "Fitting estimator with 242 features.\n",
      "Fitting estimator with 241 features.\n",
      "Fitting estimator with 240 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 238 features.\n",
      "Fitting estimator with 237 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 235 features.\n",
      "Fitting estimator with 234 features.\n",
      "Fitting estimator with 233 features.\n",
      "Fitting estimator with 232 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 230 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 228 features.\n",
      "Fitting estimator with 227 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 225 features.\n",
      "Fitting estimator with 224 features.\n",
      "Fitting estimator with 223 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 221 features.\n",
      "Fitting estimator with 220 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 218 features.\n",
      "Fitting estimator with 217 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 215 features.\n",
      "Fitting estimator with 214 features.\n",
      "Fitting estimator with 213 features.\n",
      "Fitting estimator with 212 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 210 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 208 features.\n",
      "Fitting estimator with 207 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 205 features.\n",
      "Fitting estimator with 204 features.\n",
      "Fitting estimator with 203 features.\n",
      "Fitting estimator with 202 features.\n",
      "Fitting estimator with 201 features.\n",
      "Fitting estimator with 200 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 198 features.\n",
      "Fitting estimator with 197 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 195 features.\n",
      "Fitting estimator with 194 features.\n",
      "Fitting estimator with 193 features.\n",
      "Fitting estimator with 192 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 190 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 188 features.\n",
      "Fitting estimator with 187 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 185 features.\n",
      "Fitting estimator with 184 features.\n",
      "Fitting estimator with 183 features.\n",
      "Fitting estimator with 182 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 180 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 178 features.\n",
      "Fitting estimator with 177 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 174 features.\n",
      "Fitting estimator with 173 features.\n",
      "Fitting estimator with 172 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 170 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 168 features.\n",
      "Fitting estimator with 167 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 165 features.\n",
      "Fitting estimator with 164 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 162 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 160 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 158 features.\n",
      "Fitting estimator with 157 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 155 features.\n",
      "Fitting estimator with 154 features.\n",
      "Fitting estimator with 153 features.\n",
      "Fitting estimator with 152 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 150 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 148 features.\n",
      "Fitting estimator with 147 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 145 features.\n",
      "Fitting estimator with 144 features.\n",
      "Fitting estimator with 143 features.\n",
      "Fitting estimator with 142 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 140 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 138 features.\n",
      "Fitting estimator with 137 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 135 features.\n",
      "Fitting estimator with 134 features.\n",
      "Fitting estimator with 133 features.\n",
      "Fitting estimator with 132 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 130 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 128 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 125 features.\n",
      "Fitting estimator with 124 features.\n",
      "Fitting estimator with 123 features.\n",
      "Fitting estimator with 122 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 120 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 118 features.\n",
      "Fitting estimator with 117 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 114 features.\n",
      "Fitting estimator with 113 features.\n",
      "Fitting estimator with 112 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 110 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 108 features.\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 104 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 533 features.\n",
      "Fitting estimator with 532 features.\n",
      "Fitting estimator with 531 features.\n",
      "Fitting estimator with 530 features.\n",
      "Fitting estimator with 529 features.\n",
      "Fitting estimator with 528 features.\n",
      "Fitting estimator with 527 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 525 features.\n",
      "Fitting estimator with 524 features.\n",
      "Fitting estimator with 523 features.\n",
      "Fitting estimator with 522 features.\n",
      "Fitting estimator with 521 features.\n",
      "Fitting estimator with 520 features.\n",
      "Fitting estimator with 519 features.\n",
      "Fitting estimator with 518 features.\n",
      "Fitting estimator with 517 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 515 features.\n",
      "Fitting estimator with 514 features.\n",
      "Fitting estimator with 513 features.\n",
      "Fitting estimator with 512 features.\n",
      "Fitting estimator with 511 features.\n",
      "Fitting estimator with 510 features.\n",
      "Fitting estimator with 509 features.\n",
      "Fitting estimator with 508 features.\n",
      "Fitting estimator with 507 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 505 features.\n",
      "Fitting estimator with 504 features.\n",
      "Fitting estimator with 503 features.\n",
      "Fitting estimator with 502 features.\n",
      "Fitting estimator with 501 features.\n",
      "Fitting estimator with 500 features.\n",
      "Fitting estimator with 499 features.\n",
      "Fitting estimator with 498 features.\n",
      "Fitting estimator with 497 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 495 features.\n",
      "Fitting estimator with 494 features.\n",
      "Fitting estimator with 493 features.\n",
      "Fitting estimator with 492 features.\n",
      "Fitting estimator with 491 features.\n",
      "Fitting estimator with 490 features.\n",
      "Fitting estimator with 489 features.\n",
      "Fitting estimator with 488 features.\n",
      "Fitting estimator with 487 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 485 features.\n",
      "Fitting estimator with 484 features.\n",
      "Fitting estimator with 483 features.\n",
      "Fitting estimator with 482 features.\n",
      "Fitting estimator with 481 features.\n",
      "Fitting estimator with 480 features.\n",
      "Fitting estimator with 479 features.\n",
      "Fitting estimator with 478 features.\n",
      "Fitting estimator with 477 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 475 features.\n",
      "Fitting estimator with 474 features.\n",
      "Fitting estimator with 473 features.\n",
      "Fitting estimator with 472 features.\n",
      "Fitting estimator with 471 features.\n",
      "Fitting estimator with 470 features.\n",
      "Fitting estimator with 469 features.\n",
      "Fitting estimator with 468 features.\n",
      "Fitting estimator with 467 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 465 features.\n",
      "Fitting estimator with 464 features.\n",
      "Fitting estimator with 463 features.\n",
      "Fitting estimator with 462 features.\n",
      "Fitting estimator with 461 features.\n",
      "Fitting estimator with 460 features.\n",
      "Fitting estimator with 459 features.\n",
      "Fitting estimator with 458 features.\n",
      "Fitting estimator with 457 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 455 features.\n",
      "Fitting estimator with 454 features.\n",
      "Fitting estimator with 453 features.\n",
      "Fitting estimator with 452 features.\n",
      "Fitting estimator with 451 features.\n",
      "Fitting estimator with 450 features.\n",
      "Fitting estimator with 449 features.\n",
      "Fitting estimator with 448 features.\n",
      "Fitting estimator with 447 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 445 features.\n",
      "Fitting estimator with 444 features.\n",
      "Fitting estimator with 443 features.\n",
      "Fitting estimator with 442 features.\n",
      "Fitting estimator with 441 features.\n",
      "Fitting estimator with 440 features.\n",
      "Fitting estimator with 439 features.\n",
      "Fitting estimator with 438 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 435 features.\n",
      "Fitting estimator with 434 features.\n",
      "Fitting estimator with 433 features.\n",
      "Fitting estimator with 432 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 430 features.\n",
      "Fitting estimator with 429 features.\n",
      "Fitting estimator with 428 features.\n",
      "Fitting estimator with 427 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 425 features.\n",
      "Fitting estimator with 424 features.\n",
      "Fitting estimator with 423 features.\n",
      "Fitting estimator with 422 features.\n",
      "Fitting estimator with 421 features.\n",
      "Fitting estimator with 420 features.\n",
      "Fitting estimator with 419 features.\n",
      "Fitting estimator with 418 features.\n",
      "Fitting estimator with 417 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 415 features.\n",
      "Fitting estimator with 414 features.\n",
      "Fitting estimator with 413 features.\n",
      "Fitting estimator with 412 features.\n",
      "Fitting estimator with 411 features.\n",
      "Fitting estimator with 410 features.\n",
      "Fitting estimator with 409 features.\n",
      "Fitting estimator with 408 features.\n",
      "Fitting estimator with 407 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 405 features.\n",
      "Fitting estimator with 404 features.\n",
      "Fitting estimator with 403 features.\n",
      "Fitting estimator with 402 features.\n",
      "Fitting estimator with 401 features.\n",
      "Fitting estimator with 400 features.\n",
      "Fitting estimator with 399 features.\n",
      "Fitting estimator with 398 features.\n",
      "Fitting estimator with 397 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 395 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 393 features.\n",
      "Fitting estimator with 392 features.\n",
      "Fitting estimator with 391 features.\n",
      "Fitting estimator with 390 features.\n",
      "Fitting estimator with 389 features.\n",
      "Fitting estimator with 388 features.\n",
      "Fitting estimator with 387 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 385 features.\n",
      "Fitting estimator with 384 features.\n",
      "Fitting estimator with 383 features.\n",
      "Fitting estimator with 382 features.\n",
      "Fitting estimator with 381 features.\n",
      "Fitting estimator with 380 features.\n",
      "Fitting estimator with 379 features.\n",
      "Fitting estimator with 378 features.\n",
      "Fitting estimator with 377 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 375 features.\n",
      "Fitting estimator with 374 features.\n",
      "Fitting estimator with 373 features.\n",
      "Fitting estimator with 372 features.\n",
      "Fitting estimator with 371 features.\n",
      "Fitting estimator with 370 features.\n",
      "Fitting estimator with 369 features.\n",
      "Fitting estimator with 368 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 367 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 365 features.\n",
      "Fitting estimator with 364 features.\n",
      "Fitting estimator with 363 features.\n",
      "Fitting estimator with 362 features.\n",
      "Fitting estimator with 361 features.\n",
      "Fitting estimator with 360 features.\n",
      "Fitting estimator with 359 features.\n",
      "Fitting estimator with 358 features.\n",
      "Fitting estimator with 357 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 355 features.\n",
      "Fitting estimator with 354 features.\n",
      "Fitting estimator with 353 features.\n",
      "Fitting estimator with 352 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 350 features.\n",
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 348 features.\n",
      "Fitting estimator with 347 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 345 features.\n",
      "Fitting estimator with 344 features.\n",
      "Fitting estimator with 343 features.\n",
      "Fitting estimator with 342 features.\n",
      "Fitting estimator with 341 features.\n",
      "Fitting estimator with 340 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 338 features.\n",
      "Fitting estimator with 337 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 335 features.\n",
      "Fitting estimator with 334 features.\n",
      "Fitting estimator with 333 features.\n",
      "Fitting estimator with 332 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 330 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 328 features.\n",
      "Fitting estimator with 327 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 325 features.\n",
      "Fitting estimator with 324 features.\n",
      "Fitting estimator with 323 features.\n",
      "Fitting estimator with 322 features.\n",
      "Fitting estimator with 321 features.\n",
      "Fitting estimator with 320 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 318 features.\n",
      "Fitting estimator with 317 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 315 features.\n",
      "Fitting estimator with 314 features.\n",
      "Fitting estimator with 313 features.\n",
      "Fitting estimator with 312 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 310 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 307 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 305 features.\n",
      "Fitting estimator with 304 features.\n",
      "Fitting estimator with 303 features.\n",
      "Fitting estimator with 302 features.\n",
      "Fitting estimator with 301 features.\n",
      "Fitting estimator with 300 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 298 features.\n",
      "Fitting estimator with 297 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 295 features.\n",
      "Fitting estimator with 294 features.\n",
      "Fitting estimator with 293 features.\n",
      "Fitting estimator with 292 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 290 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 288 features.\n",
      "Fitting estimator with 287 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 285 features.\n",
      "Fitting estimator with 284 features.\n",
      "Fitting estimator with 283 features.\n",
      "Fitting estimator with 282 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 280 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 278 features.\n",
      "Fitting estimator with 277 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 275 features.\n",
      "Fitting estimator with 274 features.\n",
      "Fitting estimator with 273 features.\n",
      "Fitting estimator with 272 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 270 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 268 features.\n",
      "Fitting estimator with 267 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 264 features.\n",
      "Fitting estimator with 263 features.\n",
      "Fitting estimator with 262 features.\n",
      "Fitting estimator with 261 features.\n",
      "Fitting estimator with 260 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 258 features.\n",
      "Fitting estimator with 257 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 255 features.\n",
      "Fitting estimator with 254 features.\n",
      "Fitting estimator with 253 features.\n",
      "Fitting estimator with 252 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 250 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 248 features.\n",
      "Fitting estimator with 247 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 245 features.\n",
      "Fitting estimator with 244 features.\n",
      "Fitting estimator with 243 features.\n",
      "Fitting estimator with 242 features.\n",
      "Fitting estimator with 241 features.\n",
      "Fitting estimator with 240 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 238 features.\n",
      "Fitting estimator with 237 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 235 features.\n",
      "Fitting estimator with 234 features.\n",
      "Fitting estimator with 233 features.\n",
      "Fitting estimator with 232 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 230 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 228 features.\n",
      "Fitting estimator with 227 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 225 features.\n",
      "Fitting estimator with 224 features.\n",
      "Fitting estimator with 223 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 221 features.\n",
      "Fitting estimator with 220 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 218 features.\n",
      "Fitting estimator with 217 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 215 features.\n",
      "Fitting estimator with 214 features.\n",
      "Fitting estimator with 213 features.\n",
      "Fitting estimator with 212 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 210 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 208 features.\n",
      "Fitting estimator with 207 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 205 features.\n",
      "Fitting estimator with 204 features.\n",
      "Fitting estimator with 203 features.\n",
      "Fitting estimator with 202 features.\n",
      "Fitting estimator with 201 features.\n",
      "Fitting estimator with 200 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 198 features.\n",
      "Fitting estimator with 197 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 195 features.\n",
      "Fitting estimator with 194 features.\n",
      "Fitting estimator with 193 features.\n",
      "Fitting estimator with 192 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 190 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 188 features.\n",
      "Fitting estimator with 187 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 185 features.\n",
      "Fitting estimator with 184 features.\n",
      "Fitting estimator with 183 features.\n",
      "Fitting estimator with 182 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 180 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 178 features.\n",
      "Fitting estimator with 177 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 174 features.\n",
      "Fitting estimator with 173 features.\n",
      "Fitting estimator with 172 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 170 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 168 features.\n",
      "Fitting estimator with 167 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 165 features.\n",
      "Fitting estimator with 164 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 162 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 160 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 158 features.\n",
      "Fitting estimator with 157 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 155 features.\n",
      "Fitting estimator with 154 features.\n",
      "Fitting estimator with 153 features.\n",
      "Fitting estimator with 152 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 150 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 148 features.\n",
      "Fitting estimator with 147 features.\n",
      "Fitting estimator with 146 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 145 features.\n",
      "Fitting estimator with 144 features.\n",
      "Fitting estimator with 143 features.\n",
      "Fitting estimator with 142 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 140 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 138 features.\n",
      "Fitting estimator with 137 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 135 features.\n",
      "Fitting estimator with 134 features.\n",
      "Fitting estimator with 133 features.\n",
      "Fitting estimator with 132 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 130 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 128 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 125 features.\n",
      "Fitting estimator with 124 features.\n",
      "Fitting estimator with 123 features.\n",
      "Fitting estimator with 122 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 120 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 118 features.\n",
      "Fitting estimator with 117 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 114 features.\n",
      "Fitting estimator with 113 features.\n",
      "Fitting estimator with 112 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 110 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 108 features.\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 104 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 533 features.\n",
      "Fitting estimator with 532 features.\n",
      "Fitting estimator with 531 features.\n",
      "Fitting estimator with 530 features.\n",
      "Fitting estimator with 529 features.\n",
      "Fitting estimator with 528 features.\n",
      "Fitting estimator with 527 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 525 features.\n",
      "Fitting estimator with 524 features.\n",
      "Fitting estimator with 523 features.\n",
      "Fitting estimator with 522 features.\n",
      "Fitting estimator with 521 features.\n",
      "Fitting estimator with 520 features.\n",
      "Fitting estimator with 519 features.\n",
      "Fitting estimator with 518 features.\n",
      "Fitting estimator with 517 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 515 features.\n",
      "Fitting estimator with 514 features.\n",
      "Fitting estimator with 513 features.\n",
      "Fitting estimator with 512 features.\n",
      "Fitting estimator with 511 features.\n",
      "Fitting estimator with 510 features.\n",
      "Fitting estimator with 509 features.\n",
      "Fitting estimator with 508 features.\n",
      "Fitting estimator with 507 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 505 features.\n",
      "Fitting estimator with 504 features.\n",
      "Fitting estimator with 503 features.\n",
      "Fitting estimator with 502 features.\n",
      "Fitting estimator with 501 features.\n",
      "Fitting estimator with 500 features.\n",
      "Fitting estimator with 499 features.\n",
      "Fitting estimator with 498 features.\n",
      "Fitting estimator with 497 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 495 features.\n",
      "Fitting estimator with 494 features.\n",
      "Fitting estimator with 493 features.\n",
      "Fitting estimator with 492 features.\n",
      "Fitting estimator with 491 features.\n",
      "Fitting estimator with 490 features.\n",
      "Fitting estimator with 489 features.\n",
      "Fitting estimator with 488 features.\n",
      "Fitting estimator with 487 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 485 features.\n",
      "Fitting estimator with 484 features.\n",
      "Fitting estimator with 483 features.\n",
      "Fitting estimator with 482 features.\n",
      "Fitting estimator with 481 features.\n",
      "Fitting estimator with 480 features.\n",
      "Fitting estimator with 479 features.\n",
      "Fitting estimator with 478 features.\n",
      "Fitting estimator with 477 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 475 features.\n",
      "Fitting estimator with 474 features.\n",
      "Fitting estimator with 473 features.\n",
      "Fitting estimator with 472 features.\n",
      "Fitting estimator with 471 features.\n",
      "Fitting estimator with 470 features.\n",
      "Fitting estimator with 469 features.\n",
      "Fitting estimator with 468 features.\n",
      "Fitting estimator with 467 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 465 features.\n",
      "Fitting estimator with 464 features.\n",
      "Fitting estimator with 463 features.\n",
      "Fitting estimator with 462 features.\n",
      "Fitting estimator with 461 features.\n",
      "Fitting estimator with 460 features.\n",
      "Fitting estimator with 459 features.\n",
      "Fitting estimator with 458 features.\n",
      "Fitting estimator with 457 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 455 features.\n",
      "Fitting estimator with 454 features.\n",
      "Fitting estimator with 453 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 452 features.\n",
      "Fitting estimator with 451 features.\n",
      "Fitting estimator with 450 features.\n",
      "Fitting estimator with 449 features.\n",
      "Fitting estimator with 448 features.\n",
      "Fitting estimator with 447 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 445 features.\n",
      "Fitting estimator with 444 features.\n",
      "Fitting estimator with 443 features.\n",
      "Fitting estimator with 442 features.\n",
      "Fitting estimator with 441 features.\n",
      "Fitting estimator with 440 features.\n",
      "Fitting estimator with 439 features.\n",
      "Fitting estimator with 438 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 435 features.\n",
      "Fitting estimator with 434 features.\n",
      "Fitting estimator with 433 features.\n",
      "Fitting estimator with 432 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 430 features.\n",
      "Fitting estimator with 429 features.\n",
      "Fitting estimator with 428 features.\n",
      "Fitting estimator with 427 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 425 features.\n",
      "Fitting estimator with 424 features.\n",
      "Fitting estimator with 423 features.\n",
      "Fitting estimator with 422 features.\n",
      "Fitting estimator with 421 features.\n",
      "Fitting estimator with 420 features.\n",
      "Fitting estimator with 419 features.\n",
      "Fitting estimator with 418 features.\n",
      "Fitting estimator with 417 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 415 features.\n",
      "Fitting estimator with 414 features.\n",
      "Fitting estimator with 413 features.\n",
      "Fitting estimator with 412 features.\n",
      "Fitting estimator with 411 features.\n",
      "Fitting estimator with 410 features.\n",
      "Fitting estimator with 409 features.\n",
      "Fitting estimator with 408 features.\n",
      "Fitting estimator with 407 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 405 features.\n",
      "Fitting estimator with 404 features.\n",
      "Fitting estimator with 403 features.\n",
      "Fitting estimator with 402 features.\n",
      "Fitting estimator with 401 features.\n",
      "Fitting estimator with 400 features.\n",
      "Fitting estimator with 399 features.\n",
      "Fitting estimator with 398 features.\n",
      "Fitting estimator with 397 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 395 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 393 features.\n",
      "Fitting estimator with 392 features.\n",
      "Fitting estimator with 391 features.\n",
      "Fitting estimator with 390 features.\n",
      "Fitting estimator with 389 features.\n",
      "Fitting estimator with 388 features.\n",
      "Fitting estimator with 387 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 385 features.\n",
      "Fitting estimator with 384 features.\n",
      "Fitting estimator with 383 features.\n",
      "Fitting estimator with 382 features.\n",
      "Fitting estimator with 381 features.\n",
      "Fitting estimator with 380 features.\n",
      "Fitting estimator with 379 features.\n",
      "Fitting estimator with 378 features.\n",
      "Fitting estimator with 377 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 375 features.\n",
      "Fitting estimator with 374 features.\n",
      "Fitting estimator with 373 features.\n",
      "Fitting estimator with 372 features.\n",
      "Fitting estimator with 371 features.\n",
      "Fitting estimator with 370 features.\n",
      "Fitting estimator with 369 features.\n",
      "Fitting estimator with 368 features.\n",
      "Fitting estimator with 367 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 365 features.\n",
      "Fitting estimator with 364 features.\n",
      "Fitting estimator with 363 features.\n",
      "Fitting estimator with 362 features.\n",
      "Fitting estimator with 361 features.\n",
      "Fitting estimator with 360 features.\n",
      "Fitting estimator with 359 features.\n",
      "Fitting estimator with 358 features.\n",
      "Fitting estimator with 357 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 355 features.\n",
      "Fitting estimator with 354 features.\n",
      "Fitting estimator with 353 features.\n",
      "Fitting estimator with 352 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 350 features.\n",
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 348 features.\n",
      "Fitting estimator with 347 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 345 features.\n",
      "Fitting estimator with 344 features.\n",
      "Fitting estimator with 343 features.\n",
      "Fitting estimator with 342 features.\n",
      "Fitting estimator with 341 features.\n",
      "Fitting estimator with 340 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 338 features.\n",
      "Fitting estimator with 337 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 335 features.\n",
      "Fitting estimator with 334 features.\n",
      "Fitting estimator with 333 features.\n",
      "Fitting estimator with 332 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 330 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 328 features.\n",
      "Fitting estimator with 327 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 325 features.\n",
      "Fitting estimator with 324 features.\n",
      "Fitting estimator with 323 features.\n",
      "Fitting estimator with 322 features.\n",
      "Fitting estimator with 321 features.\n",
      "Fitting estimator with 320 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 318 features.\n",
      "Fitting estimator with 317 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 315 features.\n",
      "Fitting estimator with 314 features.\n",
      "Fitting estimator with 313 features.\n",
      "Fitting estimator with 312 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 310 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 307 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 305 features.\n",
      "Fitting estimator with 304 features.\n",
      "Fitting estimator with 303 features.\n",
      "Fitting estimator with 302 features.\n",
      "Fitting estimator with 301 features.\n",
      "Fitting estimator with 300 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 298 features.\n",
      "Fitting estimator with 297 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 295 features.\n",
      "Fitting estimator with 294 features.\n",
      "Fitting estimator with 293 features.\n",
      "Fitting estimator with 292 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 290 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 288 features.\n",
      "Fitting estimator with 287 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 285 features.\n",
      "Fitting estimator with 284 features.\n",
      "Fitting estimator with 283 features.\n",
      "Fitting estimator with 282 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 280 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 278 features.\n",
      "Fitting estimator with 277 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 275 features.\n",
      "Fitting estimator with 274 features.\n",
      "Fitting estimator with 273 features.\n",
      "Fitting estimator with 272 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 270 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 268 features.\n",
      "Fitting estimator with 267 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 264 features.\n",
      "Fitting estimator with 263 features.\n",
      "Fitting estimator with 262 features.\n",
      "Fitting estimator with 261 features.\n",
      "Fitting estimator with 260 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 258 features.\n",
      "Fitting estimator with 257 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 255 features.\n",
      "Fitting estimator with 254 features.\n",
      "Fitting estimator with 253 features.\n",
      "Fitting estimator with 252 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 250 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 248 features.\n",
      "Fitting estimator with 247 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 245 features.\n",
      "Fitting estimator with 244 features.\n",
      "Fitting estimator with 243 features.\n",
      "Fitting estimator with 242 features.\n",
      "Fitting estimator with 241 features.\n",
      "Fitting estimator with 240 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 238 features.\n",
      "Fitting estimator with 237 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 235 features.\n",
      "Fitting estimator with 234 features.\n",
      "Fitting estimator with 233 features.\n",
      "Fitting estimator with 232 features.\n",
      "Fitting estimator with 231 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 230 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 228 features.\n",
      "Fitting estimator with 227 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 225 features.\n",
      "Fitting estimator with 224 features.\n",
      "Fitting estimator with 223 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 221 features.\n",
      "Fitting estimator with 220 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 218 features.\n",
      "Fitting estimator with 217 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 215 features.\n",
      "Fitting estimator with 214 features.\n",
      "Fitting estimator with 213 features.\n",
      "Fitting estimator with 212 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 210 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 208 features.\n",
      "Fitting estimator with 207 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 205 features.\n",
      "Fitting estimator with 204 features.\n",
      "Fitting estimator with 203 features.\n",
      "Fitting estimator with 202 features.\n",
      "Fitting estimator with 201 features.\n",
      "Fitting estimator with 200 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 198 features.\n",
      "Fitting estimator with 197 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 195 features.\n",
      "Fitting estimator with 194 features.\n",
      "Fitting estimator with 193 features.\n",
      "Fitting estimator with 192 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 190 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 188 features.\n",
      "Fitting estimator with 187 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 185 features.\n",
      "Fitting estimator with 184 features.\n",
      "Fitting estimator with 183 features.\n",
      "Fitting estimator with 182 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 180 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 178 features.\n",
      "Fitting estimator with 177 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 174 features.\n",
      "Fitting estimator with 173 features.\n",
      "Fitting estimator with 172 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 170 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 168 features.\n",
      "Fitting estimator with 167 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 165 features.\n",
      "Fitting estimator with 164 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 162 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 160 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 158 features.\n",
      "Fitting estimator with 157 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 155 features.\n",
      "Fitting estimator with 154 features.\n",
      "Fitting estimator with 153 features.\n",
      "Fitting estimator with 152 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 150 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 148 features.\n",
      "Fitting estimator with 147 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 145 features.\n",
      "Fitting estimator with 144 features.\n",
      "Fitting estimator with 143 features.\n",
      "Fitting estimator with 142 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 140 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 138 features.\n",
      "Fitting estimator with 137 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 135 features.\n",
      "Fitting estimator with 134 features.\n",
      "Fitting estimator with 133 features.\n",
      "Fitting estimator with 132 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 130 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 128 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 125 features.\n",
      "Fitting estimator with 124 features.\n",
      "Fitting estimator with 123 features.\n",
      "Fitting estimator with 122 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 120 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 118 features.\n",
      "Fitting estimator with 117 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 114 features.\n",
      "Fitting estimator with 113 features.\n",
      "Fitting estimator with 112 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 110 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 108 features.\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 104 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 533 features.\n",
      "Fitting estimator with 532 features.\n",
      "Fitting estimator with 531 features.\n",
      "Fitting estimator with 530 features.\n",
      "Fitting estimator with 529 features.\n",
      "Fitting estimator with 528 features.\n",
      "Fitting estimator with 527 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 525 features.\n",
      "Fitting estimator with 524 features.\n",
      "Fitting estimator with 523 features.\n",
      "Fitting estimator with 522 features.\n",
      "Fitting estimator with 521 features.\n",
      "Fitting estimator with 520 features.\n",
      "Fitting estimator with 519 features.\n",
      "Fitting estimator with 518 features.\n",
      "Fitting estimator with 517 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 515 features.\n",
      "Fitting estimator with 514 features.\n",
      "Fitting estimator with 513 features.\n",
      "Fitting estimator with 512 features.\n",
      "Fitting estimator with 511 features.\n",
      "Fitting estimator with 510 features.\n",
      "Fitting estimator with 509 features.\n",
      "Fitting estimator with 508 features.\n",
      "Fitting estimator with 507 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 505 features.\n",
      "Fitting estimator with 504 features.\n",
      "Fitting estimator with 503 features.\n",
      "Fitting estimator with 502 features.\n",
      "Fitting estimator with 501 features.\n",
      "Fitting estimator with 500 features.\n",
      "Fitting estimator with 499 features.\n",
      "Fitting estimator with 498 features.\n",
      "Fitting estimator with 497 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 495 features.\n",
      "Fitting estimator with 494 features.\n",
      "Fitting estimator with 493 features.\n",
      "Fitting estimator with 492 features.\n",
      "Fitting estimator with 491 features.\n",
      "Fitting estimator with 490 features.\n",
      "Fitting estimator with 489 features.\n",
      "Fitting estimator with 488 features.\n",
      "Fitting estimator with 487 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 485 features.\n",
      "Fitting estimator with 484 features.\n",
      "Fitting estimator with 483 features.\n",
      "Fitting estimator with 482 features.\n",
      "Fitting estimator with 481 features.\n",
      "Fitting estimator with 480 features.\n",
      "Fitting estimator with 479 features.\n",
      "Fitting estimator with 478 features.\n",
      "Fitting estimator with 477 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 475 features.\n",
      "Fitting estimator with 474 features.\n",
      "Fitting estimator with 473 features.\n",
      "Fitting estimator with 472 features.\n",
      "Fitting estimator with 471 features.\n",
      "Fitting estimator with 470 features.\n",
      "Fitting estimator with 469 features.\n",
      "Fitting estimator with 468 features.\n",
      "Fitting estimator with 467 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 465 features.\n",
      "Fitting estimator with 464 features.\n",
      "Fitting estimator with 463 features.\n",
      "Fitting estimator with 462 features.\n",
      "Fitting estimator with 461 features.\n",
      "Fitting estimator with 460 features.\n",
      "Fitting estimator with 459 features.\n",
      "Fitting estimator with 458 features.\n",
      "Fitting estimator with 457 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 455 features.\n",
      "Fitting estimator with 454 features.\n",
      "Fitting estimator with 453 features.\n",
      "Fitting estimator with 452 features.\n",
      "Fitting estimator with 451 features.\n",
      "Fitting estimator with 450 features.\n",
      "Fitting estimator with 449 features.\n",
      "Fitting estimator with 448 features.\n",
      "Fitting estimator with 447 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 445 features.\n",
      "Fitting estimator with 444 features.\n",
      "Fitting estimator with 443 features.\n",
      "Fitting estimator with 442 features.\n",
      "Fitting estimator with 441 features.\n",
      "Fitting estimator with 440 features.\n",
      "Fitting estimator with 439 features.\n",
      "Fitting estimator with 438 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 435 features.\n",
      "Fitting estimator with 434 features.\n",
      "Fitting estimator with 433 features.\n",
      "Fitting estimator with 432 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 430 features.\n",
      "Fitting estimator with 429 features.\n",
      "Fitting estimator with 428 features.\n",
      "Fitting estimator with 427 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 425 features.\n",
      "Fitting estimator with 424 features.\n",
      "Fitting estimator with 423 features.\n",
      "Fitting estimator with 422 features.\n",
      "Fitting estimator with 421 features.\n",
      "Fitting estimator with 420 features.\n",
      "Fitting estimator with 419 features.\n",
      "Fitting estimator with 418 features.\n",
      "Fitting estimator with 417 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 415 features.\n",
      "Fitting estimator with 414 features.\n",
      "Fitting estimator with 413 features.\n",
      "Fitting estimator with 412 features.\n",
      "Fitting estimator with 411 features.\n",
      "Fitting estimator with 410 features.\n",
      "Fitting estimator with 409 features.\n",
      "Fitting estimator with 408 features.\n",
      "Fitting estimator with 407 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 405 features.\n",
      "Fitting estimator with 404 features.\n",
      "Fitting estimator with 403 features.\n",
      "Fitting estimator with 402 features.\n",
      "Fitting estimator with 401 features.\n",
      "Fitting estimator with 400 features.\n",
      "Fitting estimator with 399 features.\n",
      "Fitting estimator with 398 features.\n",
      "Fitting estimator with 397 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 395 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 393 features.\n",
      "Fitting estimator with 392 features.\n",
      "Fitting estimator with 391 features.\n",
      "Fitting estimator with 390 features.\n",
      "Fitting estimator with 389 features.\n",
      "Fitting estimator with 388 features.\n",
      "Fitting estimator with 387 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 385 features.\n",
      "Fitting estimator with 384 features.\n",
      "Fitting estimator with 383 features.\n",
      "Fitting estimator with 382 features.\n",
      "Fitting estimator with 381 features.\n",
      "Fitting estimator with 380 features.\n",
      "Fitting estimator with 379 features.\n",
      "Fitting estimator with 378 features.\n",
      "Fitting estimator with 377 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 375 features.\n",
      "Fitting estimator with 374 features.\n",
      "Fitting estimator with 373 features.\n",
      "Fitting estimator with 372 features.\n",
      "Fitting estimator with 371 features.\n",
      "Fitting estimator with 370 features.\n",
      "Fitting estimator with 369 features.\n",
      "Fitting estimator with 368 features.\n",
      "Fitting estimator with 367 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 365 features.\n",
      "Fitting estimator with 364 features.\n",
      "Fitting estimator with 363 features.\n",
      "Fitting estimator with 362 features.\n",
      "Fitting estimator with 361 features.\n",
      "Fitting estimator with 360 features.\n",
      "Fitting estimator with 359 features.\n",
      "Fitting estimator with 358 features.\n",
      "Fitting estimator with 357 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 355 features.\n",
      "Fitting estimator with 354 features.\n",
      "Fitting estimator with 353 features.\n",
      "Fitting estimator with 352 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 350 features.\n",
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 348 features.\n",
      "Fitting estimator with 347 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 345 features.\n",
      "Fitting estimator with 344 features.\n",
      "Fitting estimator with 343 features.\n",
      "Fitting estimator with 342 features.\n",
      "Fitting estimator with 341 features.\n",
      "Fitting estimator with 340 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 338 features.\n",
      "Fitting estimator with 337 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 335 features.\n",
      "Fitting estimator with 334 features.\n",
      "Fitting estimator with 333 features.\n",
      "Fitting estimator with 332 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 330 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 328 features.\n",
      "Fitting estimator with 327 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 325 features.\n",
      "Fitting estimator with 324 features.\n",
      "Fitting estimator with 323 features.\n",
      "Fitting estimator with 322 features.\n",
      "Fitting estimator with 321 features.\n",
      "Fitting estimator with 320 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 318 features.\n",
      "Fitting estimator with 317 features.\n",
      "Fitting estimator with 316 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 315 features.\n",
      "Fitting estimator with 314 features.\n",
      "Fitting estimator with 313 features.\n",
      "Fitting estimator with 312 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 310 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 307 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 305 features.\n",
      "Fitting estimator with 304 features.\n",
      "Fitting estimator with 303 features.\n",
      "Fitting estimator with 302 features.\n",
      "Fitting estimator with 301 features.\n",
      "Fitting estimator with 300 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 298 features.\n",
      "Fitting estimator with 297 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 295 features.\n",
      "Fitting estimator with 294 features.\n",
      "Fitting estimator with 293 features.\n",
      "Fitting estimator with 292 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 290 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 288 features.\n",
      "Fitting estimator with 287 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 285 features.\n",
      "Fitting estimator with 284 features.\n",
      "Fitting estimator with 283 features.\n",
      "Fitting estimator with 282 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 280 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 278 features.\n",
      "Fitting estimator with 277 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 275 features.\n",
      "Fitting estimator with 274 features.\n",
      "Fitting estimator with 273 features.\n",
      "Fitting estimator with 272 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 270 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 268 features.\n",
      "Fitting estimator with 267 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 264 features.\n",
      "Fitting estimator with 263 features.\n",
      "Fitting estimator with 262 features.\n",
      "Fitting estimator with 261 features.\n",
      "Fitting estimator with 260 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 258 features.\n",
      "Fitting estimator with 257 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 255 features.\n",
      "Fitting estimator with 254 features.\n",
      "Fitting estimator with 253 features.\n",
      "Fitting estimator with 252 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 250 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 248 features.\n",
      "Fitting estimator with 247 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 245 features.\n",
      "Fitting estimator with 244 features.\n",
      "Fitting estimator with 243 features.\n",
      "Fitting estimator with 242 features.\n",
      "Fitting estimator with 241 features.\n",
      "Fitting estimator with 240 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 238 features.\n",
      "Fitting estimator with 237 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 235 features.\n",
      "Fitting estimator with 234 features.\n",
      "Fitting estimator with 233 features.\n",
      "Fitting estimator with 232 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 230 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 228 features.\n",
      "Fitting estimator with 227 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 225 features.\n",
      "Fitting estimator with 224 features.\n",
      "Fitting estimator with 223 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 221 features.\n",
      "Fitting estimator with 220 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 218 features.\n",
      "Fitting estimator with 217 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 215 features.\n",
      "Fitting estimator with 214 features.\n",
      "Fitting estimator with 213 features.\n",
      "Fitting estimator with 212 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 210 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 208 features.\n",
      "Fitting estimator with 207 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 205 features.\n",
      "Fitting estimator with 204 features.\n",
      "Fitting estimator with 203 features.\n",
      "Fitting estimator with 202 features.\n",
      "Fitting estimator with 201 features.\n",
      "Fitting estimator with 200 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 198 features.\n",
      "Fitting estimator with 197 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 195 features.\n",
      "Fitting estimator with 194 features.\n",
      "Fitting estimator with 193 features.\n",
      "Fitting estimator with 192 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 190 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 188 features.\n",
      "Fitting estimator with 187 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 185 features.\n"
     ]
    }
   ],
   "source": [
    "estimator = RandomForestClassifier(n_estimators=200, max_depth=8, max_features = 'auto', criterion = 'gini')\n",
    "\n",
    "min_features_to_select = 1\n",
    "selector = RFECV(estimator, step=1, cv=5, scoring='accuracy', min_features_to_select=min_features_to_select, verbose = 2)\n",
    "selector = selector.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.style.use('fivethirtyeight')\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(min_features_to_select,\n",
    "               len(selector.grid_scores_) + min_features_to_select),selector.grid_scores_)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_features = np.sum(selector.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=100)\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score\")\n",
    "\n",
    "ax.plot(range(min_features_to_select,\n",
    "        len(selector.grid_scores_) + min_features_to_select),\n",
    "        selector.grid_scores_, linewidth='2', color='steelblue')\n",
    "\n",
    "ax.set_facecolor('white')\n",
    "fig.set_facecolor('white')\n",
    "plt.grid(color='#d4d4d4')\n",
    "fig.suptitle('Feature Selection with RFECV', fontsize=20)\n",
    "ax.text(nbr_features, 0.75, 'best: '+str(nbr_features), ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False,  True,  True, False, False,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "       False, False, False, False,  True,  True,  True,  True,  True,\n",
       "        True, False,  True, False,  True, False, False, False,  True,\n",
       "        True, False,  True, False,  True,  True,  True,  True,  True,\n",
       "        True, False, False, False,  True,  True,  True,  True,  True,\n",
       "       False,  True, False, False, False,  True, False,  True, False,\n",
       "       False, False, False,  True, False,  True,  True, False, False,\n",
       "        True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True,  True,  True,  True, False, False,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True, False,  True, False, False,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True, False,\n",
       "        True,  True, False,  True, False,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True, False, False,  True,  True,  True, False, False,\n",
       "       False, False, False, False,  True,  True,  True, False, False,\n",
       "       False, False,  True, False, False,  True,  True, False,  True,\n",
       "        True, False,  True, False, False, False, False, False, False,\n",
       "       False,  True, False, False,  True,  True, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False,  True,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True,  True,  True, False, False, False, False, False,  True,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "        True,  True, False, False,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False,  True, False, False,\n",
       "        True,  True, False, False, False, False,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "        True, False, False, False, False, False, False,  True, False,\n",
       "       False, False,  True, False, False,  True, False, False, False,\n",
       "        True, False, False, False,  True,  True, False,  True,  True,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False,  True,  True, False,  True,  True, False, False,\n",
       "       False,  True, False, False, False, False,  True, False,  True,\n",
       "        True, False,  True,  True, False, False, False, False, False,\n",
       "        True,  True,  True, False,  True,  True, False,  True, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False,  True, False,  True,  True,  True, False, False,\n",
       "        True, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False,  True, False, False,  True,\n",
       "        True, False, False, False, False,  True,  True,  True, False,\n",
       "       False,  True])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(selector.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([147,   1,  57,   1,   1,   9,  63,   1,   1,   1,   1, 112,   1,\n",
       "         1,   1,   1,   1,   1, 158, 225,  53, 110,   1,   1,   1,   1,\n",
       "         1,   1,   6,   1,  35,   1,  87, 186,  28,   1,   1,  24,   1,\n",
       "       115,   1,   1,   1,   1,   1,   1, 128, 195, 117,   1,   1,   1,\n",
       "         1,   1,  21,   1, 133,  93,  83,   1,  67,   1,  44, 136,  56,\n",
       "       168,   1, 236,   1,   1, 270, 272,   1,   1,   1,   1,   1,   1,\n",
       "       228,   1, 206, 226, 151, 169, 161, 171, 302, 172, 154, 193, 164,\n",
       "       189, 253,   1, 289, 266, 258, 210, 262, 349, 316, 260, 215, 240,\n",
       "       175, 315, 281,   1, 320, 314, 241, 232, 325, 346, 252, 271, 259,\n",
       "       311, 267, 347, 276,   1, 307, 265, 205, 277, 284, 255, 334, 294,\n",
       "       248, 197, 275, 301, 251,   1, 245, 273, 264, 229, 179, 254, 238,\n",
       "       174, 209, 292, 223, 214, 199,   1, 246, 291, 285, 283, 239, 282,\n",
       "       261, 268, 192, 274, 269, 286, 296,   1, 221, 208, 181, 200, 216,\n",
       "       203, 170, 187, 111, 212,   1,   1,   1,   1,  98, 156,   1,   1,\n",
       "         1,   1,   1,  23,   1,   1,   1,   1,   1,  17,   1, 121, 190,\n",
       "         1,   1,   1,   1,   1,  38,   1,   1,   1,   1,   1,  16,   1,\n",
       "         1,  37,   1,  11,   1,   1,   1, 220,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1, 297,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "       180,   1, 303, 287,   1,   1,   1, 335, 333, 202, 322, 338, 324,\n",
       "         1,   1,   1, 176,  92, 339, 344,   1, 114,  42,   1,   1, 319,\n",
       "         1,   1,   7,   1, 321, 308, 134, 343,  69, 167, 329,   1, 340,\n",
       "       305,   1,   1, 213,   1, 328, 256, 233, 327, 330, 318, 278, 290,\n",
       "       313, 146,   1,   1, 345, 332, 342, 337, 312, 306, 350, 336, 323,\n",
       "       326, 331, 348, 309,   1, 119,   1, 299, 341, 317, 234, 310, 280,\n",
       "         1, 230, 107,   1,   1,   1, 166, 144, 288, 304, 184,   1,   1,\n",
       "        46, 108,   1,  82,  88, 162,  22,  85,   1,   1,  14,  45,   1,\n",
       "         1, 244, 148, 237, 231, 300, 178,  47,  73, 159, 142, 194, 243,\n",
       "       135,   1, 109,  70,  30,  80,  89, 131,  66,  96, 127,   1, 120,\n",
       "        27,  68,   1, 123,  50,   1,   1,  77, 157, 125,  58,   1,   4,\n",
       "        65,  94,  25,   1, 263, 235, 293,  55, 198,  74,  72,  99,  41,\n",
       "        86, 247, 250,   1, 218,  62,  91,  15,   8,  19,   1, 153,  52,\n",
       "        78, 130, 279, 295, 149, 217, 143, 129, 182, 163,   1,   1,  59,\n",
       "        48,  51,  34, 257, 298,   1, 207, 101, 145,   1, 137, 177,   1,\n",
       "        29, 103,  36,   1, 222, 118,  12,   1,   1, 113,   1,   1,  90,\n",
       "         1, 201,  49, 185, 183, 155, 150,  54, 116,  31,   1,   1, 242,\n",
       "         1,   1,  32,  60,  20,   1, 173, 122,  13,   5,   1, 138,   1,\n",
       "         1, 106,   1,   1, 126,  61,   3, 204, 139,   1,   1,   1,  40,\n",
       "         1,   1,  43,   1, 124,  97, 100, 188,  71,  64,  84,  79,   1,\n",
       "       102, 219, 196,   1, 141,   1,   1,   1, 140,  18,   1, 132, 165,\n",
       "         2,  81, 211, 227,   1, 160,  75,  26,  10, 191, 104,   1,  95,\n",
       "       105,   1,   1, 249, 224,  39, 152,   1,   1,   1,  76,  33,   1])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10', 'E11',\n",
       "       'E12', 'E13', 'E14', 'E15', 'E16', 'E17', 'E18', 'E19', 'E20',\n",
       "       'E21', 'E22', 'E23', 'E24', 'E25', 'E26', 'E27', 'E28', 'E29',\n",
       "       'E30', 'E31', 'E32', 'E33', 'E34', 'E35', 'E36', 'E37', 'E38',\n",
       "       'E39', 'E40', 'E41', 'E42', 'E43', 'E44', 'E45', 'E46', 'E47',\n",
       "       'E48', 'E49', 'E50', 'E51', 'E52', 'E53', 'E54', 'E55', 'E56',\n",
       "       'E57', 'E58', 'E59', 'E60', 'E61', 'E62', 'E63', 'E64', 'E65',\n",
       "       'E66', 'E67', 'E68', 'E69', 'E70', 'E71', 'E72', 'E73', 'E74',\n",
       "       'E75', 'E76', 'E77', 'E78', 'E79', 'E80', 'E81', 'E82', 'E83',\n",
       "       'E84', 'E85', 'E86', 'E87', 'E88', 'E89', 'E90', 'E91', 'E92',\n",
       "       'E93', 'E94', 'E95', 'E96', 'E97', 'E98', 'E99', 'E100', 'E101',\n",
       "       'E102', 'E103', 'E104', 'E105', 'E106', 'E107', 'E108', 'E109',\n",
       "       'E110', 'E111', 'E112', 'E113', 'E114', 'E115', 'E116', 'E117',\n",
       "       'E118', 'E119', 'E120', 'E121', 'E122', 'E123', 'E124', 'E125',\n",
       "       'E126', 'E127', 'E128', 'E129', 'E130', 'E131', 'E132', 'E133',\n",
       "       'E134', 'E135', 'E136', 'E137', 'E138', 'E139', 'E140', 'E141',\n",
       "       'E142', 'E143', 'E144', 'E145', 'E146', 'E147', 'E148', 'E149',\n",
       "       'E150', 'E151', 'E152', 'E153', 'E154', 'E155', 'E156', 'E157',\n",
       "       'E158', 'E159', 'E160', 'E161', 'E162', 'E163', 'E164', 'E165',\n",
       "       'E166', 'E167', 'E168', 'E169', 'E170', 'E171', 'E172', 'E173',\n",
       "       'E174', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9',\n",
       "       'T10', 'T11', 'T12', 'T13', 'T14', 'T15', 'T16', 'T17', 'T18',\n",
       "       'T19', 'T20', 'T21', 'T22', 'T23', 'T24', 'T25', 'T26', 'T27',\n",
       "       'T28', 'T29', 'T30', 'T31', 'T32', 'T33', 'T34', 'T35', 'T36',\n",
       "       'T37', 'T38', 'T39', 'T40', 'T41', 'T42', 'T43', 'T44', 'T45',\n",
       "       'T46', 'T47', 'T48', 'T49', 'T50', 'T51', 'T52', 'T53', 'T54',\n",
       "       'T55', 'T56', 'T57', 'T58', 'T59', 'T60', 'T61', 'T62', 'T63',\n",
       "       'T64', 'T65', 'T66', 'T67', 'T68', 'T69', 'T70', 'T71', 'T72',\n",
       "       'T73', 'T74', 'T75', 'T76', 'T77', 'T78', 'T79', 'T80', 'T81',\n",
       "       'T82', 'T83', 'T84', 'T85', 'T86', 'T87', 'T88', 'T89', 'T90',\n",
       "       'T91', 'T92', 'T93', 'T94', 'T95', 'T96', 'T97', 'T98', 'T99',\n",
       "       'T100', 'T101', 'T102', 'T103', 'T104', 'T105', 'T106', 'T107',\n",
       "       'T108', 'T109', 'T110', 'T111', 'T112', 'T113', 'T114', 'T115',\n",
       "       'T116', 'T117', 'T118', 'T119', 'T120', 'T121', 'T122', 'T123',\n",
       "       'T124', 'T125', 'T126', 'T127', 'T128', 'T129', 'T130', 'T131',\n",
       "       'T132', 'T133', 'T134', 'T135', 'T136', 'T137', 'T138', 'T139',\n",
       "       'T140', 'T141', 'T142', 'T143', 'T144', 'T145', 'T146', 'T147',\n",
       "       'T148', 'T149', 'T150', 'T151', 'DA1', 'DA2', 'DA3', 'DA4', 'DA5',\n",
       "       'DA6', 'DA7', 'DA8', 'DA9', 'DA10', 'DA11', 'DA12', 'DA13', 'DA14',\n",
       "       'DA15', 'DA16', 'DA17', 'DA18', 'DA19', 'DA20', 'DA21', 'DA22',\n",
       "       'DA23', 'DA24', 'DA25', 'DA26', 'DA27', 'DA28', 'DA29', 'DA30',\n",
       "       'DA31', 'DA32', 'DA33', 'DA34', 'DA35', 'DA36', 'DA37', 'DA38',\n",
       "       'DA39', 'DA40', 'DA41', 'DA42', 'DA43', 'DA44', 'DA45', 'DA46',\n",
       "       'DA47', 'DA48', 'DA49', 'DA50', 'DA51', 'DA52', 'DA53', 'DA54',\n",
       "       'DA55', 'DA56', 'DA57', 'DA58', 'DA59', 'DA60', 'DA61', 'DA62',\n",
       "       'DA63', 'DA64', 'DA65', 'DA66', 'DA67', 'DA68', 'DA69', 'DA70',\n",
       "       'DA71', 'DA72', 'DA73', 'DA74', 'DA75', 'DA76', 'DA77', 'DA78',\n",
       "       'DA79', 'DA80', 'DA81', 'DA82', 'DA83', 'DA84', 'DA85', 'DA86',\n",
       "       'DA87', 'DA88', 'DA89', 'DA90', 'DA91', 'DA92', 'DA93', 'DA94',\n",
       "       'DA95', 'DA96', 'DA97', 'DA98', 'DA99', 'DA100', 'DA101', 'DA102',\n",
       "       'DA103', 'DA104', 'DH1', 'DH2', 'DH3', 'DH4', 'DH5', 'DH6', 'DH7',\n",
       "       'DH8', 'DH9', 'DH10', 'DH11', 'DH12', 'DH13', 'DH14', 'DH15',\n",
       "       'DH16', 'DH17', 'DH18', 'DH19', 'DH20', 'DH21', 'DH22', 'DH23',\n",
       "       'DH24', 'DH25', 'DH26', 'DH27', 'DH28', 'DH29', 'DH30', 'DH31',\n",
       "       'DH32', 'DH33', 'DH34', 'DH35', 'DH36', 'DH37', 'DH38', 'DH39',\n",
       "       'DH40', 'DH41', 'DH42', 'DH43', 'DH44', 'DH45', 'DH46', 'DH47',\n",
       "       'DH48', 'DH49', 'DH50', 'DH51', 'DH52', 'DH53', 'DH54', 'DH55',\n",
       "       'DH56', 'DH57', 'DH58', 'DH59', 'DH60', 'DH61', 'DH62', 'DH63',\n",
       "       'DH64', 'DH65', 'DH66', 'DH67', 'DH68', 'DH69', 'DH70', 'DH71',\n",
       "       'DH72', 'DH73', 'DH74', 'DH75', 'DH76', 'DH77', 'DH78', 'DH79',\n",
       "       'DH80', 'DH81', 'DH82', 'DH83', 'DH84', 'DH85', 'DH86', 'DH87',\n",
       "       'DH88', 'DH89', 'DH90', 'DH91', 'DH92', 'DH93', 'DH94', 'DH95',\n",
       "       'DH96', 'DH97', 'DH98', 'DH99', 'DH100', 'DH101', 'DH102', 'DH103',\n",
       "       'DH104'], dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.array(data_input.columns)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['E2', 'E4', 'E5', 'E8', 'E9', 'E10', 'E11', 'E13', 'E14', 'E15',\n",
       "       'E16', 'E17', 'E18', 'E23', 'E24', 'E25', 'E26', 'E27', 'E28',\n",
       "       'E30', 'E32', 'E36', 'E37', 'E39', 'E41', 'E42', 'E43', 'E44',\n",
       "       'E45', 'E46', 'E50', 'E51', 'E52', 'E53', 'E54', 'E56', 'E60',\n",
       "       'E62', 'E67', 'E69', 'E70', 'E73', 'E74', 'E75', 'E76', 'E77',\n",
       "       'E78', 'E80', 'E94', 'E108', 'E122', 'E136', 'E150', 'E164', 'T1',\n",
       "       'T2', 'T3', 'T4', 'T7', 'T8', 'T9', 'T10', 'T11', 'T13', 'T14',\n",
       "       'T15', 'T16', 'T17', 'T19', 'T22', 'T23', 'T24', 'T25', 'T26',\n",
       "       'T28', 'T29', 'T30', 'T31', 'T32', 'T34', 'T35', 'T37', 'T39',\n",
       "       'T40', 'T41', 'T43', 'T44', 'T45', 'T46', 'T47', 'T48', 'T49',\n",
       "       'T50', 'T52', 'T53', 'T54', 'T55', 'T56', 'T57', 'T58', 'T59',\n",
       "       'T60', 'T62', 'T65', 'T66', 'T67', 'T74', 'T75', 'T76', 'T81',\n",
       "       'T84', 'T85', 'T87', 'T88', 'T90', 'T98', 'T101', 'T102', 'T104',\n",
       "       'T115', 'T116', 'T130', 'T132', 'T139', 'T142', 'T143', 'T144',\n",
       "       'T150', 'T151', 'DA3', 'DA9', 'DA10', 'DA13', 'DA14', 'DA28',\n",
       "       'DA38', 'DA42', 'DA45', 'DA46', 'DA51', 'DA56', 'DA69', 'DA76',\n",
       "       'DA89', 'DA90', 'DA97', 'DA101', 'DA104', 'DH4', 'DH8', 'DH9',\n",
       "       'DH11', 'DH12', 'DH14', 'DH24', 'DH25', 'DH27', 'DH28', 'DH32',\n",
       "       'DH37', 'DH39', 'DH40', 'DH42', 'DH43', 'DH49', 'DH50', 'DH51',\n",
       "       'DH53', 'DH54', 'DH56', 'DH65', 'DH69', 'DH71', 'DH72', 'DH73',\n",
       "       'DH76', 'DH83', 'DH90', 'DH93', 'DH94', 'DH99', 'DH100', 'DH101',\n",
       "       'DH104'], dtype=object)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv = features[np.array(selector.support_)]\n",
    "rfecv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rfecv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person</th>\n",
       "      <th>class</th>\n",
       "      <th>E2</th>\n",
       "      <th>E4</th>\n",
       "      <th>E5</th>\n",
       "      <th>E8</th>\n",
       "      <th>E9</th>\n",
       "      <th>E10</th>\n",
       "      <th>E11</th>\n",
       "      <th>E13</th>\n",
       "      <th>...</th>\n",
       "      <th>DH73</th>\n",
       "      <th>DH76</th>\n",
       "      <th>DH83</th>\n",
       "      <th>DH90</th>\n",
       "      <th>DH93</th>\n",
       "      <th>DH94</th>\n",
       "      <th>DH99</th>\n",
       "      <th>DH100</th>\n",
       "      <th>DH101</th>\n",
       "      <th>DH104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.254095</td>\n",
       "      <td>-0.01037</td>\n",
       "      <td>-0.538509</td>\n",
       "      <td>-1.37437</td>\n",
       "      <td>-0.10937</td>\n",
       "      <td>0.10763</td>\n",
       "      <td>0.093296</td>\n",
       "      <td>0.172694</td>\n",
       "      <td>...</td>\n",
       "      <td>12.09630</td>\n",
       "      <td>4901420.0</td>\n",
       "      <td>1.160800e+09</td>\n",
       "      <td>4902090.0</td>\n",
       "      <td>10.43340</td>\n",
       "      <td>5.83548</td>\n",
       "      <td>2.53425</td>\n",
       "      <td>17.3882</td>\n",
       "      <td>8.05589</td>\n",
       "      <td>3028080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.193761</td>\n",
       "      <td>-0.00237</td>\n",
       "      <td>0.781415</td>\n",
       "      <td>-0.71937</td>\n",
       "      <td>-0.08737</td>\n",
       "      <td>0.11163</td>\n",
       "      <td>0.079461</td>\n",
       "      <td>0.142173</td>\n",
       "      <td>...</td>\n",
       "      <td>11.62070</td>\n",
       "      <td>4882550.0</td>\n",
       "      <td>1.142700e+09</td>\n",
       "      <td>4883220.0</td>\n",
       "      <td>10.24230</td>\n",
       "      <td>5.76355</td>\n",
       "      <td>2.51513</td>\n",
       "      <td>16.5914</td>\n",
       "      <td>7.81769</td>\n",
       "      <td>3016420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.182336</td>\n",
       "      <td>-0.02337</td>\n",
       "      <td>0.881194</td>\n",
       "      <td>-0.71937</td>\n",
       "      <td>-0.08037</td>\n",
       "      <td>0.08863</td>\n",
       "      <td>0.074408</td>\n",
       "      <td>0.131310</td>\n",
       "      <td>...</td>\n",
       "      <td>10.57340</td>\n",
       "      <td>4863140.0</td>\n",
       "      <td>1.015080e+09</td>\n",
       "      <td>4863810.0</td>\n",
       "      <td>9.27871</td>\n",
       "      <td>5.16683</td>\n",
       "      <td>2.25959</td>\n",
       "      <td>15.2312</td>\n",
       "      <td>7.11684</td>\n",
       "      <td>3004430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.176636</td>\n",
       "      <td>-0.02737</td>\n",
       "      <td>1.024900</td>\n",
       "      <td>-0.71937</td>\n",
       "      <td>-0.08037</td>\n",
       "      <td>0.07163</td>\n",
       "      <td>0.070138</td>\n",
       "      <td>0.125188</td>\n",
       "      <td>...</td>\n",
       "      <td>9.85611</td>\n",
       "      <td>4843300.0</td>\n",
       "      <td>9.061740e+08</td>\n",
       "      <td>4843960.0</td>\n",
       "      <td>8.65402</td>\n",
       "      <td>4.63212</td>\n",
       "      <td>2.13924</td>\n",
       "      <td>14.4663</td>\n",
       "      <td>6.70236</td>\n",
       "      <td>2992170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.179248</td>\n",
       "      <td>-0.02737</td>\n",
       "      <td>0.935697</td>\n",
       "      <td>-0.75637</td>\n",
       "      <td>-0.08337</td>\n",
       "      <td>0.07163</td>\n",
       "      <td>0.072914</td>\n",
       "      <td>0.127866</td>\n",
       "      <td>...</td>\n",
       "      <td>8.87342</td>\n",
       "      <td>4822950.0</td>\n",
       "      <td>7.843120e+08</td>\n",
       "      <td>4823610.0</td>\n",
       "      <td>7.78651</td>\n",
       "      <td>4.23410</td>\n",
       "      <td>1.93595</td>\n",
       "      <td>12.5493</td>\n",
       "      <td>6.08647</td>\n",
       "      <td>2979610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4475</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.254373</td>\n",
       "      <td>-0.00101</td>\n",
       "      <td>-0.165105</td>\n",
       "      <td>-1.19301</td>\n",
       "      <td>-0.15801</td>\n",
       "      <td>0.12299</td>\n",
       "      <td>0.115445</td>\n",
       "      <td>0.187620</td>\n",
       "      <td>...</td>\n",
       "      <td>50.11640</td>\n",
       "      <td>645724.0</td>\n",
       "      <td>5.241020e+09</td>\n",
       "      <td>645610.0</td>\n",
       "      <td>45.16100</td>\n",
       "      <td>24.78100</td>\n",
       "      <td>9.48535</td>\n",
       "      <td>73.9901</td>\n",
       "      <td>31.82590</td>\n",
       "      <td>398810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4476</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.238946</td>\n",
       "      <td>-0.00901</td>\n",
       "      <td>-0.034522</td>\n",
       "      <td>-1.10201</td>\n",
       "      <td>-0.14501</td>\n",
       "      <td>0.11899</td>\n",
       "      <td>0.109450</td>\n",
       "      <td>0.175395</td>\n",
       "      <td>...</td>\n",
       "      <td>46.61380</td>\n",
       "      <td>667729.0</td>\n",
       "      <td>5.109350e+09</td>\n",
       "      <td>667621.0</td>\n",
       "      <td>41.95380</td>\n",
       "      <td>22.77270</td>\n",
       "      <td>8.73701</td>\n",
       "      <td>68.4041</td>\n",
       "      <td>29.83820</td>\n",
       "      <td>412407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4477</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.213325</td>\n",
       "      <td>0.01099</td>\n",
       "      <td>0.613841</td>\n",
       "      <td>-0.57301</td>\n",
       "      <td>-0.10401</td>\n",
       "      <td>0.13699</td>\n",
       "      <td>0.099362</td>\n",
       "      <td>0.159078</td>\n",
       "      <td>...</td>\n",
       "      <td>47.95200</td>\n",
       "      <td>688802.0</td>\n",
       "      <td>4.941720e+09</td>\n",
       "      <td>688691.0</td>\n",
       "      <td>41.81550</td>\n",
       "      <td>22.85350</td>\n",
       "      <td>8.90410</td>\n",
       "      <td>68.5051</td>\n",
       "      <td>30.45150</td>\n",
       "      <td>425422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.212210</td>\n",
       "      <td>0.01299</td>\n",
       "      <td>0.593249</td>\n",
       "      <td>-0.64101</td>\n",
       "      <td>-0.10001</td>\n",
       "      <td>0.13299</td>\n",
       "      <td>0.098206</td>\n",
       "      <td>0.157308</td>\n",
       "      <td>...</td>\n",
       "      <td>47.35050</td>\n",
       "      <td>711921.0</td>\n",
       "      <td>5.379120e+09</td>\n",
       "      <td>711797.0</td>\n",
       "      <td>43.73450</td>\n",
       "      <td>24.15910</td>\n",
       "      <td>8.97766</td>\n",
       "      <td>72.4431</td>\n",
       "      <td>30.38700</td>\n",
       "      <td>439695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4479</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.232580</td>\n",
       "      <td>-0.00501</td>\n",
       "      <td>0.397291</td>\n",
       "      <td>-0.98601</td>\n",
       "      <td>-0.13101</td>\n",
       "      <td>0.11899</td>\n",
       "      <td>0.105631</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>...</td>\n",
       "      <td>47.87340</td>\n",
       "      <td>735631.0</td>\n",
       "      <td>5.525150e+09</td>\n",
       "      <td>735508.0</td>\n",
       "      <td>45.72940</td>\n",
       "      <td>25.32300</td>\n",
       "      <td>9.20105</td>\n",
       "      <td>75.5608</td>\n",
       "      <td>30.77280</td>\n",
       "      <td>454341.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4480 rows Ã— 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Person  class        E2       E4        E5       E8       E9      E10  \\\n",
       "0          1      1  0.254095 -0.01037 -0.538509 -1.37437 -0.10937  0.10763   \n",
       "1          1      1  0.193761 -0.00237  0.781415 -0.71937 -0.08737  0.11163   \n",
       "2          1      1  0.182336 -0.02337  0.881194 -0.71937 -0.08037  0.08863   \n",
       "3          1      1  0.176636 -0.02737  1.024900 -0.71937 -0.08037  0.07163   \n",
       "4          1      1  0.179248 -0.02737  0.935697 -0.75637 -0.08337  0.07163   \n",
       "...      ...    ...       ...      ...       ...      ...      ...      ...   \n",
       "4475      40      4  0.254373 -0.00101 -0.165105 -1.19301 -0.15801  0.12299   \n",
       "4476      40      4  0.238946 -0.00901 -0.034522 -1.10201 -0.14501  0.11899   \n",
       "4477      40      4  0.213325  0.01099  0.613841 -0.57301 -0.10401  0.13699   \n",
       "4478      40      4  0.212210  0.01299  0.593249 -0.64101 -0.10001  0.13299   \n",
       "4479      40      4  0.232580 -0.00501  0.397291 -0.98601 -0.13101  0.11899   \n",
       "\n",
       "           E11       E13  ...      DH73       DH76          DH83       DH90  \\\n",
       "0     0.093296  0.172694  ...  12.09630  4901420.0  1.160800e+09  4902090.0   \n",
       "1     0.079461  0.142173  ...  11.62070  4882550.0  1.142700e+09  4883220.0   \n",
       "2     0.074408  0.131310  ...  10.57340  4863140.0  1.015080e+09  4863810.0   \n",
       "3     0.070138  0.125188  ...   9.85611  4843300.0  9.061740e+08  4843960.0   \n",
       "4     0.072914  0.127866  ...   8.87342  4822950.0  7.843120e+08  4823610.0   \n",
       "...        ...       ...  ...       ...        ...           ...        ...   \n",
       "4475  0.115445  0.187620  ...  50.11640   645724.0  5.241020e+09   645610.0   \n",
       "4476  0.109450  0.175395  ...  46.61380   667729.0  5.109350e+09   667621.0   \n",
       "4477  0.099362  0.159078  ...  47.95200   688802.0  4.941720e+09   688691.0   \n",
       "4478  0.098206  0.157308  ...  47.35050   711921.0  5.379120e+09   711797.0   \n",
       "4479  0.105631  0.171429  ...  47.87340   735631.0  5.525150e+09   735508.0   \n",
       "\n",
       "          DH93      DH94     DH99    DH100     DH101      DH104  \n",
       "0     10.43340   5.83548  2.53425  17.3882   8.05589  3028080.0  \n",
       "1     10.24230   5.76355  2.51513  16.5914   7.81769  3016420.0  \n",
       "2      9.27871   5.16683  2.25959  15.2312   7.11684  3004430.0  \n",
       "3      8.65402   4.63212  2.13924  14.4663   6.70236  2992170.0  \n",
       "4      7.78651   4.23410  1.93595  12.5493   6.08647  2979610.0  \n",
       "...        ...       ...      ...      ...       ...        ...  \n",
       "4475  45.16100  24.78100  9.48535  73.9901  31.82590   398810.0  \n",
       "4476  41.95380  22.77270  8.73701  68.4041  29.83820   412407.0  \n",
       "4477  41.81550  22.85350  8.90410  68.5051  30.45150   425422.0  \n",
       "4478  43.73450  24.15910  8.97766  72.4431  30.38700   439695.0  \n",
       "4479  45.72940  25.32300  9.20105  75.5608  30.77280   454341.0  \n",
       "\n",
       "[4480 rows x 186 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_rfecv = data[['Person', 'class']+list(rfecv)]\n",
    "\n",
    "pd_rfecv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_rfecv.to_csv('../rfecv_184.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe mit 223 Features nach RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = pd.read_csv('../rfecv_184.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person</th>\n",
       "      <th>class</th>\n",
       "      <th>E2</th>\n",
       "      <th>E4</th>\n",
       "      <th>E5</th>\n",
       "      <th>E8</th>\n",
       "      <th>E9</th>\n",
       "      <th>E10</th>\n",
       "      <th>E11</th>\n",
       "      <th>E13</th>\n",
       "      <th>...</th>\n",
       "      <th>DH73</th>\n",
       "      <th>DH76</th>\n",
       "      <th>DH83</th>\n",
       "      <th>DH90</th>\n",
       "      <th>DH93</th>\n",
       "      <th>DH94</th>\n",
       "      <th>DH99</th>\n",
       "      <th>DH100</th>\n",
       "      <th>DH101</th>\n",
       "      <th>DH104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.254095</td>\n",
       "      <td>-0.01037</td>\n",
       "      <td>-0.538509</td>\n",
       "      <td>-1.37437</td>\n",
       "      <td>-0.10937</td>\n",
       "      <td>0.10763</td>\n",
       "      <td>0.093296</td>\n",
       "      <td>0.172694</td>\n",
       "      <td>...</td>\n",
       "      <td>12.09630</td>\n",
       "      <td>4901420.0</td>\n",
       "      <td>1.160800e+09</td>\n",
       "      <td>4902090.0</td>\n",
       "      <td>10.43340</td>\n",
       "      <td>5.83548</td>\n",
       "      <td>2.53425</td>\n",
       "      <td>17.3882</td>\n",
       "      <td>8.05589</td>\n",
       "      <td>3028080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.193761</td>\n",
       "      <td>-0.00237</td>\n",
       "      <td>0.781415</td>\n",
       "      <td>-0.71937</td>\n",
       "      <td>-0.08737</td>\n",
       "      <td>0.11163</td>\n",
       "      <td>0.079461</td>\n",
       "      <td>0.142173</td>\n",
       "      <td>...</td>\n",
       "      <td>11.62070</td>\n",
       "      <td>4882550.0</td>\n",
       "      <td>1.142700e+09</td>\n",
       "      <td>4883220.0</td>\n",
       "      <td>10.24230</td>\n",
       "      <td>5.76355</td>\n",
       "      <td>2.51513</td>\n",
       "      <td>16.5914</td>\n",
       "      <td>7.81769</td>\n",
       "      <td>3016420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.182336</td>\n",
       "      <td>-0.02337</td>\n",
       "      <td>0.881194</td>\n",
       "      <td>-0.71937</td>\n",
       "      <td>-0.08037</td>\n",
       "      <td>0.08863</td>\n",
       "      <td>0.074408</td>\n",
       "      <td>0.131310</td>\n",
       "      <td>...</td>\n",
       "      <td>10.57340</td>\n",
       "      <td>4863140.0</td>\n",
       "      <td>1.015080e+09</td>\n",
       "      <td>4863810.0</td>\n",
       "      <td>9.27871</td>\n",
       "      <td>5.16683</td>\n",
       "      <td>2.25959</td>\n",
       "      <td>15.2312</td>\n",
       "      <td>7.11684</td>\n",
       "      <td>3004430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.176636</td>\n",
       "      <td>-0.02737</td>\n",
       "      <td>1.024900</td>\n",
       "      <td>-0.71937</td>\n",
       "      <td>-0.08037</td>\n",
       "      <td>0.07163</td>\n",
       "      <td>0.070138</td>\n",
       "      <td>0.125188</td>\n",
       "      <td>...</td>\n",
       "      <td>9.85611</td>\n",
       "      <td>4843300.0</td>\n",
       "      <td>9.061740e+08</td>\n",
       "      <td>4843960.0</td>\n",
       "      <td>8.65402</td>\n",
       "      <td>4.63212</td>\n",
       "      <td>2.13924</td>\n",
       "      <td>14.4663</td>\n",
       "      <td>6.70236</td>\n",
       "      <td>2992170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.179248</td>\n",
       "      <td>-0.02737</td>\n",
       "      <td>0.935697</td>\n",
       "      <td>-0.75637</td>\n",
       "      <td>-0.08337</td>\n",
       "      <td>0.07163</td>\n",
       "      <td>0.072914</td>\n",
       "      <td>0.127866</td>\n",
       "      <td>...</td>\n",
       "      <td>8.87342</td>\n",
       "      <td>4822950.0</td>\n",
       "      <td>7.843120e+08</td>\n",
       "      <td>4823610.0</td>\n",
       "      <td>7.78651</td>\n",
       "      <td>4.23410</td>\n",
       "      <td>1.93595</td>\n",
       "      <td>12.5493</td>\n",
       "      <td>6.08647</td>\n",
       "      <td>2979610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4475</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.254373</td>\n",
       "      <td>-0.00101</td>\n",
       "      <td>-0.165105</td>\n",
       "      <td>-1.19301</td>\n",
       "      <td>-0.15801</td>\n",
       "      <td>0.12299</td>\n",
       "      <td>0.115445</td>\n",
       "      <td>0.187620</td>\n",
       "      <td>...</td>\n",
       "      <td>50.11640</td>\n",
       "      <td>645724.0</td>\n",
       "      <td>5.241020e+09</td>\n",
       "      <td>645610.0</td>\n",
       "      <td>45.16100</td>\n",
       "      <td>24.78100</td>\n",
       "      <td>9.48535</td>\n",
       "      <td>73.9901</td>\n",
       "      <td>31.82590</td>\n",
       "      <td>398810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4476</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.238946</td>\n",
       "      <td>-0.00901</td>\n",
       "      <td>-0.034522</td>\n",
       "      <td>-1.10201</td>\n",
       "      <td>-0.14501</td>\n",
       "      <td>0.11899</td>\n",
       "      <td>0.109450</td>\n",
       "      <td>0.175395</td>\n",
       "      <td>...</td>\n",
       "      <td>46.61380</td>\n",
       "      <td>667729.0</td>\n",
       "      <td>5.109350e+09</td>\n",
       "      <td>667621.0</td>\n",
       "      <td>41.95380</td>\n",
       "      <td>22.77270</td>\n",
       "      <td>8.73701</td>\n",
       "      <td>68.4041</td>\n",
       "      <td>29.83820</td>\n",
       "      <td>412407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4477</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.213325</td>\n",
       "      <td>0.01099</td>\n",
       "      <td>0.613841</td>\n",
       "      <td>-0.57301</td>\n",
       "      <td>-0.10401</td>\n",
       "      <td>0.13699</td>\n",
       "      <td>0.099362</td>\n",
       "      <td>0.159078</td>\n",
       "      <td>...</td>\n",
       "      <td>47.95200</td>\n",
       "      <td>688802.0</td>\n",
       "      <td>4.941720e+09</td>\n",
       "      <td>688691.0</td>\n",
       "      <td>41.81550</td>\n",
       "      <td>22.85350</td>\n",
       "      <td>8.90410</td>\n",
       "      <td>68.5051</td>\n",
       "      <td>30.45150</td>\n",
       "      <td>425422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.212210</td>\n",
       "      <td>0.01299</td>\n",
       "      <td>0.593249</td>\n",
       "      <td>-0.64101</td>\n",
       "      <td>-0.10001</td>\n",
       "      <td>0.13299</td>\n",
       "      <td>0.098206</td>\n",
       "      <td>0.157308</td>\n",
       "      <td>...</td>\n",
       "      <td>47.35050</td>\n",
       "      <td>711921.0</td>\n",
       "      <td>5.379120e+09</td>\n",
       "      <td>711797.0</td>\n",
       "      <td>43.73450</td>\n",
       "      <td>24.15910</td>\n",
       "      <td>8.97766</td>\n",
       "      <td>72.4431</td>\n",
       "      <td>30.38700</td>\n",
       "      <td>439695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4479</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.232580</td>\n",
       "      <td>-0.00501</td>\n",
       "      <td>0.397291</td>\n",
       "      <td>-0.98601</td>\n",
       "      <td>-0.13101</td>\n",
       "      <td>0.11899</td>\n",
       "      <td>0.105631</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>...</td>\n",
       "      <td>47.87340</td>\n",
       "      <td>735631.0</td>\n",
       "      <td>5.525150e+09</td>\n",
       "      <td>735508.0</td>\n",
       "      <td>45.72940</td>\n",
       "      <td>25.32300</td>\n",
       "      <td>9.20105</td>\n",
       "      <td>75.5608</td>\n",
       "      <td>30.77280</td>\n",
       "      <td>454341.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4480 rows Ã— 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Person  class        E2       E4        E5       E8       E9      E10  \\\n",
       "0          1      1  0.254095 -0.01037 -0.538509 -1.37437 -0.10937  0.10763   \n",
       "1          1      1  0.193761 -0.00237  0.781415 -0.71937 -0.08737  0.11163   \n",
       "2          1      1  0.182336 -0.02337  0.881194 -0.71937 -0.08037  0.08863   \n",
       "3          1      1  0.176636 -0.02737  1.024900 -0.71937 -0.08037  0.07163   \n",
       "4          1      1  0.179248 -0.02737  0.935697 -0.75637 -0.08337  0.07163   \n",
       "...      ...    ...       ...      ...       ...      ...      ...      ...   \n",
       "4475      40      4  0.254373 -0.00101 -0.165105 -1.19301 -0.15801  0.12299   \n",
       "4476      40      4  0.238946 -0.00901 -0.034522 -1.10201 -0.14501  0.11899   \n",
       "4477      40      4  0.213325  0.01099  0.613841 -0.57301 -0.10401  0.13699   \n",
       "4478      40      4  0.212210  0.01299  0.593249 -0.64101 -0.10001  0.13299   \n",
       "4479      40      4  0.232580 -0.00501  0.397291 -0.98601 -0.13101  0.11899   \n",
       "\n",
       "           E11       E13  ...      DH73       DH76          DH83       DH90  \\\n",
       "0     0.093296  0.172694  ...  12.09630  4901420.0  1.160800e+09  4902090.0   \n",
       "1     0.079461  0.142173  ...  11.62070  4882550.0  1.142700e+09  4883220.0   \n",
       "2     0.074408  0.131310  ...  10.57340  4863140.0  1.015080e+09  4863810.0   \n",
       "3     0.070138  0.125188  ...   9.85611  4843300.0  9.061740e+08  4843960.0   \n",
       "4     0.072914  0.127866  ...   8.87342  4822950.0  7.843120e+08  4823610.0   \n",
       "...        ...       ...  ...       ...        ...           ...        ...   \n",
       "4475  0.115445  0.187620  ...  50.11640   645724.0  5.241020e+09   645610.0   \n",
       "4476  0.109450  0.175395  ...  46.61380   667729.0  5.109350e+09   667621.0   \n",
       "4477  0.099362  0.159078  ...  47.95200   688802.0  4.941720e+09   688691.0   \n",
       "4478  0.098206  0.157308  ...  47.35050   711921.0  5.379120e+09   711797.0   \n",
       "4479  0.105631  0.171429  ...  47.87340   735631.0  5.525150e+09   735508.0   \n",
       "\n",
       "          DH93      DH94     DH99    DH100     DH101      DH104  \n",
       "0     10.43340   5.83548  2.53425  17.3882   8.05589  3028080.0  \n",
       "1     10.24230   5.76355  2.51513  16.5914   7.81769  3016420.0  \n",
       "2      9.27871   5.16683  2.25959  15.2312   7.11684  3004430.0  \n",
       "3      8.65402   4.63212  2.13924  14.4663   6.70236  2992170.0  \n",
       "4      7.78651   4.23410  1.93595  12.5493   6.08647  2979610.0  \n",
       "...        ...       ...      ...      ...       ...        ...  \n",
       "4475  45.16100  24.78100  9.48535  73.9901  31.82590   398810.0  \n",
       "4476  41.95380  22.77270  8.73701  68.4041  29.83820   412407.0  \n",
       "4477  41.81550  22.85350  8.90410  68.5051  30.45150   425422.0  \n",
       "4478  43.73450  24.15910  8.97766  72.4431  30.38700   439695.0  \n",
       "4479  45.72940  25.32300  9.20105  75.5608  30.77280   454341.0  \n",
       "\n",
       "[4480 rows x 186 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimierung des groÃŸen Neuronalen Netzes auf Grundlage der zuvor selektierten Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../rfecv_184.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bestimmung eines Ablageorts fÃ¼r das spÃ¤tere Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_models = '../models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitten der Daten in Features, die Zielvariable 'class' und die Group-Variable 'Person'\n",
    "data_input = data.drop(['Person', 'class'], axis = 1)\n",
    "data_person = data['Person']\n",
    "data_labels_raw = data['class']\n",
    "\n",
    "## Splitten der Daten in Trainings- und Testdatensatz\n",
    "train_data, test_data, train_labels_raw, test_labels_raw = train_test_split(\n",
    "                      data_input, data_labels_raw, test_size = 0.1, random_state=123)\n",
    "\n",
    "## Skalierung der Daten\n",
    "scaler = MinMaxScaler().fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)\n",
    "\n",
    "## one-hot-encoding \n",
    "encoder = LabelBinarizer().fit(train_labels_raw)\n",
    "train_labels = encoder.transform(train_labels_raw)\n",
    "test_labels = encoder.transform(test_labels_raw)\n",
    "\n",
    "## Extrahierung von Features und Zielvariablen\n",
    "n_attributes = data_input.shape[1]\n",
    "n_classes = train_labels.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erstellung des Neuronalen Netzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMyANN(hyperparams):\n",
    "\n",
    "    #hyperparameters for keras tuner\n",
    "    hp_units = hyperparams.Int('units', min_value=140, max_value=220, step=20)\n",
    "    hp_activations = hyperparams.Choice('activation', values=['relu', 'tanh', 'elu'])\n",
    "    hp_lr = hyperparams.Choice('learning_rate', values=[0.01, 0.001, 0.0001])\n",
    "    hp_nbr_hidden_layers = hyperparams.Int('nbr_hidden_layers', min_value=2, max_value=4, step=1)\n",
    "\n",
    "    model = Sequential()  \n",
    "    model.add( InputLayer(input_shape=(n_attributes, ), name=\"input_1D_vector\")) \n",
    "\n",
    "    for i in range(hp_nbr_hidden_layers):\n",
    "        model.add( Dense(units=hp_units, activation=hp_activations,\n",
    "                             name=\"hidden\" +str(i)+ \"_\" +str(hp_units)+ \"nodes\")) #hidden layer\n",
    "\n",
    "\n",
    "    model.add( Dense(units=n_classes, activation='softmax', name=\"output_softmax\"))\n",
    "    \n",
    "    optim = Adam(learning_rate = hp_lr) \n",
    "    \n",
    "    #model.compile(loss='mse', optimizer=optim, metrics=['accuracy'])\n",
    "    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=optim, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verwendung des Keras-Tuners zur ErschlieÃŸung der besten Hyperparameter-Kombination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 61 Complete [00h 00m 36s]\n",
      "val_accuracy: 0.9925742745399475\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 51m 18s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "keras_tuner = RandomSearch(\n",
    "    createMyANN,  \n",
    "    objective= 'val_accuracy', \n",
    "    max_trials=100,  \n",
    "    executions_per_trial=1,  \n",
    "    directory= path_models + 'ann_big_opt_feat_sel',\n",
    "    project_name='ann_big_opt_feat_sel')\n",
    "\n",
    "import time\n",
    "time_start = time.time()\n",
    "\n",
    "\n",
    "keras_tuner.search(train_data, train_labels, validation_split=0.1, \n",
    "             epochs=500, verbose=2,\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=50,\n",
    "                                                      restore_best_weights=True)])\n",
    "\n",
    "time_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for model training: 0:51:19 [h:m:s]\n"
     ]
    }
   ],
   "source": [
    "hours = (time_end - time_start) // 3600\n",
    "minutes = ((time_end - time_start) % 3600) // 60\n",
    "seconds = round((time_end - time_start - hours * 3600 - minutes * 60), 0)\n",
    "print(f\"Elapsed time for model training: {int(hours)}:{int(minutes)}:{int(seconds)} [h:m:s]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beste Hyperparameter-Kombination aus dem Keras-Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparamters:\n",
      "{'units': 220, 'activation': 'relu', 'learning_rate': 0.001, 'nbr_hidden_layers': 2}\n",
      "Results summary\n",
      "Results in ../models/ann_big_opt_feat_sel/ann_big_opt_feat_sel\n",
      "Showing 1 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 220\n",
      "activation: relu\n",
      "learning_rate: 0.001\n",
      "nbr_hidden_layers: 2\n",
      "Score: 1.0\n",
      "Best model:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden0_220nodes (Dense)     (None, 220)               40700     \n",
      "_________________________________________________________________\n",
      "hidden1_220nodes (Dense)     (None, 220)               48620     \n",
      "_________________________________________________________________\n",
      "output_softmax (Dense)       (None, 4)                 884       \n",
      "=================================================================\n",
      "Total params: 90,204\n",
      "Trainable params: 90,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#keras_tuner.search_space_summary()\n",
    "\n",
    "hyperparams_best = keras_tuner.get_best_hyperparameters()[0].values\n",
    "\n",
    "print(\"Best hyperparamters:\")\n",
    "print(hyperparams_best)\n",
    "\n",
    "keras_tuner.results_summary(1) \n",
    "\n",
    "model = keras_tuner.get_best_models(num_models=1)[0] \n",
    "print(\"Best model:\")\n",
    "model.summary()  \n",
    "\n",
    "tf.keras.utils.plot_model(model) \n",
    "\n",
    "model.save(path_models + \"ann_big_opt_feat_sel.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'units': 220, 'activation': 'relu', 'learning_rate': 0.001, 'nbr_hidden_layers': 2}\n"
     ]
    }
   ],
   "source": [
    "print(hyperparams_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anwendung des Modells auf Testdatensatz und Ausgabe der Accuracy sowie Visualisierung der Ergebnisse Ã¼ber Confusion-Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Results auf test data #########\n",
      "Accuracy (test):  0.984375\n",
      "[[106   0   1   0]\n",
      " [  0 103   5   0]\n",
      " [  0   1 105   0]\n",
      " [  0   0   0 127]]\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Results auf test data #########\")\n",
    "pred = model.predict(test_data)\n",
    "predictions = np.argmax(model.predict(test_data), axis=-1)  \n",
    "cm = confusion_matrix(test_labels_raw, predictions+1)\n",
    "\n",
    "acc = accuracy_score(test_labels_raw, predictions+1)\n",
    "print(\"Accuracy (test): \", acc)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "B_Data Unterstanding.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
